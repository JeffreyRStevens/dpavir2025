[
  {
    "objectID": "slides/39_tables.html",
    "href": "slides/39_tables.html",
    "title": "Tables",
    "section": "",
    "text": "First, load {tidyverse} and {papaja} and import the data.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(papaja)\n\nLoading required package: tinylabels\n\nhai &lt;- read_csv(\"https://decisionslab.unl.edu/data/thayer_stevens_2020_data1.csv\") |&gt;\n  select(experiment, participant, condition, gender,\n         panas_pre = panas_pre_pos, panas_post = panas_post_pos)\n\nRows: 157 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): condition, gender, race, parent_income\ndbl  (33): experiment, participant, age_num, pas, pets_now, pets_child, dog_...\ndttm  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhai_long &lt;- hai |&gt;\n  pivot_longer(contains(\"panas\"), names_to = \"prepost\", values_to = \"panas\") |&gt;\n  mutate(condition = fct_recode(condition, \"Control\" = \"control\", \"HAI\" = \"hai\"),\n         prepost = fct_recode(prepost, \"Pre\" = \"panas_pre\", \"Post\" = \"panas_post\"),\n         prepost = fct_relevel(prepost, c(\"Pre\", \"Post\")))\n\nNow let’s build a data frame that will be our table.\n\n(condition_prepost_means &lt;- hai_long |&gt;\n  group_by(condition, prepost) |&gt;\n  summarise(across(starts_with(\"panas\"), ~ mean(.x, na.rm = TRUE))))\n\n`summarise()` has grouped output by 'condition'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   condition [2]\n  condition prepost panas\n  &lt;fct&gt;     &lt;fct&gt;   &lt;dbl&gt;\n1 Control   Pre      2.99\n2 Control   Post     2.76\n3 HAI       Pre      2.97\n4 HAI       Post     3.23"
  },
  {
    "objectID": "slides/39_tables.html#column-and-row-names",
    "href": "slides/39_tables.html#column-and-row-names",
    "title": "Tables",
    "section": "Column and row names",
    "text": "Column and row names\nYou can control column names and row names with col.names and row.names.\n\nkable(condition_prepost_means, \n      col.names = c(\"Condition\", \"Prepost\", \"Mean PANAS\"))\n\n\n\n\nCondition\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.989873\n\n\nControl\nPost\n2.760759\n\n\nHAI\nPre\n2.971795\n\n\nHAI\nPost\n3.232051"
  },
  {
    "objectID": "slides/39_tables.html#column-alignment",
    "href": "slides/39_tables.html#column-alignment",
    "title": "Tables",
    "section": "Column alignment",
    "text": "Column alignment\nBy default, character columns are left aligned and numeric columns are right aligned. You can set alignment manually with the align argument with l = left, c = center, and r = right. You can just pass a character string with a series of those letters.\n\nkable(condition_prepost_means,\n      col.names = c(\"Condition\", \"Prepost\", \"Mean PANAS\"), \n      align = \"rcl\")\n\n\n\n\nCondition\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.989873\n\n\nControl\nPost\n2.760759\n\n\nHAI\nPre\n2.971795\n\n\nHAI\nPost\n3.232051"
  },
  {
    "objectID": "slides/39_tables.html#digit-rounding",
    "href": "slides/39_tables.html#digit-rounding",
    "title": "Tables",
    "section": "Digit rounding",
    "text": "Digit rounding\nRound the digits for all numeric data columns with digits argument.\n\nkable(condition_prepost_means,\n      col.names = c(\"Condition\", \"Prepost\", \"Mean PANAS\"), \n      digits = 2)\n\n\n\n\nCondition\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.99\n\n\nControl\nPost\n2.76\n\n\nHAI\nPre\n2.97\n\n\nHAI\nPost\n3.23\n\n\n\n\n\nIf you want different digits for different columns, you can pass a vector to the digits argument.\n\ncondition_prepost_means |&gt; \n  pivot_wider(id_cols = condition, names_from = prepost, values_from = panas) |&gt; \n  kable(digits = c(0, 2, 3))\n\n\n\n\ncondition\nPre\nPost\n\n\n\n\nControl\n2.99\n2.761\n\n\nHAI\n2.97\n3.232"
  },
  {
    "objectID": "slides/39_tables.html#table-titles",
    "href": "slides/39_tables.html#table-titles",
    "title": "Tables",
    "section": "Table titles",
    "text": "Table titles\nAdd a title to the table with the caption argument. The good news is that we can cross-reference easily (Table @ref(tab:title-table)). The bad news is that with captions, tables in PDFs are automatically placed at the top of the page. We’ll see how to fix this later.\n\nkable(condition_prepost_means,\n      col.names = c(\"Condition\", \"Prepost\", \"Mean PANAS\"), \n      caption = \"PANAS scores by condition and prepost\")\n\n\nPANAS scores by condition and prepost\n\n\nCondition\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.989873\n\n\nControl\nPost\n2.760759\n\n\nHAI\nPre\n2.971795\n\n\nHAI\nPost\n3.232051"
  },
  {
    "objectID": "slides/39_tables.html#general-styling",
    "href": "slides/39_tables.html#general-styling",
    "title": "Tables",
    "section": "General styling",
    "text": "General styling\nThe kable_styling() function formats a number of things such as font size, table width, and table alignment. I’ll also add latex_options = \"hold_position\" to keep the table in the text. Otherwise, it puts it at the top of the page.\n\nkable(condition_prepost_means,\n      caption = \"PANAS scores by condition and prepost\",\n      col.names = c(\"Condition\", \"Prepost\", \"Mean PANAS\"), \n      booktabs = TRUE) |&gt;\n  kable_styling(font_size = 18, latex_options = \"hold_position\")\n\n\nPANAS scores by condition and prepost\n\n\nCondition\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.989873\n\n\nControl\nPost\n2.760759\n\n\nHAI\nPre\n2.971795\n\n\nHAI\nPost\n3.232051"
  },
  {
    "objectID": "slides/39_tables.html#labels-spanning-rows",
    "href": "slides/39_tables.html#labels-spanning-rows",
    "title": "Tables",
    "section": "Labels spanning rows",
    "text": "Labels spanning rows\nIf you want to label groups of rows, use pack_rows(). Let’s get rid of the condition column and label the conditions explicitly.\n\ncondition_prepost_means2 &lt;- condition_prepost_means |&gt;\n  ungroup(condition) |&gt;\n  select(-condition)\n\n\nkable(condition_prepost_means2, \n      booktabs = TRUE)\n\n\n\n\nprepost\npanas\n\n\n\n\nPre\n2.989873\n\n\nPost\n2.760759\n\n\nPre\n2.971795\n\n\nPost\n3.232051\n\n\n\n\n\n\nkable(condition_prepost_means2, \n      booktabs = TRUE,\n      col.names = c(\"\", \"Mean PANAS\")) |&gt;\n  pack_rows(\"Control\", start_row = 1, end_row = 2) |&gt;\n  pack_rows(\"HAI\", start_row = 3, end_row = 4)\n\n\n\n\n\nMean PANAS\n\n\n\n\nControl\n\n\nPre\n2.989873\n\n\nPost\n2.760759\n\n\nHAI\n\n\nPre\n2.971795\n\n\nPost\n3.232051\n\n\n\n\n\n\n\nNotice that we removed the first column name with \"\"."
  },
  {
    "objectID": "slides/39_tables.html#labels-spanning-columns",
    "href": "slides/39_tables.html#labels-spanning-columns",
    "title": "Tables",
    "section": "Labels spanning columns",
    "text": "Labels spanning columns\nYou can labels groups of columns with the add_header_above() function. Let’s rearrange the data into wide format to illustrate this.\n\n(wide_means &lt;- condition_prepost_means |&gt;\n   unite(cond_prepost, condition:prepost) |&gt;\n   pivot_wider(names_from = cond_prepost, values_from = panas))\n\n# A tibble: 1 × 4\n  Control_Pre Control_Post HAI_Pre HAI_Post\n        &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1        2.99         2.76    2.97     3.23\n\n\n\nkable(wide_means, booktabs = TRUE)\n\n\n\n\nControl_Pre\nControl_Post\nHAI_Pre\nHAI_Post\n\n\n\n\n2.989873\n2.760759\n2.971795\n3.232051\n\n\n\n\n\nNow that the data are in wide format, we can add the column names by repeating Pre and Post then add the headers.\n\nkable(wide_means, \n      booktabs = TRUE, \n      col.names = rep(c(\"Pre\", \"Post\"), 2),\n      digits = 2) |&gt;\n  add_header_above(c(\"Control\" = 2, \"HAI\" = 2))\n\n\n\n\n\n\n\n\n\n\n\nControl\n\n\nHAI\n\n\n\nPre\nPost\nPre\nPost\n\n\n\n\n2.99\n2.76\n2.97\n3.23\n\n\n\n\n\n\n\nMaybe we need a column stating this is Mean PANAS.\n\nwide_means2 &lt;- wide_means |&gt; \n  mutate(label = \"Mean PANAS\", .before = 1)\nkable(wide_means2, \n      booktabs = TRUE, \n      col.names = c(\"\", rep(c(\"Pre\", \"Post\"), 2)),\n      digits = 2) |&gt;\n  add_header_above(c(\"\", \"Control\" = 2, \"HAI\" = 2))\n\n\n\n\n\n\n\n\n\n\n\n\n\nControl\n\n\nHAI\n\n\n\n\nPre\nPost\nPre\nPost\n\n\n\n\nMean PANAS\n2.99\n2.76\n2.97\n3.23"
  },
  {
    "objectID": "slides/39_tables.html#table-footnotes",
    "href": "slides/39_tables.html#table-footnotes",
    "title": "Tables",
    "section": "Table footnotes",
    "text": "Table footnotes\nAdd table notes with the footnote() function.\n\nkable(condition_prepost_means, \n      booktabs = TRUE,\n      caption = \"PANAS scores by condition and prepost\",\n      col.names = c(\"Condition*\", \"Prepost\", \"Mean PANAS\")) |&gt;\n  kable_styling(latex_options = \"hold_position\") |&gt;\n  footnote(general = \"Source: Thayer & Stevens (2021)\",\n           symbol = \"73 control participants, 72 HAI participants\",\n           footnote_as_chunk = TRUE)\n\n\nPANAS scores by condition and prepost\n\n\nCondition*\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.989873\n\n\nControl\nPost\n2.760759\n\n\nHAI\nPre\n2.971795\n\n\nHAI\nPost\n3.232051\n\n\n\nNote:   Source: Thayer & Stevens (2021)\n\n\n\n\n* 73 control participants, 72 HAI participants"
  },
  {
    "objectID": "slides/39_tables.html#landscape",
    "href": "slides/39_tables.html#landscape",
    "title": "Tables",
    "section": "Landscape",
    "text": "Landscape\nRotate wide tables with landscape() function.\n\nkable(condition_prepost_means, \n      booktabs = TRUE,\n      caption = \"PANAS scores by condition and prepost\",\n      col.names = c(\"Condition\", \"Prepost\", \"Mean PANAS\")) |&gt;\n  kable_styling(latex_options = \"hold_position\") |&gt;\n  footnote(general = \"Source: Thayer & Stevens (2021)\",\n           footnote_as_chunk = TRUE) |&gt;\n  landscape()\n\n\nPANAS scores by condition and prepost\n\n\nCondition\nPrepost\nMean PANAS\n\n\n\n\nControl\nPre\n2.989873\n\n\nControl\nPost\n2.760759\n\n\nHAI\nPre\n2.971795\n\n\nHAI\nPost\n3.232051\n\n\n\nNote:   Source: Thayer & Stevens (2021)"
  },
  {
    "objectID": "slides/39_tables.html#linear-regression",
    "href": "slides/39_tables.html#linear-regression",
    "title": "Tables",
    "section": "Linear regression",
    "text": "Linear regression\n\nhai_lm &lt;- lm(panas_post ~ condition * gender, data = hai)\nsummary(hai_lm)\n\n\nCall:\nlm(formula = panas_post ~ condition * gender, data = hai)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.80909 -0.58525  0.01475  0.48333  1.88333 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              2.68525    0.09578  28.035  &lt; 2e-16 ***\nconditionhai             0.52385    0.13287   3.943 0.000122 ***\ngenderMale               0.33142    0.20066   1.652 0.100662    \nconditionhai:genderMale -0.18218    0.30884  -0.590 0.556142    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7481 on 153 degrees of freedom\nMultiple R-squared:  0.109, Adjusted R-squared:  0.09149 \nF-statistic: 6.236 on 3 and 153 DF,  p-value: 0.0005053\n\napa_print(hai_lm)\n\n$estimate\n$estimate$Intercept\n[1] \"$b = 2.69$, 95\\\\% CI $[2.50, 2.87]$\"\n\n$estimate$conditionhai\n[1] \"$b = 0.52$, 95\\\\% CI $[0.26, 0.79]$\"\n\n$estimate$genderMale\n[1] \"$b = 0.33$, 95\\\\% CI $[-0.07, 0.73]$\"\n\n$estimate$conditionhai_genderMale\n[1] \"$b = -0.18$, 95\\\\% CI $[-0.79, 0.43]$\"\n\n$estimate$modelfit\n$estimate$modelfit$r2\n[1] \"$R^2 = .11$, 90\\\\% CI $[0.03, 0.18]$\"\n\n$estimate$modelfit$r2_adj\n[1] \"$R^2_{adj} = .09$\"\n\n$estimate$modelfit$aic\n[1] \"$\\\\mathrm{AIC} = 360.36$\"\n\n$estimate$modelfit$bic\n[1] \"$\\\\mathrm{BIC} = 375.64$\"\n\n\n\n$statistic\n$statistic$Intercept\n[1] \"$t(153) = 28.03$, $p &lt; .001$\"\n\n$statistic$conditionhai\n[1] \"$t(153) = 3.94$, $p &lt; .001$\"\n\n$statistic$genderMale\n[1] \"$t(153) = 1.65$, $p = .101$\"\n\n$statistic$conditionhai_genderMale\n[1] \"$t(153) = -0.59$, $p = .556$\"\n\n$statistic$modelfit\n$statistic$modelfit$r2\n[1] \"$F(3, 153) = 6.24$, $p &lt; .001$\"\n\n\n\n$full_result\n$full_result$Intercept\n[1] \"$b = 2.69$, 95\\\\% CI $[2.50, 2.87]$, $t(153) = 28.03$, $p &lt; .001$\"\n\n$full_result$conditionhai\n[1] \"$b = 0.52$, 95\\\\% CI $[0.26, 0.79]$, $t(153) = 3.94$, $p &lt; .001$\"\n\n$full_result$genderMale\n[1] \"$b = 0.33$, 95\\\\% CI $[-0.07, 0.73]$, $t(153) = 1.65$, $p = .101$\"\n\n$full_result$conditionhai_genderMale\n[1] \"$b = -0.18$, 95\\\\% CI $[-0.79, 0.43]$, $t(153) = -0.59$, $p = .556$\"\n\n$full_result$modelfit\n$full_result$modelfit$r2\n[1] \"$R^2 = .11$, 90\\\\% CI $[0.03, 0.18]$, $F(3, 153) = 6.24$, $p &lt; .001$\"\n\n\n\n$table\nA data.frame with 6 labelled columns:\n\n                               term estimate      conf.int statistic  df\n1                         Intercept     2.69  [2.50, 2.87]     28.03 153\n2                      Conditionhai     0.52  [0.26, 0.79]      3.94 153\n3                        GenderMale     0.33 [-0.07, 0.73]      1.65 153\n4 Conditionhai $\\\\times$ GenderMale    -0.18 [-0.79, 0.43]     -0.59 153\n  p.value\n1  &lt; .001\n2  &lt; .001\n3    .101\n4    .556\n\nterm     : Predictor \nestimate : $b$ \nconf.int : 95\\\\% CI \nstatistic: $t$ \ndf       : $\\\\mathit{df}$ \np.value  : $p$ \nattr(,\"class\")\n[1] \"apa_results\" \"list\"       \n\n\n\napa_table(apa_print(hai_lm)$table,\n          caption = \"Linear regression results\",\n          placement = \"h\")\n\n\n(#tab:lm-table) Linear regression results\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n2.69\n[2.50, 2.87]\n28.03\n153\n&lt; .001\n\n\nConditionhai\n0.52\n[0.26, 0.79]\n3.94\n153\n&lt; .001\n\n\nGenderMale\n0.33\n[-0.07, 0.73]\n1.65\n153\n.101\n\n\nConditionhai \\(\\times\\) GenderMale\n-0.18\n[-0.79, 0.43]\n-0.59\n153\n.556\n\n\n\n\n\n\nLet’s clean up those predictor names.\n\nhai_lm_table &lt;- apa_print(hai_lm)$table\nhai_lm_table &lt;- hai_lm_table |&gt;\n  mutate(term = str_replace(term, \"Conditionhai\", \"Condition\"),\n         term = str_replace(term, \"GenderMale\", \"Gender\"))\napa_table(hai_lm_table,\n          caption = \"Linear regression results\",\n          placement = \"h\")\n\n\n(#tab:unnamed-chunk-23) Linear regression results\n\n\nterm\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n2.69\n[2.50, 2.87]\n28.03\n153\n&lt; .001\n\n\nCondition\n0.52\n[0.26, 0.79]\n3.94\n153\n&lt; .001\n\n\nGender\n0.33\n[-0.07, 0.73]\n1.65\n153\n.101\n\n\nCondition \\(\\times\\) Gender\n-0.18\n[-0.79, 0.43]\n-0.59\n153\n.556\n\n\n\n\n\nHow could we name the first column Predictor instead of term?"
  },
  {
    "objectID": "code/plot_challenge.html",
    "href": "code/plot_challenge.html",
    "title": "Plotting challenge",
    "section": "",
    "text": "Recreate the following plot. Don’t worry about exact locations, size, or scaling. But pay attention to subsetting of the data and capitalization of text. Feel free to write the code in an R script or R Markdown document. Upload your final code to Canvas under Exercise: Plotting challenge by May 3."
  },
  {
    "objectID": "code/40_publications.html",
    "href": "code/40_publications.html",
    "title": "Publications",
    "section": "",
    "text": "Using the mpg data, create a data frame called mpg46 that only includes 4 and 6 cylinder cars. Conduct a t-test that compares highway fuel efficiency between the 4 and 6 cylinder cars and save the output as mpg_ttest.\n\n\n# &gt;\n\n\nLoad {papaja} and use the apa_print() function to extract the mean difference between cylinder numbers and the 95% confidence interval from mpg_ttest.\n\n\n# &gt;\n\n\nExtract the t-statistic and p-value for mpg_ttest.\n\n\n# &gt;\n\n\nExtract the mean difference, 95% CI, t-statistic, and p-value in one string.\n\n\n# &gt;\n\n\nUse printp() to format 0.0000001 as a p-value in APA format.\n\n\n# &gt;\n\n\nDropping the leading zero is silly. Use printnum() to return the same output as #5 but include the leading zero.\n\n\n# &gt;"
  },
  {
    "objectID": "code/39_tables.html",
    "href": "code/39_tables.html",
    "title": "Tables",
    "section": "",
    "text": "Using the mpg data, create a data frame called my_mpg that capitalizes the manufacturer.\n\n\n# &gt;\n\n\nCalculate mean highway and city fuel efficiency for each manufacturer and return a table with the caption “Highway and city fuel efficiency” and column names “Manufacturer”, “Highway”, and “City”.\n\n\n# &gt;\n\n\nRepeat the table from #2 but add a header that spans Highway and City that says “Fuel efficiency”. Reminder, you’ll need to load {kableExtra} to do this.\n\n\n# &gt;\n\n\nCalculate mean highway and city fuel efficiency for each manufacturer and year. Order the data frame by year, then remove the year column and add labels for each year that spans the rows for each year. Also, add a footnote that says “Source: mpg data set.”.\n\n\n# &gt;\n\n\nConduct a linear regression called my_model of the effects of displacement, cylinder, and year on highway fuel efficiency: lm(hwy ~ displ + cyl + year, my_mpg). Apply the summary() function to the model object, then return the coefficients table from the summary.\n\n\n# &gt;\n\n\nExtract the table after applying {papaja}’s apa_print() to my_model, then pass this to apa_table().\n\n\n# &gt;"
  },
  {
    "objectID": "code/37_annotating.html",
    "href": "code/37_annotating.html",
    "title": "Annotating plots",
    "section": "",
    "text": "Using the mpg data, create a scatterplot of highway and city fuel efficiencies. Create a title, subtitle, caption, and axes labels.\n\n\n# &gt;\n\n\nRepeat #1 adding a linear regression line. Use cor() to calculate the correlation coefficient for the correlation. Add it to the plot somewhere labeled and rounded to two decimals.\n\n\n# &gt;\n\n\nRepeat #1. Find the manufacturer and model of the data point with the highest city fuel efficiency. Label this point by drawing a line from the point to the text label and include the manufacturer and model (broken across two lines).\n\n\n# &gt;\n\n\nRepeat #1 drawing grey horizontal and vertical lines at 20 mpg for both axes underneath the data points. Add a lightpink rectangle under the points filling the upper right quandrant (&gt;20 for both axes).\n\n\n# &gt;\n\n\nCreate boxplots of fuel efficiency by class but order the class levels by mean highway fuel efficiency. At y = 10, add the sample size for each box (e.g., N=5, N=47, etc.).\n\n\n# &gt;"
  },
  {
    "objectID": "code/36_axes.html",
    "href": "code/36_axes.html",
    "title": "Adjusting axes",
    "section": "",
    "text": "Using the mpg data, create boxplots of highway fuel efficiency as a function of class.\n\n\n# &gt;\n\n\nZoom into the plot with y-axis limits of 15 and 40 without altering the data.\n\n\n# &gt;\n\n\nChange the y-axis limits to 15 and 40 but allow the statistical transformations to change the data.\n\n\n# &gt;\n\n\nReplot #1 but using a log10 scale.\n\n\n# &gt;\n\n\nReplot #1 but with y-axis limits running from 0 to 50 and with labels in increments of 5 but no minor grid lines.\n\n\n# &gt;\n\n\nReplot #1 but create separate panels based on year (as rows) and cylinders (as columns) and allowing the scales to vary across rows.\n\n\n# &gt;\n\n\nReplot #1 and assign it to hwy_plot and replot a similar version with city fuel efficiency named cty_plot. Then combine them into a compound plot labeled as subfigures A and B and save this figure on your computer as a PNG file.\n\n\n# &gt;"
  },
  {
    "objectID": "code/35_categories.html",
    "href": "code/35_categories.html",
    "title": "Plotting x-y data: categories",
    "section": "",
    "text": "Using the mpg data, create a data object called class_cyl that subsets only the compact and midsize class cars with 4 or 6 cylinders and makes cylinder number a factor. You should end up with 84 observations.\n\n\n# &gt;\n\n\nCreate an interaction plot from class_cyl with cylinder number on the x-axis, highway fuel efficiency on the y-axis, and separately colored lines for class. Spatially separate overlapping error bars.\n\n\n# &gt;\n\n\nRepeat interaction plot #2, reversing the roles of class and cylinder number by making class the x-axis and cylinder number the lines. Do the two plots communicate information differently? Which do you prefer?\n\n\n# &gt;\n\n\nTake the class_cyl data and calculate the mean and standard error for each combination of class and cylinder number levels. Note that you can calculate standard error by dividing the standard deviation by the square root of the sample size. Next, create a column that subtracts SE from mean for the lower bound and add SE to mean for the upper bound. Assign these means, standard errors, and lower and upper bounds to mean_mpg (you should have 4 observations and 6 variables).\n\n\n# &gt;\n\n\nReplicate plot #3 using the mean_mpg data set by plotting the means and bounds as error bars and include a line connecting across class. Is it identical to plot #3?\n\n\n# &gt;\n\n\nUsing class_cyl, calculate the mean highway fuel efficiency for each manufacturer and cylinder size. Plot a slopegraph of dashed lines for each manufacturer connecting the mean fuel efficiency for 4 and 6 cylinders. Overlay the mean and standard deviation across manufacturers for both levels of cylinder number.\n\n\n# &gt;\n\n\nUsing mpg, create a raincloud plot that includes a half density plot and half dot plot of highway fuel efficiency for each class. Adjust the bin width and dot size to produce a reasonable distribution of dots. Color the lines and shaded areas differently for each class, but remove the legend. Reduce the opacity of the shaded areas.\n\n\n# &gt;"
  },
  {
    "objectID": "code/34_timeseries.html",
    "href": "code/34_timeseries.html",
    "title": "Plotting x-y data: time series",
    "section": "",
    "text": "Using the mpg data, calculate the mean highway fuel efficiency for each number of cylinders and plot a line graph of fuel efficiency by cylinder number.\n\n\n# &gt;\n\n\nRepeat the previous plot but also group by class and plot separately colored lines for different classes.\n\n\n# &gt;\n\n\nCreate a new column called low_high that codes high fuel efficiency greater than or equal to 25 as 1 and less than 25 as 0. Plot low_high as a function of displacement with a bubble chart (no legend) and include a logistic regression curve and band.\n\n\n# &gt;\n\n\nPlot highway fuel efficiency for each class as points first, then add jitter, finding an appropriate amount of jitter to add.\n\n\n# &gt;\n\n\nRepeat plot #4 with a beeswarm plot.\n\n\n# &gt;"
  },
  {
    "objectID": "code/33_associations.html",
    "href": "code/33_associations.html",
    "title": "Plotting x-y data: associations",
    "section": "",
    "text": "Using the mpg data, create a scatterplot of the highway fuel efficiency and city fuel efficiency.\n\n\n# &gt;\n\n\nNow add a dashed reference line showing equivalent values for the two axes and set the aspect ratio to 1.\n\n\n# &gt;\n\n\nLooks like there is a possibility of overplotting. Turn this into a bubble chart with dot size scaling to the number of data points for each dot and make the dot colors steelblue.\n\n\n# &gt;\n\n\nAdd rugs to scatterplot #1 and change to minimal theme.\n\n\n# &gt;\n\n\nFrom scatterplot #1, color the dots by class, move the legend to the top left corner of the plot, and add marginal density plots.\n\n\n# &gt;\n\n\nCreate a data frame called mpg_num that only includes variables with numeric values using the where() function. Then remove the year column.\n\n\n# &gt;\n\n\nCreate correlation plots of the numeric variables in mpg_num in both base R and using {GGally}’s ggpairs() function.\n\n\n# &gt;\n\n\nCreate a correlation matrix of mpg_num with the cor() function. Then use ggcorrplot() from the {ggcorrplot} package to make a heatmap correlation plot with just the upper triangle of the matrix and using circles to represent correlation coefficient magnitude.\n\n\n# &gt;"
  },
  {
    "objectID": "code/32_barcharts.html",
    "href": "code/32_barcharts.html",
    "title": "Plotting amounts: barcharts and dot plots",
    "section": "",
    "text": "Using the mtcars data, create a barchart of the counts for each level of cylinder.\n\n\n# &gt;\n\n\nRepeat the barchart but stack the counts by gear.\n\n\n# &gt;\n\n\nRecreate this plot:\n\n\n\n# &gt;\n\n\nRepeat barchart #2 but set the position to “dodge”.\n\n\n# &gt;\n\n\nWhoa, what happened to 8 cylinders? Unfortunately, since there were only two levels of gear for 8 cylinders, it just split the bars in two. To hold the numbers of bars the same across all levels, you can set position to position_dodge(preserve = \"single\"). Try that.\n\n\n# &gt;\n\n\nWell, that’s better—the two bars are the same width as all of the other bars. But the 4 gears should show up as 0. To fix, we need to count the data first, find implicitly missing data, and plot using geom_col(). So first, find counts for the combinations of cylinders and gears. Then use complete() to find the implicitly missing combinations. Then replace the NAs with 0s. Then use geom_col() to plot these values with the position dodged.\n\n\n# &gt;\n\n\nMake a dotplot of the counts for each level of carb and plot carb on the y-axis and the count on the x-axis. Reminder that first you’ll need to count the observations in each level of carb before starting the plot.\n\n\n# &gt;\n\n\nRepeat dotplot #8 but order carb based on the counts from highest to lowest count.\n\n\n# &gt;"
  },
  {
    "objectID": "code/31_boxplots.html",
    "href": "code/31_boxplots.html",
    "title": "Plotting distributions: boxplots",
    "section": "",
    "text": "Using the penguins data, create a boxplot that shows penguin flipper length by island without outliers.\n\n\n# &gt;\n\n\nAdd the means and standard error for each boxplot.\n\n\n# &gt;\n\n\nSwitch from standard errors to confidence intervals, increase the size of the point, and color the box shading chocolate.\n\n\n# &gt;\n\n\nFill the boxplots with color separately for each island and remove the legend.\n\n\n# &gt;\n\n\nCreate a boxplot to show how flipper length differs for each species by island.\n\n\n# &gt;\n\n\nRecreate the boxplot #5 as a violin plot with a white background.\n\n\n# &gt;"
  },
  {
    "objectID": "code/30_histograms.html",
    "href": "code/30_histograms.html",
    "title": "Plotting distributions: histograms",
    "section": "",
    "text": "Using the mtcars data, create a histogram of the fuel efficiency values.\n\n\n# &gt;\n\n\nNot a great histogram. Mess with the number of bins until you get a nice histogram.\n\n\n# &gt;\n\n\nNow change the bin width to generate the same plot as #2.\n\n\n# &gt;\n\n\nUsing the same binwidth from #3, plot a histogram with lightseagreen lines and aquamarine3 shaded areas. Then overlay a density plot with a aquamarine4 line with width 2.\n\n\n# &gt;\n\n\nWhat is the difference between a frequency polygon and a density plot?\nMake a density plot with bandwidth of 3 and separate line colors for different cylinder levels.\n\n\n# &gt;\n\n\nRepeat #6 but also include separate colors for the shaded areas with a transparency of 0.5. Use viridis colors for both lines and shaded areas, and reverse the direction of the colors where 4 is yellow, 6 is greenish, and 8 is purplish.\n\n\n# &gt;"
  },
  {
    "objectID": "code/29_color.html",
    "href": "code/29_color.html",
    "title": "Color",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight with color based on the number of cylinders.\n\n\n# &gt;\n\n\nRepeat the scatterplot but use scale_color_brewer() to set the palette to Set1.\n\n\n# &gt;\n\n\nWhy did you use scale_color_brewer() not scale_fill_brewer() or scale_color_distiller()?\nRepeat scatterplot #1 but use scale_color_manual() to set the three colors to red, green, and blue.\n\n\n# &gt;\n\n\nFind three colors (either names or hex codes), and repeat scatterplot #4 with your own colors.\n\n\n# &gt;\n\n\nUsing the mtcars data, create a scatterplot of the fuel efficiency as a function of weight with color based on horsepower using the BuPu palette and reverse the direction of the gradient.\n\n\n# &gt;\n\n\nCreate a new column in mtcars that centers and scales displacement with the scale() function. Create a scatterplot of fuel efficiency as a function of weight with color based on the rescaled displacement, using a diverging scale of your choice.\n\n\n# &gt;"
  },
  {
    "objectID": "code/28_themes.html",
    "href": "code/28_themes.html",
    "title": "Design and themes",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight with color based on the number of cylinders.\n\n\n# &gt;\n\n\nRepeat the scatterplot but with classic, bw, and dark themes.\n\n\n# &gt;\n\n\nRepeat the scatterplot from #1 but with no minor grid lines and no legend.\n\n\n# &gt;\n\n\nRepeat the scatterplot from #1 but no minor grid lines for the x-axis (keep them for the y-axis) and move the legend inside the plot area and remove the legend title.\n\n\n# &gt;\n\n\nRepeat the scatterplot from #1 but make the major y-axis grid lines black dashed lines and change the text font to 12 point Times font.\n\n\n# &gt;\n\n\nCreate a version of scatterplot #1 that minimizes the data-ink ratio by reducing non-data-ink.\n\n\n# &gt;"
  },
  {
    "objectID": "code/27_grammar2.html",
    "href": "code/27_grammar2.html",
    "title": "Grammar of graphics II",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight.\n\n\n# &gt;\n\n\nRepeat the scatterplot, but make the points violet open squares of size 5.\n\n\n# &gt;\n\n\nRepeat the scatterplot but with separate colors for cylinder levels.\n\n\n# &gt;\n\n\nWhy does the legend look like that? Fix it so there are separate colors for cylinder levels.\n\n\n# &gt;\n\n\nOverlay separate regression lines for each cylinder level.\n\n\n# &gt;\n\n\nOverlay a single firebrick regression line over the points with a firebrick1-colored confidence band.\n\n\n# &gt;\n\n\nPlot the mean and standard error of the mean of fuel efficiency for each level of cylinder and color them sienna.\n\n\n# &gt;"
  },
  {
    "objectID": "code/26_grammar1.html",
    "href": "code/26_grammar1.html",
    "title": "Grammar of graphics I",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight.\n\n\n# &gt;\n\n\nRepeat the plot but only with vehicles having 4 or 6 cylinders.\n\n\n# &gt;\n\n\nRepeat plot #1 but add a smooth line underneath the data points.\n\n\n# &gt;\n\n\nMake a boxplot of fuel efficiency for each cylinder size.\n\n\n# &gt;\n\n\nAdd ” cylinders” to the end of each value in the cylinder column of data and replot #4.\n\n\n# &gt;\n\n\nReplot #4 ordering the cylinders such that the median mpg increases from left to right.\n\n\n# &gt;"
  },
  {
    "objectID": "code/25_iteration.html",
    "href": "code/25_iteration.html",
    "title": "Iteration",
    "section": "",
    "text": "Write a for loop that calculates the mean bill length for each species in the penguins data set (don’t use group_by()) and saves them as species_means.\n\n\n# &gt;\n\n\nTurn #1 into a function called species_mean that lets the user determine which variable to calculate the mean over.\n\n\n# &gt;\n\n\nCreate a list penguins_island that separates the penguins data by island.\n\n\n# &gt;\n\n\nApply map() to find the number of observations for each year.\n\n\n# &gt;\n\n\nApply map() to calculate the mean body weight for each island.\n\n\n# &gt;\n\n\nRework #5 to return a numeric vector with values rounded to 1 decimal place.\n\n\n# &gt;"
  },
  {
    "objectID": "code/24_functions.html",
    "href": "code/24_functions.html",
    "title": "Functions",
    "section": "",
    "text": "Write a function called mystring that takes a vector as an argument and returns the first three characters from the string. Test it on words[1:10].\n\n\n# &gt;\n\n\nAdd an argument to mystring() that allows the user to control how many of the first characters should be returned. Test it on words[1:10] with 5 characters.\n\n\n# &gt;\n\n\nSet the default number of characters returned by mystring() to be 3 and test that the default works and that you can override the default.\n\n\n# &gt;\n\n\nAdd a step that checks whether the inputted vector is a character string. If it is, continue to return the truncated strings. If the vector is not a character string, use the stop() function to stop the computation and return a message to the console telling the user that the vector was not a character vector. Test your function with a character vector, a numeric vector, and a logical vector.\n\n\n# &gt;\n\n\nCreate a function called parse_my_vector that does the following:\n\n\nAllows users to input a vector and a response to the argument type that determines whether the vector is a numeric (\"num\"), character (\"char\"), or logical (\"logical\") vector. There should be no default value. If the user response does not match any of these three strings, stop with a message asking the user to specify one of the three strings.\nFor each type, checks whether the vector is actually the type specified by the user and stops with a message if they do not match.\nFor numeric vectors, multiplies by 10. For character vectors, extracts the first three characters. For logical vectors, returns the number of TRUE responses.\nBefore returning output, prints a message thanking the user.\nReturns the original vector and output of the functions described above.\n\n\n# &gt;\n\n\nCheck the following with parse_my_vector():\n\n\nx = 1:10, type = “num”\nx = 1:10, type = “char”\nx = words[1:10], type = “num”\nx = words[1:10], type = “char”\nx = c(TRUE, FALSE, TRUE), type = “num”\nx = c(TRUE, FALSE, TRUE), type = “logical”\nx = 1:10, type = “nums”\n\n\n# &gt;"
  },
  {
    "objectID": "code/23_dates.html",
    "href": "code/23_dates.html",
    "title": "Dates and times",
    "section": "",
    "text": "For these exercises, we’ll use the dates data set.\n\nLoad tidyverse, import dates.csv to dates, and view the data set.\n\n\n# &gt;\n\n\nConvert birth_date to a date object and resave dates.\n\n\n# &gt;\n\n\nCreate a column called time1 that converts test1 to datetime and change the time zone to “America/Chicago”.\n\n\n# &gt;\n\n\nCalculate each participant’s age in years at the time of test 1, rounded to 1 decimal place, stored in age and resave dates.\n\n\n# &gt;\n\n\nCalculate the number of days between test 1 and test 2 for each participant and label this column test_diff (and resave dates).\n\n\n# &gt;\n\n\nCreate dates2 that subsets the participants who were born after January 1, 1970.\n\n\n# &gt;\n\n\nCreate a column named diff_text that writes the following sentence for each participant in dates2: “Participant [insert id] (age: [insert age]) had test 1 on [insert test1] and test 2 on [insert test2], which were [insert test_diff] days apart.”\n\n\n# &gt;"
  },
  {
    "objectID": "code/22_factors.html",
    "href": "code/22_factors.html",
    "title": "Factors",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nLoad tidyverse, import dog_breed_traits_clean.csv to traits.\n\n\n# &gt;\n\n\nConvert both coat_type and coat_length into factors using across() and save as traits2.\n\n\n# &gt;\n\n\nCheck the levels for both columns, one using a pipe and one without using a pipe.\n\n\n# &gt;\n\n\nReorder the levels for coat_length to be Short, Medium, Long (reassigned to traits2) and then check the levels.\n\n\n# &gt;\n\n\nReorder the levels for coat_type to be in the order of the most to least frequent coat type and then check the levels.\n\n\n# &gt;\n\n\nRelabel coat_length to be Stubby, Mid, and Lush rather than Short, Medium, and Long.\n\n\n# &gt;\n\n\nThe new AKC standard subsumes Rough coats with Wiry coats and Silky with Wavy. Please update the coat_type variable accordingly.\n\n\n# &gt;"
  },
  {
    "objectID": "code/21_patterns.html",
    "href": "code/21_patterns.html",
    "title": "Matching patterns",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nLoad tidyverse, import dog_breed_traits_clean.csv to traits, and extract the breed column into an object called breeds that randomly shuffles the breeds using 12 as a seed for randomization.\n\n\n# &gt;\n\n\nView the breeds ending with the letter “s”.\n\n\n# &gt;\n\n\nCreate a logical vector showing whether breeds have at least two words in their names.\n\n\n# &gt;\n\n\nExtract the hounds (but don’t release them). That is, return a vector of all breeds that include the string “hound” or “Hound”.\n\n\n# &gt;\n\n\nExtract the breeds that include the following pattern “&lt;wildcard&gt;ep”.\n\n\n# &gt;\n\n\nOK, maybe English Buttdragger isn’t the proper AKC name for this breed. Replace English Buttdragger with English Chaser.\n\n\n# &gt;\n\n\nReplace all instances of “English” with “British” and then return the breeds that include “English” or “British” in them (to check our work).\n\n\n# &gt;\n\n\nExtract the Spaniels and then separate the breed names into different strings for each word and create a matrix out of it.\n\n\n# &gt;"
  },
  {
    "objectID": "code/20_strings.html",
    "href": "code/20_strings.html",
    "title": "Strings",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nLoad tidyverse and import dog_breed_traits_clean.csv to traits.\n\n\n# &gt;\n\n\nReturn the first ten letters of the alphabet in upper case.\n\n\n# &gt;\n\n\nCreate this character string and assign it to mystring: The elephant said “Hello” then ‘Bye!’ Then view how it would be printed.\n\n\n# &gt;\n\n\nFind how many characters are in mystring.\n\n\n# &gt;\n\n\nCreate a vector of the first four characters of the coat_length column from traits.\n\n\n# &gt;\n\n\nConvert the breed column of traits to sentence case.\n\n\n# &gt;\n\n\nCreate series of sentences using breed and coat_length that states “[insert breed name] have a [insert coat length] coat” that uses the proper cases.\n\n\n# &gt;\n\n\nIn the mtcars data set, extract the first two digits of the mpg variable and the last three digits of the car names and combine them into a single string.\n\n\n# &gt;\n\n\nPrint the fruit data set, then capitalize all first word letters in the data set, then capitalize all words in the data set.\n\n\n# &gt;"
  },
  {
    "objectID": "code/19_numbers.html",
    "href": "code/19_numbers.html",
    "title": "Numbers",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits and dog breed popularity rankings data sets.\n\nLoad tidyverse and import dog_breed_traits_clean.csv to traits.\n\n\n# &gt;\n\n\nCreate a column of per-row means over all rating columns called mean_ratings and assign to traits2.\n\n\n# &gt;\n\n\nConvert mean_ratings to a proportion in a column called pmean_ratings and add to traits2.\n\n\n# &gt;\n\n\nApply a natural log transformation to the pmeans_ratings vector.\n\n\n# &gt;\n\n\nRound pmean_ratings to two decimal places.\n\n\n# &gt;\n\n\nConvert pmean_ratings to scientific notation.\n\n\n# &gt;\n\n\nSum up the total grooming ratings for each coat type.\n\n\n# &gt;\n\n\nAdd inline R code to the following sentence in R Markdown to say how many rows have NA for grooming:\n\nWe are missing grooming data for [insert inline R code] breeds."
  },
  {
    "objectID": "code/18_mergingrows.html",
    "href": "code/18_mergingrows.html",
    "title": "Merging rows",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits and dog breed popularity rankings data sets.\n\nLoad tidyverse, import dog_breed_traits_clean.csv to traits, import dog_breed_ranks.csv to ranks, and import dog_breed_ranks.csv to popularity.\n\n\n# &gt;\n\n\nFirst, set a random seed by using set.seed(2). Then create a subset of ranks that is a random selection of 10% of the rows, sort by breed name, and assign to ranks2.\n\n\n# &gt;\n\n\nUse a filtering join to return the subset of traits that matches the breeds in ranks2 and assign this to traits2.\n\n\n# &gt;\n\n\nUse a filtering join to return the subset of traits that excludes the breeds in ranks2.\n\n\n# &gt;\n\n\nNow we want to filter traits based on breeds in popularity. Notice that the breeds column in popularity is called Breed. This is problematic because the breed column in traits is called breed and names are case-sensitive. Use join_by() to filter traits by breeds in popularity. How many rows are there?\n\n\n# &gt;\n\n\nUse filter() (not joins) to return the subset of traits that excludes the breeds in ranks2.\n\n\n# &gt;\n\n\nAppend traits2 to the bottom of itself.\n\n\n# &gt;\n\n\nAppend traits2 to the right of itself.\n\n\n# &gt;\n\n\nAppend traits2 to the right of ranks2.\n\n\n# &gt;\n\n\nWhy is this not a good idea? What would be a better way to achieve this?\n\n\n# &gt;"
  },
  {
    "objectID": "code/17_mergingcolumns.html",
    "href": "code/17_mergingcolumns.html",
    "title": "Merging columns",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set along with the data on breed popularity rankings.\n\nLoad tidyverse, download and import dog_breed_traits_clean.csv to traits, and import dog_breed_ranks.csv to ranks. Make sure to download both files from the website, as they have changed or are new.\n\n\n# &gt;\n\n\nWhich breeds differ between traits and ranks?\n\n\n# &gt;\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes breeds shared by both data sets. How many rows are there?\n\n\n# &gt;\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes all breeds included in either data set. How many rows are there?\n\n\n# &gt;\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes only breeds included in traits. How many rows are there?\n\n\n# &gt;\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes only breeds included in ranks. How many rows are there?\n\n\n# &gt;\n\n\nMake table4a and table4b tidy then join them to replicate table1.\n\n\n# &gt;"
  },
  {
    "objectID": "code/16_separating.html",
    "href": "code/16_separating.html",
    "title": "Separating and uniting data",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nLoad tidyverse, import data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv, and assign it to traits.\n\n\n# &gt;\n\n\nCreate traits2 which adds a coat column that combines coat_type and coat_length into single column delimited by “-”.\n\n\n# &gt;\n\n\nSplit the coat column into type and length and keep the original coat column.\n\n\n# &gt;\n\n\nCreate traits3 from traits that (1) removes the coat columns, (2) turns the ratings columns into long format, and (3) removes the children row for Bulldogs.\n\n\n# &gt;\n\n\nCreate traits4 from traits3 that ensures a complete data set with all five ratings for all breeds (and fills in missing combinations with NA) and check for the missing Bulldog children row.\n\n\n# &gt;\n\n\nHow could we copy the rating from the previous row into the Bulldog children row to replace the NA? (Note this is not a good idea in this case!)\n\n\n# &gt;\n\n\nFrom traits, generate all combinations of coat type and length observed in the data, excluding NA.\n\n\n# &gt;\n\n\nFrom traits, generate all possible combinations of coat type and length, excluding NA.\n\n\n# &gt;"
  },
  {
    "objectID": "code/15_pivoting.html",
    "href": "code/15_pivoting.html",
    "title": "Pivoting data",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nImport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv and assign to traits.\n\n\n# &gt;\n\n\nCreate traits2 where we delete the coat columns, so we only have breed and ratings data.\n\n\n# &gt;\n\n\nIs traits2 tidy?\nIs traits2 in wide or long format?\nReshape traits2 so that all of the ratings scores are in a single column called rating with a column labeling what kind of rating it is called scale. Assign this to traits3.\n\n\n# &gt;\n\n\nHow would we check if traits3 has the expected number of rows?\nCreate traits4 by removing the rows with affectionate, children, and other_dogs as values of scale.\n\n\n# &gt;\n\n\nSpread out the data into wide format with separate columns for the shedding and grooming data, then create a new column diff that subtracts grooming from shedding ratings.\n\n\n# &gt;"
  },
  {
    "objectID": "code/14_summarizing.html",
    "href": "code/14_summarizing.html",
    "title": "Summarizing rows",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nImport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv and assign to traits.\n\n\n# &gt;\n\n\nWhat is the overall mean rating for affectionate?\n\n\n# &gt;\n\n\nWhat is the overall mean rating for all rating columns ignoring NAs?\n\n\n# &gt;\n\n\nHow many breeds are there in each coat type?\n\n\n# &gt;\n\n\nWhat is the median grooming rating for each coat type?\n\n\n# &gt;\n\n\nWhat is the lowest rating per coat length for each of the rating columns, ignoring NAs?\n\n\n# &gt;\n\n\nWhat are the sample size, mean, and standard deviation of shedding ratings for medium coat length dogs per coat type sorted from largest to smallest sample size and only including coat types with 5 or more samples?\n\n\n# &gt;\n\n\nCalculate each breed’s mean rating across all ratings columns and return a data frame with the highest rating for each coat type. Don’t forget to undo rowwise() with ungroup() before further calculations.\n\n\n# &gt;"
  },
  {
    "objectID": "code/13_filtering.html",
    "href": "code/13_filtering.html",
    "title": "Filtering rows",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nImport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv and assign to traits.\n\n\n# &gt;\n\n\nView dogs only with short coats.\n\n\n# &gt;\n\n\nView a data frame excluding dogs with short coats.\n\n\n# &gt;\n\n\nView dogs with double or silky coats.\n\n\n# &gt;\n\n\nView dogs with double or silky coats and shedding ratings 3 or below.\n\n\n# &gt;\n\n\nView dogs with NA for coat_type.\n\n\n# &gt;\n\n\nView dogs with NA for any column.\n\n\n# &gt;\n\n\nView dogs not missing any data.\n\n\n# &gt;\n\n\nView dogs sorted by breed name.\n\n\n# &gt;\n\n\nView dogs sorted by coat type then coat length then affectionate rating.\n\n\n# &gt;"
  },
  {
    "objectID": "code/12_piping.html",
    "href": "code/12_piping.html",
    "title": "Piping",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nCreate a pipeline to do all of the following:\n\n\nassign pipeline to traits\nimport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv\nsubset only the columns Breed through Coat Length\nremove the Drooling Level column\n\n\n# &gt;\n\n\nRename the column names to \"breed\", \"affectionate\", \"children\", \"other_dogs\", \"shedding\", \"grooming\", \"coat_type\", \"coat_length\".\n\n\n# &gt;\n\n\nDo the following using traits.\n\n\nassign to traits2\nrescale all of the ratings columns by subtracting 1 from all of the values\ncreate a new column called coat that combines the coat_type and coat_length columns by pasting the values of those two columns separated by -\ncreate a new column called shed that dichotomizes shedding such that values of 3 and above are “A lot” and values below 3 are “Not much” and places the new column after shedding\ncalculate the mean rating for the children and other_dogs columns in a column called mean_rating and place it after other_dogs\n\n\n# &gt;\n\n\nDo the following using traits2.\n\n\nassign to coat_grooming\nsubset only the grooming and coat_type columns\nrun a linear model (lm) using the formula grooming ~ coat_type (remember to use a placeholder for the data)\napply the summary() function\nprint the results to console\n\n\n# &gt;"
  },
  {
    "objectID": "code/11_mutating.html",
    "href": "code/11_mutating.html",
    "title": "Mutating columns",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set, so import that from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv (if you don’t already have it) and assign it to traits.\n\n# &gt;\n\n\nView traits to see what it looks like.\n\n\n# &gt;\n\n\nReassign traits with only the columns Breed through Coat Length.\n\n\n# &gt;\n\n\nReassign traits removing the Drooling Level column. That’s gross.\n\n\n# &gt;\n\n\nWhat terrible column names! Reassign traits and change the column names to \"breed\", \"affectionate\", \"children\", \"other_dogs\", \"shedding\", \"grooming\", \"coat_type\", \"coat_length\". Note, use the colnames() function rather than select() or rename() since you already have the full vector of names.\n\n\n# &gt;\n\n\nThe ratings are supposed to run from 0 to 4 rather than 1 to 5. Change the affectionate column by subtracting 1 from the original numbers to rescale the values. Don’t reassign traits.\n\n\n# &gt;\n\n\nActually, all of the ratings need to be rescaled. Subtract 1 from all of the ratings columns by using across().\n\n\n# &gt;\n\n\nCreate a new column called coat that combines the coat_type and coat_length columns by pasting the values of those two columns separated by -.\n\n\n# &gt;\n\n\nCreate a new column called shed that dichotomizes shedding such that values of 3 and above are “A lot” and values below 3 are “Not much”. Do you need to account for missing data?\n\n\n# &gt;\n\n\nUse rowwise() to calculate the mean rating for the children and other_dogs columns in a column called mean_rating.\n\n\n# &gt;\n\n\nCreate a column called coat_type2 that categorizes the coat_type values in the following way and puts it after coat_type:\n\n\n“very petable” = “Smooth”, “Silky”, “Wavy”\n“petable” = “Double”, “Curly”\n“not petable” = “Wiry”, “Hairless”, “Rough”, “Corded”\n\n\n# &gt;"
  },
  {
    "objectID": "code/10_selecting.html",
    "href": "code/10_selecting.html",
    "title": "Selecting columns",
    "section": "",
    "text": "For these exercises, we’ll use the iris data set build into base R.\n\nView iris to see what it looks like.\n\n\n# &gt;\n\n\nReturn a data frame with only the sepal data using inclusion.\n\n\n# &gt;\n\n\nReturn a data frame with only the sepal data using a helper function.\n\n\n# &gt;\n\n\nReturn a data frame with the sepal and petal data using a helper function.\n\n\n# &gt;\n\n\nReturn a data frame with the sepal and petal data using exclusion.\n\n\n# &gt;\n\n\nMove Species to be the first column using select() and a helper function.\n\n\n# &gt;\n\n\nMove Species to be the first column using relocate().\n\n\n# &gt;\n\n\nRename Species to species using select().\n\n\n# &gt;\n\n\nRename Species to species using rename().\n\n\n# &gt;"
  },
  {
    "objectID": "code/09_validating.html",
    "href": "code/09_validating.html",
    "title": "Validating data",
    "section": "",
    "text": "For these exercises, we’ll use the mtcars data set build into base R.\n\nWhat are the dimensions of mtcars?\n\n\n# &gt;\n\n\nIn one line of code, view the data types for all of the columns in mtcars.\n\n\n# &gt;\n\n\nWhat is the range of values for the mpg column?\n\n\n# &gt;\n\n\nWhat are all of the possible values used in gear?\n\n\n# &gt;\n\n\nCheck whether the value 5 is found in the carb column.\n\n\n# &gt;\n\n\nDo any columns have missing values?\n\n\n# &gt;\n\n\nWhat is the 3rd quartile for mpg?\n\n\n# &gt;\n\n\nCheck whether all horsepower (hp) values fall between 50 and 300. Which row numbers fall out of this range?\n\n\n# &gt;\n\n\nMake a codebook for mtcars.\n\n\n# &gt;"
  },
  {
    "objectID": "code/08_importing.html",
    "href": "code/08_importing.html",
    "title": "Importing data",
    "section": "",
    "text": "Download https://jeffreyrstevens.quarto.pub/dpavir/data/newdata.csv and save it in your data/ directory.\nImport newdata.csv and name it newdata using read.csv().\n\n\n# &gt;\n\n\nImport https://jeffreyrstevens.quarto.pub/dpavir/data/newdata2.csv directly from the URL using readr::read_csv().\n\n\n# &gt;\n\n\nRepeat the previous import of newdata2.csv, but add the arguments col_select = c(\"Breed\", \"links\") and show_col_types = FALSE and name it newdata3.\n\n\n# &gt;\n\n\nExport the newdata3 data as a CSV file to your data/ directory.\n\n\n# &gt;"
  },
  {
    "objectID": "code/07_datastructures.html",
    "href": "code/07_datastructures.html",
    "title": "Data structures",
    "section": "",
    "text": "Make a sequence from 0 to 100 in steps of 10.\n\n# &gt;\n\nCreate a repetition of “yes” and “no” with 10 instance of each, alternating between the two. Then make one with 10 “yes” and then 10 “no”.\n\n# &gt;\n\nAdd the argument n = 10 to head(mtcars). What does this do?\n\n# &gt;"
  },
  {
    "objectID": "code/07_datastructures.html#in-class-coding",
    "href": "code/07_datastructures.html#in-class-coding",
    "title": "Data structures",
    "section": "",
    "text": "Make a sequence from 0 to 100 in steps of 10.\n\n# &gt;\n\nCreate a repetition of “yes” and “no” with 10 instance of each, alternating between the two. Then make one with 10 “yes” and then 10 “no”.\n\n# &gt;\n\nAdd the argument n = 10 to head(mtcars). What does this do?\n\n# &gt;"
  },
  {
    "objectID": "code/07_datastructures.html#extra-coding-practice",
    "href": "code/07_datastructures.html#extra-coding-practice",
    "title": "Data structures",
    "section": "Extra coding practice",
    "text": "Extra coding practice\n\nVectors\nCreate a vector called dog_names with the values Bella, Daisy, and Max.\n\n# &gt;\n\nCreate a vector called sex with the values Female, Male, and Male.\n\n# &gt;\n\nUse the index operator to print to console only Daisy and Max from dog_names.\n\n# &gt;\n\nReplace the Daisy entry with Luna and print dog_names to console.\n\n# &gt;\n\n\n\nLists\nCopy/paste and run this code: (mylist &lt;- list(a = 1:4, b = c(4, 3, 8, 5), c = LETTERS[10:15], d = c(\"yes\", \"yes\")))\n\n# &gt;\n\nCheck the data types for each list element individually.\n\n# &gt;\n\nCheck the data types for each list element with one command.\n\n# &gt;\n\nCombine list elements a and b into a single vector.\n\n# &gt;\n\n\n\nData frames\nCreate a data frame called mydf with three columns: x, y, and z and five rows. For x assign any five numbers, for y assign any five character strings, and for z assign any five logical values.\n\n# &gt;\n\nCreate a data frame called dogs that combines the dog_names and sex vectors and print to console.\n\n# &gt;\n\nPrint to console just Luna’s row.\n\n# &gt;\n\nPrint to console the number of rows in dogs.\n\n# &gt;"
  },
  {
    "objectID": "code/06_datatypes.html",
    "href": "code/06_datatypes.html",
    "title": "Data types",
    "section": "",
    "text": "aa &lt;- 3; bb &lt;- 3L; cc &lt;- \"3\"; dd &lt;- \"TRUE\"; ee &lt;- TRUE; ff &lt;- \"NA\"; gg &lt;- NA\n\n# &gt;"
  },
  {
    "objectID": "code/06_datatypes.html#creating-objects",
    "href": "code/06_datatypes.html#creating-objects",
    "title": "Data types",
    "section": "",
    "text": "aa &lt;- 3; bb &lt;- 3L; cc &lt;- \"3\"; dd &lt;- \"TRUE\"; ee &lt;- TRUE; ff &lt;- \"NA\"; gg &lt;- NA\n\n# &gt;"
  },
  {
    "objectID": "code/06_datatypes.html#checking-data-types",
    "href": "code/06_datatypes.html#checking-data-types",
    "title": "Data types",
    "section": "Checking data types",
    "text": "Checking data types\n\nGuess what data type each object is then check it.\n\n# &gt;\n\n\n\nHow do we test if aa is an integer?\n\n# &gt;\n\n\n\nWhat will is.logical(dd) return?\n\n# &gt;\n\n\n\nHow do we test if ff and gg are NA?\n\n# &gt;"
  },
  {
    "objectID": "code/06_datatypes.html#checking-if-objects-are-the-same",
    "href": "code/06_datatypes.html#checking-if-objects-are-the-same",
    "title": "Data types",
    "section": "Checking if objects are the same",
    "text": "Checking if objects are the same\n\nAre aa and bb the same? How do we test this?\n\n# &gt;\n\n\n\nWhat about aa and cc?\n\n# &gt;\n\n\n\nA safer comparison tool is identical(). Test if aa and bb are identical. Then try aa and cc.\n\n# &gt;\n\n\n\nNow see if aa is identical to 3 and if bb is identical to 3L.\n\n# &gt;"
  },
  {
    "objectID": "code/03_coding_answers.html",
    "href": "code/03_coding_answers.html",
    "title": "Coding basics",
    "section": "",
    "text": "Let’s go to R’s console, which is the direct connection to the R engine. In the console, you give R a command, and it returns the output."
  },
  {
    "objectID": "code/03_coding_answers.html#assignment",
    "href": "code/03_coding_answers.html#assignment",
    "title": "Coding basics",
    "section": "Assignment",
    "text": "Assignment\nRemember our text string with our names?\n\"My name is Jeff!\"\nIt is repetitive to have to copy/paste text. We can assign things to objects, which store the contents in a variable. The assignment operator &lt;- assigns the value of the right hand side to the object on the left hand side. Use the &lt;- operator to assign the name text to an object called my_name.\n\nmy_name &lt;- \"My name is Jeff!\"\n\nNow print the contents of my_name by just typing it into the console.\n\nmy_name\n\n[1] \"My name is Jeff!\"\n\n\nNow apply the toupper() function to my_name rather than the actual character string.\n\ntoupper(my_name)\n\n[1] \"MY NAME IS JEFF!\"\n\n\nHow do we find out all of the arguments for the toupper() function?\nLet’s specify the argument names not just the value.\n\ntoupper(x = my_name)\n\n[1] \"MY NAME IS JEFF!\"\n\n\nPress the up arrow to navigate to the assignment command and change the object name to something different."
  },
  {
    "objectID": "code/03_coding_answers.html#names",
    "href": "code/03_coding_answers.html#names",
    "title": "Coding basics",
    "section": "Names",
    "text": "Names\nWhy did I assign the text to the object my_name and not, for example, names?\nWhat all is wrong with the file name Qualtrics experiment 3 ~ 01/05/22 [final_FINAL].xlsx?\nWhat would be a better name for this file?\nWhy is this date problematic? 01/05/22\nWhat would be an ISO 8601 format for this date?\nWhy is it useful to include dates in files names?"
  },
  {
    "objectID": "code/01_introduction_answers.html",
    "href": "code/01_introduction_answers.html",
    "title": "Introduction",
    "section": "",
    "text": "Let’s go to R’s console, which is the direct connection to the R engine. In the console, you give R a command, and it returns the output."
  },
  {
    "objectID": "code/01_introduction_answers.html#numerical-operations",
    "href": "code/01_introduction_answers.html#numerical-operations",
    "title": "Introduction",
    "section": "Numerical operations",
    "text": "Numerical operations\nR can be a very fancy calculator. Let’s do some calculations by entering numerical operations into the console. How many seconds are there in a year?\n\n60 * 60 * 24 * 365\n\n[1] 31536000\n\n\nOn average, how many days are in each month of a leap year?\n\n 366 / 12\n\n[1] 30.5"
  },
  {
    "objectID": "code/01_introduction_answers.html#text",
    "href": "code/01_introduction_answers.html#text",
    "title": "Introduction",
    "section": "Text",
    "text": "Text\nR also can store, manipulate, and return text. But working with text requires wrapping the characters in quotation marks (either \" or '). Type this out and replace &lt;name&gt; with your name: \"My name is &lt;name&gt;!\".\n\n\"My name is Jeff!\"\n\n[1] \"My name is Jeff!\"\n\n\nYou can also apply functions to text. If we want to yell our names, let’s convert the string of characters to upper case with the toupper() function. Put the previous text inside the parentheses of toupper().\n\ntoupper(\"My name is Jeff!\")\n\n[1] \"MY NAME IS JEFF!\"\n\n\nPress the up arrow ⬆️ to place previous commands in the console. Navigate to the previous command and change the text a bit."
  },
  {
    "objectID": "code/01_introduction_answers.html#packages",
    "href": "code/01_introduction_answers.html#packages",
    "title": "Introduction",
    "section": "Packages",
    "text": "Packages\nIf you haven’t already, install the {palmerpenguins} and {tidyverse} packages. Remember how to do that?\n\ninstall.packages(c(\"palmerpenguins\", \"tidyverse\"))\n\nNow that we have installed the {palmerpenguins} package, we want to look at the penguins data set from that package. What do we need to do first to get access to things in the package?\n\nlibrary(palmerpenguins)\n\nView the data set by typing penguins into the console.\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "code/01_introduction_answers.html#plot-data",
    "href": "code/01_introduction_answers.html#plot-data",
    "title": "Introduction",
    "section": "Plot data",
    "text": "Plot data\nExcellent! Let’s say we want to make a scatterplot of the bill length vs. the bill depth for all birds. We can use the plot() function for this.\n\nplot(bill_length_mm ~ bill_depth_mm, data = penguins)\n\n\n\n\n\n\n\n\nHey, hey! We have a plot! 📊 Sweet! We’ve viewed and plotted data. Well done! 🎉 💪"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "",
    "text": "MWF 3:30-4:30pm\nBurnett 80\nJeff Stevens (he/him)\nVersion 2025-01-07"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Course description",
    "text": "Course description\nThis course will introduce students to the fundamental concepts and methods used in the R statistical software package (focusing on the tidyverse perspective) to process, visualize, and disseminate data."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Prerequisites",
    "text": "Prerequisites\nPSYC 350 or equivalent course in introductory research design and analysis. No previous coding experience is required."
  },
  {
    "objectID": "syllabus.html#course-objectives",
    "href": "syllabus.html#course-objectives",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Course objectives",
    "text": "Course objectives\n\nLearn how to import, process, and plot data in R using tidyverse functions\nGain a basic understanding of general programming principles applied to data preparation, analysis, and visualization\nApply principles of good data visualization to plot data in an informative way\nProduce reproducible manuscripts and presentations with R code embedded"
  },
  {
    "objectID": "syllabus.html#course-expectations",
    "href": "syllabus.html#course-expectations",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Course expectations",
    "text": "Course expectations\nThe primary aim of this course is to teach you how to use R. Therefore, reading the assigned texts in advance, attending class, and participating in discussions and exercises is integral to this course and expected. Learning R follows the ‘use it or lose it’ mantra. Plan on working on it a little bit almost every day. Please don’t get behind, as we move quickly through the course, and much of what we learn is cumulative."
  },
  {
    "objectID": "syllabus.html#student-hours",
    "href": "syllabus.html#student-hours",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Student hours",
    "text": "Student hours\nJeff has time to meet with students Tuesday mornings from 10-11am and Wednesday afternoons from 1-2pm in his office at B83 East Stadium (CB3)."
  },
  {
    "objectID": "syllabus.html#computing-requirements",
    "href": "syllabus.html#computing-requirements",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Computing requirements",
    "text": "Computing requirements\nYou will need to bring a fully charged laptop to each class meeting to run in-class coding. While we will not be using very large data sets or running massive computations, having a faster computer will allow you to quickly proceed through the coding. On this laptop, you will need to install R, RStudio, and a number of R packages."
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Readings",
    "text": "Readings\nThis course will draw from a number of resources, primarily:\n\nHadley Wickham & Garrett Grolemund’s R for Data Science 1st edition.\nHadley Wickham, Garrett Grolemund, and Mine Çetinkaya-Rundel’s R for Data Science 2nd edition.\nClause Wilke’s Fundamentals of Data Visualization.\n\nOther readings are available in the course schedule."
  },
  {
    "objectID": "syllabus.html#assignments",
    "href": "syllabus.html#assignments",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Assignments",
    "text": "Assignments\n\nLearning journal\nAs you learn R, you will pick up all kinds of little gems to help you use it. For example, to add the pipe syntax |&gt; (something you’ll be doing a lot in the tidyverse), you can simply type Ctrl/Cmd-Shift-M. Keep a journal of these little tricks/hints that you are most excited about to submit at the end of the course. I highly recommend posting them on social media throughout the semester.\n\n\nExercises\nMost class meetings will be followed with sets of exercises to help you practice implementing the concepts discussed. These will be assessed as complete or incomplete. \n\n\nCheck-ins\nAt the end of each module, there will be a summative assignment checking that you understand that module’s material.\n\n\nProjects\nThe aim of this course is for you to be able to use R to process, visualize, and disseminate your data. Therefore, there will be two projects where you apply what you learn in class to your own data. The first project will involve wrangling your data into tidy format and editing values. The second project will involve plotting and presenting your data.\n\n\n\n\n\n\n\n\nWrapped\nCombine everything that we’ve learned to create your own Spotify Wrapped or other summary. If you have a Spotify account and have used it in the last year, download your data. Otherwise, use an existing data set. Then process that data to find the most listened to artists and songs and plot your results."
  },
  {
    "objectID": "syllabus.html#grades",
    "href": "syllabus.html#grades",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Grades",
    "text": "Grades\n\nGrade scale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA+\n96.5-100\nB+\n86.5-89.4\nC+\n76.5-79.4\nD\n59.5-69.4\nF\n0-59.4\n\n\nA\n96.5-100\nB\n86.5-89.4\nC\n69.5-76.4\n\n\n\n\n\n\nA-\n89.5-92.4\nB-\n79.5-82.4\n\n\n\n\n\n\n\n\n\nGrades of B- or higher (&gt;= 79.5) count as passing for Pass/No Pass grading.\n\n\nAssessment\n\n\n\nGrade component\nGrade percentage\n\n\n\n\nExercises\n20\n\n\nCheck-ins\n35\n\n\nLearning journal\n5\n\n\nProjects\n35\n\n\nCreativity\n5"
  },
  {
    "objectID": "syllabus.html#course-resources-and-policies",
    "href": "syllabus.html#course-resources-and-policies",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Course resources and policies",
    "text": "Course resources and policies\nStudents are responsible for knowing the university policies and resources.\n\nInstructional continuity plan\nIf in-person classes are canceled, you will be notified of the instructional continuity plan for this class by email.\n\n\nDiversity, inclusion, and wellness\nWe must treat every individual with respect. We are diverse in many ways, and this diversity is fundamental to building and maintaining an equitable and inclusive campus community. Diversity can refer to multiple ways that we identify ourselves, including but not limited to race, color, national origin, language, sex, disability, age, sexual orientation, gender identity, religion, creed, ancestry, belief, veteran status, or genetic information. Each of these diverse identities, along with many others not mentioned here, shape the perspectives that students and faculty bring to our campus. I would like to create a learning environment in this course that supports a diversity of thoughts, perspectives and experiences, and honors participant identities. To help accomplish this:\n\nIf you have a name and/or set of pronouns that differ from those that appear in your official records, please let me know in the course introduction form.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by me or anyone else) that was uninformed or insensitive or made you feel uncomfortable, please feel free to raise the issue in class, contact me to schedule an opportunity to discuss the issue in person, or submit anonymous feedback via the course feedback form. I recognize the power differential between student and professor, but I promise you, neither your grade nor my opinion of you will be impacted by your willingness to bring issues to me.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to talk with me. Your wellness is important to me, and I do not want this course to adversely affect your mental health. I am invested in your understanding of the course material and am happy to make accommodations to achieve the longer-term goal of you learning to use R. Beyond requesting specific accommodations, if you notice something about the class structure or assignments that could be made to improve universal accessibility, please let me know. Sometimes you might be able to work around a barrier, and not go to the trouble of going through the SSD to request a formal accommodation – but over time, working around barriers takes a toll. If I am made aware of those issues, we are better able to remove them so you can focus fully on your work.\nUnfortunately, incidents of bias or discrimination do occur, whether intentional or unintentional. They contribute to creating an unwelcoming environment for individuals and groups at the university. Therefore, the university encourages anyone who experiences or observes unfair or hostile treatment on the basis of identity to speak out for justice and support, within the moment of the incident or after the incident has passed. As noted above, if this happens in the context of this class, I encourage you to come talk to me so we can figure out together how to address the issue and find you the support you need. At a broader institutional level, resources are available at Title IX Resources and Support and incidents can be reported through the TIPS system.\n\n\n\nMental health and well-being resources\nUNL offers a variety of options to students to aid them in dealing with stress and adversity. Counseling and Psychological & Services (CAPS) is a multidisciplinary team of psychologists and counselors that works collaboratively with Nebraska students to help them explore their feelings and thoughts and learn helpful ways to improve their mental, psychological and emotional well-being when issues arise. CAPS can be reached by calling 402-472-7450. Well-Being Collective provides one-on-one well-being coaching to any student who wants to enhance their well-being. Trained well-being coaches help students create and be grateful for positive experiences, practice resilience and self-compassion, and find support as they need it. BRRWB can be reached by calling 402-472-8770.\n\n\nAccommodations for students with disabilities\nThe University strives to make all learning experiences as accessible as possible. If you anticipate or experience barriers based on your disability (including mental health, chronic or temporary medical conditions), please let me know immediately so that we can discuss options privately. To establish reasonable accommodations, I may request that you register with Services for Students with Disabilities (SSD). If you are eligible for services and register with their office, make arrangements with me as soon as possible to discuss your accommodations so they can be implemented in a timely manner. SSD contact information: 117 Louise Pound Hall; 402-472-3787.\n\n\nClass materials use and distribution\nMost class materials (anything on this website) are publicly available for anyone to use, assuming they follow the Creative Commons Attribution 4.0 International Public License (CC BY 4.0) as described in the main page of the website. Some assignments are not publicly available.\n\n\nAcademic dishonesty policy\nYou are responsible for knowing and adhering to the UNL Student Code of Conduct. Any student found guilty of academic dishonesty, including (but not limited to) cheating, falsification, and plagiarism, will fail the course and may be subject to disciplinary sanctions.\n\nCheating: Copying or attempting to copy from an academic test or examination of another student; using or attempting to use unauthorized materials, information, notes, study aids or other devices for an academic test, examination or exercise; engaging or attempting to engage the assistance of another individual in misrepresenting the academic performance of a student; or communication information in an unauthorized manner to another person for an academic test, examination or exercise.\nFabrication or Falsification: Falsifying or fabricating any information or citation in any academic exercise, work, speech, research, test or examination. Falsification is the alteration of information, while fabrication is the invention or counterfeiting of information.\nPlagiarism: Presenting the work of another as one’s own (i.e., without proper acknowledgement of the source) and submitting examination, theses, reports, speeches, drawings, laboratory notes or other academic work in whole or in part as one’s own when such work has been prepared by another person or copied from another person. Materials covered by this prohibition include, but are not limited to, text, video, audio, images, photographs, websites, electronic and online materials, and other intellectual property. Copying material from other sources with minor modifications is considered plagiarism. \nComplicity in Academic Dishonesty: Helping or attempting to help another student to commit an act of academic dishonesty.\nImpermissible Collaboration: Collaborating on any academic exercise, work, speech, test or examination unless expressly authorized by the faculty member. It is the obligation of the student to know whether collaboration is permitted.\nAI/LMMs: With the proliferation of artificial intelligence (AI) and large language models (LLMs) like ChatGPT and GitHub CoPilot, it is tempting to use these when you code. Though these tools can be useful once you know how to code, they can be impediments when you are learning to code. In particular do not just copy/paste code from an LLM. Asking an LLM to generate code is problematic because they don’t know anything about the code itself—they just output code that they’ve seen in their training data. And they can’t run the code to know if it even works. If you have some code that you don’t understand, LLMs can be useful to explain existing code (check out AI TutoR for how to use AI to support your learning). But please don’t use LLMs to generate code for this course. And do not use LLMs to write any text for your assignments."
  },
  {
    "objectID": "syllabus.html#course-schedule",
    "href": "syllabus.html#course-schedule",
    "title": "PSYC 971 Data Processing and Visualization in R",
    "section": "Course schedule",
    "text": "Course schedule\n\nNote this is tentative!\n\n\n\n\n\n\nWeek\nDate\nModule\nTopic\n\n\n\n\n1\n2025-01-20\n1\nMLK Day\n\n\n\n2025-01-22\n1\nCourse introduction\n\n\n\n2025-01-24\n1\nWorking in RStudio\n\n\n2\n2025-01-27\n1\nCoding basics\n\n\n\n2025-01-29\n1\nWorkflows\n\n\n\n2025-01-31\n1\nLiterate programming\n\n\n3\n2025-02-03\n2\nData types\n\n\n\n2025-02-05\n2\nData structures\n\n\n\n2025-02-07\n2\nImporting data\n\n\n4\n2025-02-10\n2\nValidating data\n\n\n\n2025-02-12\n3\nSelecting columns\n\n\n\n2025-02-14\n3\nMutating columns\n\n\n5\n2025-02-17\n3\nPiping commands\n\n\n\n2025-02-19\n3\nFiltering rows\n\n\n\n2025-02-21\n3\nSummarizing rows\n\n\n6\n2025-02-24\n4\nPivoting data\n\n\n\n2025-02-26\n4\nSeparating data\n\n\n\n2025-02-28\n4\nMerging columns\n\n\n7\n2025-03-03\n4\nMerging rows\n\n\n\n2025-03-05\n5\nNumbers\n\n\n\n2025-03-07\n5\nStrings\n\n\n8\n2025-03-10\n5\nMatching patterns\n\n\n\n2025-03-12\n5\nFactors\n\n\n\n2025-03-14\n5\nProject workday\n\n\n9\n2025-03-17\n\nSpring break\n\n\n\n2025-03-19\n\nSpring break\n\n\n\n2025-03-21\n\nSpring break\n\n\n10\n2025-03-24\n6\nFunctions\n\n\n\n2025-03-26\n6\nIteration\n\n\n\n2025-03-28\n7\nGrammar of graphics I\n\n\n11\n2025-03-31\n7\nGrammar of graphics II\n\n\n\n2025-04-02\n7\nDesign and themes\n\n\n\n2025-04-04\n7\nColor\n\n\n12\n2025-04-07\n8\nPlotting distributions: histograms\n\n\n\n2025-04-09\n8\nPlotting distributions: boxplots\n\n\n\n2025-04-11\n8\nPlotting amounts: bar charts\n\n\n13\n2025-04-14\n8\nPlotting x-y data: associations\n\n\n\n2025-04-16\n\nNebraska Symposium\n\n\n\n2025-04-18\n8\nPlotting x-y data: time series\n\n\n14\n2025-04-21\n8\nPlotting x-y data: categories\n\n\n\n2025-04-23\n9\nAdjusting axes\n\n\n\n2025-04-25\n9\nAnnotating plots\n\n\n15\n2025-04-28\n9\nPlotting challenge\n\n\n\n2025-04-30\n10\nTables\n\n\n\n2025-05-02\n10\nPublications\n\n\n16\n2025-05-05\n10\nAdvanced R Markdown\n\n\n\n2025-05-07\n11\nStatistics I\n\n\n\n2025-05-09\n11\nStatistics II"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#code-chunk-options",
    "href": "slides/41_advrmarkdown.html#code-chunk-options",
    "title": "Advanced R Markdown",
    "section": "Code chunk options",
    "text": "Code chunk options\nGo in the {r} header of code chunks (in one line)\n\n\n\nlabel = my-chunk - chunk label\n\neval = TRUE - evaluates code chunk\n\necho = TRUE - displays source code in document\n\ninclude = TRUE - displays chunk output in document\n\nmessage = TRUE - displays messages in document\n\nwarning = TRUE - displays warnings in document\n\nerror = TRUE - displays errors in document"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#code-chunk-options-1",
    "href": "slides/41_advrmarkdown.html#code-chunk-options-1",
    "title": "Advanced R Markdown",
    "section": "Code chunk options",
    "text": "Code chunk options\nGo in the {r} header of code chunks (in one line)\n```{r my-chunk, echo = FALSE, message = FALSE, warning = FALSE}\n```"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#code-chunk-options-2",
    "href": "slides/41_advrmarkdown.html#code-chunk-options-2",
    "title": "Advanced R Markdown",
    "section": "Code chunk options",
    "text": "Code chunk options\nCan also be separated from header using #|\n```{r}\n#| my-chunk, echo = FALSE, message = FALSE\n#| warning = FALSE\n```"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#global-options",
    "href": "slides/41_advrmarkdown.html#global-options",
    "title": "Advanced R Markdown",
    "section": "Global options",
    "text": "Global options\nSet options globally with knitr::opts_chunk$set()\n```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)\n```"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figures-generated-in-chunks",
    "href": "slides/41_advrmarkdown.html#figures-generated-in-chunks",
    "title": "Advanced R Markdown",
    "section": "Figures generated in chunks",
    "text": "Figures generated in chunks\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figure-scaling",
    "href": "slides/41_advrmarkdown.html#figure-scaling",
    "title": "Advanced R Markdown",
    "section": "Figure scaling",
    "text": "Figure scaling\nfig.width = 5, fig.height = 5\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figure-scaling-1",
    "href": "slides/41_advrmarkdown.html#figure-scaling-1",
    "title": "Advanced R Markdown",
    "section": "Figure scaling",
    "text": "Figure scaling\nfig.width = 3, fig.height = 3\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#output-widthheight",
    "href": "slides/41_advrmarkdown.html#output-widthheight",
    "title": "Advanced R Markdown",
    "section": "Output width/height",
    "text": "Output width/height\nout.width = \"30%\", out.height = \"30%\"\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figure-alignment",
    "href": "slides/41_advrmarkdown.html#figure-alignment",
    "title": "Advanced R Markdown",
    "section": "Figure alignment",
    "text": "Figure alignment\nfig.align = \"center\"\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figure-caption",
    "href": "slides/41_advrmarkdown.html#figure-caption",
    "title": "Advanced R Markdown",
    "section": "Figure caption",
    "text": "Figure caption\nfig.cap = \"My figure caption\"\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()\n\n\n\nFigure 1: My figure caption"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figure-alt-text",
    "href": "slides/41_advrmarkdown.html#figure-alt-text",
    "title": "Advanced R Markdown",
    "section": "Figure alt text",
    "text": "Figure alt text\nfig.alt = \"Scatterplot of penguin bill length by depth.\"\n\nggplot(penguins, aes(bill_length_mm, bill_depth_mm)) + geom_point()\n\n\nMy figure caption"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#figure-files",
    "href": "slides/41_advrmarkdown.html#figure-files",
    "title": "Advanced R Markdown",
    "section": "Figure files",
    "text": "Figure files\nknitr::include_graphics()\n\nknitr::include_graphics(\"https://quarto.org/docs/authoring/images/crossref-figure.png\")"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#sec-cross-reference",
    "href": "slides/41_advrmarkdown.html#sec-cross-reference",
    "title": "Advanced R Markdown",
    "section": "Cross reference figures/tables",
    "text": "Cross reference figures/tables\n\n\nMake sure code chunk has a label and a caption\nUse a bookdown output format (e.g., bookdown::pdf_document2, papaja::apa6_pdf, thesisdown)\nInsert \\ref{fig:chunk-label} for figures and \\ref{tab:chunk-label} for tables\nNote for Quarto, labels must start with fig- or tbl- and reference with @fig-label or @tbl-label (e.g., Figure 1)"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#cross-reference-sections",
    "href": "slides/41_advrmarkdown.html#cross-reference-sections",
    "title": "Advanced R Markdown",
    "section": "Cross reference sections",
    "text": "Cross reference sections\n\n\nLabel sections with {#slug}  (e.g., ## Cross reference figures/tables {#sec-cross-reference})\nCross reference with \\@ref(slug)\nFor Quarto, cross references must start with #sec- and are referenced with @sec-label (e.g., Section 4.1)"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#zotero",
    "href": "slides/41_advrmarkdown.html#zotero",
    "title": "Advanced R Markdown",
    "section": "Zotero",
    "text": "Zotero"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#zotero-1",
    "href": "slides/41_advrmarkdown.html#zotero-1",
    "title": "Advanced R Markdown",
    "section": "Zotero",
    "text": "Zotero\n\nInstall Better BibTeX extension\nCreate collection for project\nAdd references to collection\nExport Collection (check Keep Updated) to BibTeX"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#set-bibliography",
    "href": "slides/41_advrmarkdown.html#set-bibliography",
    "title": "Advanced R Markdown",
    "section": "Set bibliography",
    "text": "Set bibliography\n\nIn YAML header, assign bibliography to the project’s .bib file\n\n\nbibliography: zotero-output.bib\n\n\n\nIf using {papaja}’s r_ref() output\n\n\nbibliography: [\"zotero-output.bib\", \"r-references.bib\"]"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#insert-citations-manually",
    "href": "slides/41_advrmarkdown.html#insert-citations-manually",
    "title": "Advanced R Markdown",
    "section": "Insert citations manually",
    "text": "Insert citations manually\n\n\nFind BibTex key in Zotero (e.g., Stevens.etal.2023)\nInsert with [@citation.key]: [@Stevens.etal.2023] yields (Stevens et al., 2023)\nSeparate multiple citations with ;: [@Stevens.etal.2022; @Stevens.etal.2023] yields (Stevens et al., 2022, 2023)\nAdd prefixes and suffixes: [see @Stevens.etal.2023, pp. 25] yields (see Stevens et al., 2023, pp. 25)"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#insert-citations-manually-1",
    "href": "slides/41_advrmarkdown.html#insert-citations-manually-1",
    "title": "Advanced R Markdown",
    "section": "Insert citations manually",
    "text": "Insert citations manually\n\n\nUse parentheses only for date by removing brackets: @Stevens.etal.2023 yields Stevens et al. (2023)\nUse only year by adding -: [-@Stevens.etal.2023] yields (2023)\nAdd reference to bibliography without adding citation with\n\n\n\n---\nnocite: |\n  @Barela.etal.2023\n..."
  },
  {
    "objectID": "slides/41_advrmarkdown.html#insert-with-citr-add-in",
    "href": "slides/41_advrmarkdown.html#insert-with-citr-add-in",
    "title": "Advanced R Markdown",
    "section": "Insert with {citr} add-in",
    "text": "Insert with {citr} add-in\n\nInstall {citr} with remotes::install_github(\"crsh/citr\")\n\nRestart RStudio\nStart Zotero\nStart citr add-in, select Insert citations"
  },
  {
    "objectID": "slides/41_advrmarkdown.html#set-citation-style",
    "href": "slides/41_advrmarkdown.html#set-citation-style",
    "title": "Advanced R Markdown",
    "section": "Set citation style",
    "text": "Set citation style\n\nIn YAML header, assign csl to citation style .csl file\n\n\ncsl: apa7.csl\n\n\n\nGet CSL files from Zotero Style Repository"
  },
  {
    "objectID": "slides/29_color.html#source",
    "href": "slides/29_color.html#source",
    "title": "Color",
    "section": "Source",
    "text": "Source\nData Visualization in R\nSDS 375\nClaus O. Wilke"
  },
  {
    "objectID": "slides/29_color.html#uses-of-color-1",
    "href": "slides/29_color.html#uses-of-color-1",
    "title": "Color",
    "section": "Uses of color",
    "text": "Uses of color\n\nDistinguish categories (qualitative)\nRepresent ordered numeric values (sequential)\nRepresent binary numeric values (diverging)\nHighlight"
  },
  {
    "objectID": "slides/29_color.html#distinguish-categories",
    "href": "slides/29_color.html#distinguish-categories",
    "title": "Color",
    "section": "Distinguish categories",
    "text": "Distinguish categories"
  },
  {
    "objectID": "slides/29_color.html#represent-sequential-numeric-values",
    "href": "slides/29_color.html#represent-sequential-numeric-values",
    "title": "Color",
    "section": "Represent sequential numeric values",
    "text": "Represent sequential numeric values"
  },
  {
    "objectID": "slides/29_color.html#represent-diverging-numeric-values",
    "href": "slides/29_color.html#represent-diverging-numeric-values",
    "title": "Color",
    "section": "Represent diverging numeric values",
    "text": "Represent diverging numeric values"
  },
  {
    "objectID": "slides/29_color.html#highlight",
    "href": "slides/29_color.html#highlight",
    "title": "Color",
    "section": "Highlight",
    "text": "Highlight"
  },
  {
    "objectID": "slides/29_color.html#rgb-color-space",
    "href": "slides/29_color.html#rgb-color-space",
    "title": "Color",
    "section": "RGB color space",
    "text": "RGB color space\n\n\n\nred R (0-255): amount of red\ngreen G (0-255): amount of green\nblue B (0-255): amount of blue\n\n\n\n\nR\nG\nB\nhexcode\n\n\n\n0\n0\n0\n#000000\n\n\n255\n0\n0\n#FF0000 \n\n\n0\n255\n255\n#00FFFF \n\n\n128\n128\n128\n#808080 \n\n\n0\n158\n115\n#009E73 \n\n\n255\n255\n255\n#FFFFFF"
  },
  {
    "objectID": "slides/29_color.html#rgb-color-space-1",
    "href": "slides/29_color.html#rgb-color-space-1",
    "title": "Color",
    "section": "RGB color space",
    "text": "RGB color space\n\n\nHumans cannot reason well about the RGB color space"
  },
  {
    "objectID": "slides/29_color.html#hcl-color-space",
    "href": "slides/29_color.html#hcl-color-space",
    "title": "Color",
    "section": "HCL color space",
    "text": "HCL color space\n\n\nExplore HCL colors with colorspace::choose_color()"
  },
  {
    "objectID": "slides/29_color.html#avoid-high-chroma",
    "href": "slides/29_color.html#avoid-high-chroma",
    "title": "Color",
    "section": "Avoid high chroma",
    "text": "Avoid high chroma\n\n\nHigh chroma: Toys\n\n\nSource: Alexas_Fotos\n\n\nLow chroma: Elegance\n\n\nSource: Saviesa Home"
  },
  {
    "objectID": "slides/29_color.html#be-aware-of-color-vision-deficiency",
    "href": "slides/29_color.html#be-aware-of-color-vision-deficiency",
    "title": "Color",
    "section": "Be aware of color-vision deficiency",
    "text": "Be aware of color-vision deficiency\n5%–8% of men are color blind!"
  },
  {
    "objectID": "slides/29_color.html#consider-using-okabe-ito-scale",
    "href": "slides/29_color.html#consider-using-okabe-ito-scale",
    "title": "Color",
    "section": "Consider using Okabe-Ito scale",
    "text": "Consider using Okabe-Ito scale\n\n\n\n\n\n\n\n\nName\nHex code   \nR, G, B (0-255)\n\n\n\norange\n#E69F00\n230, 159, 0\n\n\nsky blue\n#56B4E9\n86, 180, 233\n\n\nbluish green\n#009E73\n0, 158, 115\n\n\nyellow\n#F0E442\n240, 228, 66\n\n\nblue\n#0072B2\n0, 114, 178\n\n\nvermilion\n#D55E00\n213, 94, 0\n\n\nreddish purple\n#CC79A7\n204, 121, 167\n\n\nblack\n#000000\n0, 0, 0"
  },
  {
    "objectID": "slides/29_color.html#consider-using-viridis",
    "href": "slides/29_color.html#consider-using-viridis",
    "title": "Color",
    "section": "Consider using viridis",
    "text": "Consider using viridis\n\n\n\nSource: viridis package"
  },
  {
    "objectID": "slides/29_color.html#using-color-scales-in-ggplot",
    "href": "slides/29_color.html#using-color-scales-in-ggplot",
    "title": "Color",
    "section": "Using color scales in ggplot",
    "text": "Using color scales in ggplot\n\n\n\n\n\n\n\n\n\nScale function\nData type\nPalette type\n\n\n\n\n\nscale_color_hue()                    \ndiscrete        \nqualitative                                                  \n\n\n\nscale_color_gradient()\ncontinuous\nsequential\n\n\n\nscale_color_gradient2()\ncontinuous\ndiverging\n\n\n\nscale_color_brewer()\ndiscrete\nqualitative, diverging, sequential\n\n\n\nscale_color_distiller()\ncontinuous\nqualitative, diverging, sequential\n\n\n\n\n\n\nReplace color with fill for shaded areas"
  },
  {
    "objectID": "slides/29_color.html#color-palettes-qualitative",
    "href": "slides/29_color.html#color-palettes-qualitative",
    "title": "Color",
    "section": "Color palettes: qualitative",
    "text": "Color palettes: qualitative\n\n\n\n\n\n\n\nscale_color_brewer()\n\n\n\n\nmpg |&gt; \n  ggplot(aes(x = displ, y = hwy, color = drv)) +\n  geom_jitter() +\n  labs(x = \"Displacement\", y = \"Highway fuel efficiency\") +\n  scale_color_brewer(palette = \"Accent\") +\n  theme(legend.position = c(0.8, 0.8))"
  },
  {
    "objectID": "slides/29_color.html#color-palettes-sequential",
    "href": "slides/29_color.html#color-palettes-sequential",
    "title": "Color",
    "section": "Color palettes: sequential",
    "text": "Color palettes: sequential\n\n\n\n\n\n\n\nscale_color_distiller()\n\n\n\n\nmpg |&gt; \n  ggplot(aes(x = displ, y = hwy, color = cty)) +\n  geom_jitter() +\n  labs(x = \"Displacement\", y = \"Highway fuel efficiency\") +\n  scale_color_distiller(palette = \"YlGnBu\") +\n  theme(legend.position = c(0.8, 0.8))"
  },
  {
    "objectID": "slides/29_color.html#color-palettes-diverging",
    "href": "slides/29_color.html#color-palettes-diverging",
    "title": "Color",
    "section": "Color palettes: diverging",
    "text": "Color palettes: diverging\n\n\n\n\n\n\n\nscale_color_distiller()\n\n\n\n\nmpg |&gt; \n  ggplot(aes(x = displ, y = hwy, color = cty)) +\n  geom_jitter() +\n  labs(x = \"Displacement\", y = \"Highway fuel efficiency\") +\n  scale_color_distiller(palette = \"Spectral\") +\n  theme(legend.position = c(0.8, 0.8))"
  },
  {
    "objectID": "slides/29_color.html#additional-palettes",
    "href": "slides/29_color.html#additional-palettes",
    "title": "Color",
    "section": "Additional palettes",
    "text": "Additional palettes\n\nlibrary(paletteer)"
  },
  {
    "objectID": "slides/29_color.html#additional-palettes-1",
    "href": "slides/29_color.html#additional-palettes-1",
    "title": "Color",
    "section": "Additional palettes",
    "text": "Additional palettes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSwitch to R script"
  },
  {
    "objectID": "slides/29_color.html#lets-code",
    "href": "slides/29_color.html#lets-code",
    "title": "Color",
    "section": "Let’s code!",
    "text": "Let’s code!\nColor [Rmd]"
  },
  {
    "objectID": "slides/27_grammar2.html#set-up",
    "href": "slides/27_grammar2.html#set-up",
    "title": "Grammar of graphics II",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/27_grammar2.html#seven-componentslayers-of-ggplots",
    "href": "slides/27_grammar2.html#seven-componentslayers-of-ggplots",
    "title": "Grammar of graphics II",
    "section": "Seven components/layers of ggplots",
    "text": "Seven components/layers of ggplots\n\nData\nMappings – maps data to properties of geom\nGeom – represents data\nStat – transforms data\nPosition – control placement of data on coordinate\nFacet – split graph into subplots\nCoordinate – places data in coordinate system"
  },
  {
    "objectID": "slides/27_grammar2.html#map-data-to-visual-properties",
    "href": "slides/27_grammar2.html#map-data-to-visual-properties",
    "title": "Grammar of graphics II",
    "section": "Map data to visual properties",
    "text": "Map data to visual properties"
  },
  {
    "objectID": "slides/27_grammar2.html#map-data-columns-to-plot",
    "href": "slides/27_grammar2.html#map-data-columns-to-plot",
    "title": "Grammar of graphics II",
    "section": "Map data columns to plot",
    "text": "Map data columns to plot\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point()"
  },
  {
    "objectID": "slides/27_grammar2.html#size",
    "href": "slides/27_grammar2.html#size",
    "title": "Grammar of graphics II",
    "section": "Size",
    "text": "Size\n\n\nMap data to aesthetic\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, size = cty)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nApply to all points\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(size = 0.5)"
  },
  {
    "objectID": "slides/27_grammar2.html#transparency",
    "href": "slides/27_grammar2.html#transparency",
    "title": "Grammar of graphics II",
    "section": "Transparency",
    "text": "Transparency\n\n\nMap data to aesthetic\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, alpha = cty)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nApply to all points\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(alpha = 0.25)"
  },
  {
    "objectID": "slides/27_grammar2.html#shape",
    "href": "slides/27_grammar2.html#shape",
    "title": "Grammar of graphics II",
    "section": "Shape",
    "text": "Shape\n\n\nMap data to aesthetic\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nApply to all points\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(shape = 5)"
  },
  {
    "objectID": "slides/27_grammar2.html#shapes",
    "href": "slides/27_grammar2.html#shapes",
    "title": "Grammar of graphics II",
    "section": "Shapes",
    "text": "Shapes"
  },
  {
    "objectID": "slides/27_grammar2.html#color",
    "href": "slides/27_grammar2.html#color",
    "title": "Grammar of graphics II",
    "section": "Color",
    "text": "Color\n\n\nMap data to aesthetic\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nApply to all points\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(color = \"dodgerblue\")"
  },
  {
    "objectID": "slides/27_grammar2.html#color-1",
    "href": "slides/27_grammar2.html#color-1",
    "title": "Grammar of graphics II",
    "section": "Color",
    "text": "Color\nWhat happens if we put it in the aesthetic?\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, color = \"dodgerblue\")) +\n  geom_point()"
  },
  {
    "objectID": "slides/27_grammar2.html#color-points-lines-text-and-borders",
    "href": "slides/27_grammar2.html#color-points-lines-text-and-borders",
    "title": "Grammar of graphics II",
    "section": "Color: points, lines, text, and borders",
    "text": "Color: points, lines, text, and borders\n\n\nMap data to aesthetic\n\nmpg |&gt;\n  ggplot(aes(x = class, color = class)) +\n  geom_bar(show.legend = FALSE, linewidth = 2)\n\n\n\n\n\n\n\n\n\nApply to everything\n\nmpg |&gt;\n  ggplot(aes(x = class)) +\n  geom_bar(color = \"blue\", linewidth = 2)"
  },
  {
    "objectID": "slides/27_grammar2.html#fill-filled-areas",
    "href": "slides/27_grammar2.html#fill-filled-areas",
    "title": "Grammar of graphics II",
    "section": "Fill: filled areas",
    "text": "Fill: filled areas\n\n\nMap data to aesthetic\n\nmpg |&gt;\n  ggplot(aes(x = class, fill = class)) +\n  geom_bar(show.legend = FALSE)\n\n\n\n\n\n\n\n\n\nApply to everything\n\nmpg |&gt;\n  ggplot(aes(x = class)) +\n  geom_bar(fill = \"blue\")"
  },
  {
    "objectID": "slides/27_grammar2.html#lines",
    "href": "slides/27_grammar2.html#lines",
    "title": "Grammar of graphics II",
    "section": "Lines",
    "text": "Lines\nSeparated by groups\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, group = drv)) +\n  geom_smooth()"
  },
  {
    "objectID": "slides/27_grammar2.html#linetype",
    "href": "slides/27_grammar2.html#linetype",
    "title": "Grammar of graphics II",
    "section": "Linetype",
    "text": "Linetype\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, linetype = drv)) +\n  geom_smooth()"
  },
  {
    "objectID": "slides/27_grammar2.html#apply-line-aesthetics-to-groups",
    "href": "slides/27_grammar2.html#apply-line-aesthetics-to-groups",
    "title": "Grammar of graphics II",
    "section": "Apply line aesthetics to groups",
    "text": "Apply line aesthetics to groups\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, color = drv)) +\n  geom_smooth(show.legend = FALSE)"
  },
  {
    "objectID": "slides/27_grammar2.html#apply-aesthetics-to-one-geom",
    "href": "slides/27_grammar2.html#apply-aesthetics-to-one-geom",
    "title": "Grammar of graphics II",
    "section": "Apply aesthetics to one geom",
    "text": "Apply aesthetics to one geom\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth()"
  },
  {
    "objectID": "slides/27_grammar2.html#apply-aesthetics-differently-to-geoms",
    "href": "slides/27_grammar2.html#apply-aesthetics-differently-to-geoms",
    "title": "Grammar of graphics II",
    "section": "Apply aesthetics differently to geoms",
    "text": "Apply aesthetics differently to geoms\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  geom_smooth(aes(linetype = drv))"
  },
  {
    "objectID": "slides/27_grammar2.html#bands-have-aesthetics-too",
    "href": "slides/27_grammar2.html#bands-have-aesthetics-too",
    "title": "Grammar of graphics II",
    "section": "Bands have aesthetics, too",
    "text": "Bands have aesthetics, too\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_smooth(aes(color = drv, fill = drv))"
  },
  {
    "objectID": "slides/27_grammar2.html#statistical-transformations-1",
    "href": "slides/27_grammar2.html#statistical-transformations-1",
    "title": "Grammar of graphics II",
    "section": "Statistical transformations",
    "text": "Statistical transformations\n\nggplot can calculate statistics on the fly\nmany geoms have underlying statistical transformation\n\n\ndiamonds\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows"
  },
  {
    "objectID": "slides/27_grammar2.html#bar-plots",
    "href": "slides/27_grammar2.html#bar-plots",
    "title": "Grammar of graphics II",
    "section": "Bar plots",
    "text": "Bar plots\nCount observations of variable types with stat_count()\n\ndiamonds |&gt;\n  ggplot(aes(x = cut)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/27_grammar2.html#summarize-data",
    "href": "slides/27_grammar2.html#summarize-data",
    "title": "Grammar of graphics II",
    "section": "Summarize data",
    "text": "Summarize data\n\n\nstat_summary()\n\ndiamonds |&gt;\n  ggplot(aes(x = cut, y = depth)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nPlot mean and standard error\n\ndiamonds |&gt;\n  ggplot(aes(x = cut, y = depth)) +\n  stat_summary()"
  },
  {
    "objectID": "slides/27_grammar2.html#summarize-data-1",
    "href": "slides/27_grammar2.html#summarize-data-1",
    "title": "Grammar of graphics II",
    "section": "Summarize data",
    "text": "Summarize data\n\n\nPlot mean and 95% CI\n\ndiamonds |&gt;\n  ggplot(aes(x = cut, y = depth)) +\n  stat_summary(fun.data = mean_cl_normal)\n\n\n\n\n\n\n\n\n\nPlot median and range\n\ndiamonds |&gt;\n  ggplot(aes(x = cut, y = depth)) +\n  stat_summary(fun.min = min, fun.max = max, fun = median)"
  },
  {
    "objectID": "slides/27_grammar2.html#facets-1",
    "href": "slides/27_grammar2.html#facets-1",
    "title": "Grammar of graphics II",
    "section": "Facets",
    "text": "Facets\nColoring by group difficult to visualize with many groups\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy, color = class)) +\n  geom_point()"
  },
  {
    "objectID": "slides/27_grammar2.html#facet",
    "href": "slides/27_grammar2.html#facet",
    "title": "Grammar of graphics II",
    "section": "Facet",
    "text": "Facet\nPulls out groups into separate panels\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point() +\n  facet_wrap(~ class)"
  },
  {
    "objectID": "slides/27_grammar2.html#lets-code",
    "href": "slides/27_grammar2.html#lets-code",
    "title": "Grammar of graphics II",
    "section": "Let’s code!",
    "text": "Let’s code!\nGrammar of graphics II [Rmd]"
  },
  {
    "objectID": "slides/25_iteration.html#the-problems",
    "href": "slides/25_iteration.html#the-problems",
    "title": "Iteration",
    "section": "The problems",
    "text": "The problems\n\nRun the same model on multiple data sets\nCreate the same plot multiple data sets\nRead in data files from multiple subjects"
  },
  {
    "objectID": "slides/25_iteration.html#set-up",
    "href": "slides/25_iteration.html#set-up",
    "title": "Iteration",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(here)"
  },
  {
    "objectID": "slides/25_iteration.html#for-loops",
    "href": "slides/25_iteration.html#for-loops",
    "title": "Iteration",
    "section": "For loops",
    "text": "For loops"
  },
  {
    "objectID": "slides/25_iteration.html#for-loops-1",
    "href": "slides/25_iteration.html#for-loops-1",
    "title": "Iteration",
    "section": "For loops",
    "text": "For loops\n\nfor (counter in min:max) {\n  # What you want repeated.\n  # Index counter-specific vector with [counter]\n}"
  },
  {
    "objectID": "slides/25_iteration.html#building-objects-with-for-loops",
    "href": "slides/25_iteration.html#building-objects-with-for-loops",
    "title": "Iteration",
    "section": "Building objects with for loops",
    "text": "Building objects with for loops\n\nfor (i in 1:nrow(penguins)) {\n  bill_size[i] &lt;- penguins$bill_length_mm[i] * penguins$bill_depth_mm[i]\n}\n\n\nError: object 'bill_size' not found\n\n\n\n\n\n\n\n\nWarning\n\n\nYou must initialize variables that you build in for loops.\n\n\n\n\nbill_size &lt;- NA\nfor (i in 1:nrow(penguins)) {\n  bill_size[i] &lt;- penguins$bill_length_mm[i] * penguins$bill_depth_mm[i]\n}"
  },
  {
    "objectID": "slides/25_iteration.html#for-loops-with-vectors",
    "href": "slides/25_iteration.html#for-loops-with-vectors",
    "title": "Iteration",
    "section": "For loops with vectors",
    "text": "For loops with vectors\n\nfor (i in month.name) {\n  print(paste0(i, \" has \", str_length(i), \" letters.\"))\n}\n\n[1] \"January has 7 letters.\"\n[1] \"February has 8 letters.\"\n[1] \"March has 5 letters.\"\n[1] \"April has 5 letters.\"\n[1] \"May has 3 letters.\"\n[1] \"June has 4 letters.\"\n[1] \"July has 4 letters.\"\n[1] \"August has 6 letters.\"\n[1] \"September has 9 letters.\"\n[1] \"October has 7 letters.\"\n[1] \"November has 8 letters.\"\n[1] \"December has 8 letters.\""
  },
  {
    "objectID": "slides/25_iteration.html#mapping-with-purrr",
    "href": "slides/25_iteration.html#mapping-with-purrr",
    "title": "Iteration",
    "section": "Mapping with {purrr}",
    "text": "Mapping with {purrr}\n\nlibrary(purrr)\n\n\n\n\n\n\n\n\nSource: Malcolm Barrett"
  },
  {
    "objectID": "slides/25_iteration.html#mapping-functions",
    "href": "slides/25_iteration.html#mapping-functions",
    "title": "Iteration",
    "section": "Mapping functions",
    "text": "Mapping functions\npurrr::map() applies functions repeatedly across data\n\nmap(select(penguins, ends_with(\"_mm\")), ~ mean(.x, na.rm = TRUE))\n\n$bill_length_mm\n[1] 43.92193\n\n$bill_depth_mm\n[1] 17.15117\n\n$flipper_length_mm\n[1] 200.9152\n\n\n\nWhat kind of data type does map() return?"
  },
  {
    "objectID": "slides/25_iteration.html#mapping-function",
    "href": "slides/25_iteration.html#mapping-function",
    "title": "Iteration",
    "section": "Mapping function",
    "text": "Mapping function\nNeed different data types as output?\n\nmap_dbl(select(penguins, ends_with(\"_mm\")), ~ mean(.x, na.rm = TRUE))\n\n   bill_length_mm     bill_depth_mm flipper_length_mm \n         43.92193          17.15117         200.91520 \n\nmap_chr(select(penguins, ends_with(\"_mm\")), ~ mean(.x, na.rm = TRUE))\n\n   bill_length_mm     bill_depth_mm flipper_length_mm \n      \"43.921930\"       \"17.151170\"      \"200.915205\""
  },
  {
    "objectID": "slides/25_iteration.html#mapping-function-1",
    "href": "slides/25_iteration.html#mapping-function-1",
    "title": "Iteration",
    "section": "Mapping function",
    "text": "Mapping function\nUse split() like dplyr::group_by()\n\npenguins |&gt;\n  split(penguins$species) |&gt;\n  map(~ lm(bill_length_mm ~ bill_depth_mm, data = .x))\n\n$Adelie\n\nCall:\nlm(formula = bill_length_mm ~ bill_depth_mm, data = .x)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n       23.068          0.857  \n\n\n$Chinstrap\n\nCall:\nlm(formula = bill_length_mm ~ bill_depth_mm, data = .x)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n       13.428          1.922  \n\n\n$Gentoo\n\nCall:\nlm(formula = bill_length_mm ~ bill_depth_mm, data = .x)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n       17.230          2.021"
  },
  {
    "objectID": "slides/25_iteration.html#mapping-function-2",
    "href": "slides/25_iteration.html#mapping-function-2",
    "title": "Iteration",
    "section": "Mapping function",
    "text": "Mapping function\nCreate multiple plots\n\npenguins |&gt;\n  split(penguins$species) |&gt;\n  map(~ ggplot(.x, aes(bill_length_mm, bill_depth_mm)) + geom_point())\n\n$Adelie\n\n\n\n\n\n\n\n\n\n$Chinstrap\n\n\n\n\n\n\n\n\n\n$Gentoo"
  },
  {
    "objectID": "slides/25_iteration.html#importing-multiple-data-files",
    "href": "slides/25_iteration.html#importing-multiple-data-files",
    "title": "Iteration",
    "section": "Importing multiple data files",
    "text": "Importing multiple data files\nFirst, we’ll create multiple data files\n\nspecies_list &lt;- penguins |&gt; \n  split(penguins$species)\nwrite_csv(species_list$Adelie, here(\"data/adelie_penguin_data.csv\"))\nwrite_csv(species_list$Chinstrap, here(\"data/chinstrap_penguin_data.csv\"))\nwrite_csv(species_list$Gentoo, here(\"data/gentoo_penguin_data.csv\"))"
  },
  {
    "objectID": "slides/25_iteration.html#importing-multiple-data-files-1",
    "href": "slides/25_iteration.html#importing-multiple-data-files-1",
    "title": "Iteration",
    "section": "Importing multiple data files",
    "text": "Importing multiple data files\nGet file names and paths with dir()\n\n(penguin_files &lt;- dir(path = \"../data\", \n                      pattern = \"penguin_data.csv\", \n                      full.names = TRUE))\n\n[1] \"../data/adelie_penguin_data.csv\"    \"../data/chinstrap_penguin_data.csv\"\n[3] \"../data/gentoo_penguin_data.csv\""
  },
  {
    "objectID": "slides/25_iteration.html#importing-multiple-data-files-2",
    "href": "slides/25_iteration.html#importing-multiple-data-files-2",
    "title": "Iteration",
    "section": "Importing multiple data files",
    "text": "Importing multiple data files\nMap readr::read_csv() to each element of penguin_files\n\n\n(penguin_data1 &lt;- map(penguin_files, read_csv))\n\n[[1]]\n# A tibble: 152 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 142 more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n[[2]]\n# A tibble: 68 × 8\n   species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Chinstrap Dream            46.5          17.9               192        3500\n 2 Chinstrap Dream            50            19.5               196        3900\n 3 Chinstrap Dream            51.3          19.2               193        3650\n 4 Chinstrap Dream            45.4          18.7               188        3525\n 5 Chinstrap Dream            52.7          19.8               197        3725\n 6 Chinstrap Dream            45.2          17.8               198        3950\n 7 Chinstrap Dream            46.1          18.2               178        3250\n 8 Chinstrap Dream            51.3          18.2               197        3750\n 9 Chinstrap Dream            46            18.9               195        4150\n10 Chinstrap Dream            51.3          19.9               198        3700\n# ℹ 58 more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n[[3]]\n# A tibble: 124 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ℹ 114 more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;"
  },
  {
    "objectID": "slides/25_iteration.html#importing-multiple-data-files-3",
    "href": "slides/25_iteration.html#importing-multiple-data-files-3",
    "title": "Iteration",
    "section": "Importing multiple data files",
    "text": "Importing multiple data files\n\nUse purrr::map_df() to return output as data frame\n\n(penguin_data2 &lt;- map_df(penguin_files, read_csv))\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;"
  },
  {
    "objectID": "slides/25_iteration.html#solving-the-problems",
    "href": "slides/25_iteration.html#solving-the-problems",
    "title": "Iteration",
    "section": "Solving the problems",
    "text": "Solving the problems\n\nRun the same model on multiple data sets\nCreate the same plot for multiple data sets\nRead in data files from multiple subjects"
  },
  {
    "objectID": "slides/25_iteration.html#lets-code",
    "href": "slides/25_iteration.html#lets-code",
    "title": "Iteration",
    "section": "Let’s code!",
    "text": "Let’s code!\nIteration [Rmd]"
  },
  {
    "objectID": "slides/23_dates.html#the-problem",
    "href": "slides/23_dates.html#the-problem",
    "title": "Dates and times",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\n\n\n\n\ndata1\n\n# A tibble: 12 × 2\n   test_date  birth_date \n   &lt;date&gt;     &lt;chr&gt;      \n 1 2023-01-02 1997-07-14 \n 2 2023-01-02 1998-01-28 \n 3 2023-01-05 1967-07-23 \n 4 2023-01-05 Jan 9, 1960\n 5 2023-01-08 1950-11-09 \n 6 2023-01-14 2001-08-24 \n 7 2023-01-16 1979-09-23 \n 8 2023-01-23 1970-03-22 \n 9 2023-01-26 1957-04-21 \n10 2023-01-27 1989-03-07 \n11 2023-01-27 1983-11-03 \n12 2023-01-28 1989-01-31 \n\n\n\n\n\n\ndata2\n\n# A tibble: 9 × 4\n  test_date  birth_date age_at_testing day_of_birth\n  &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;         &lt;ord&gt;       \n1 2023-01-05 1967-07-23 20255 days     Sunday      \n2 2023-01-05 1960-01-09 23007 days     Saturday    \n3 2023-01-08 1950-11-09 26358 days     Thursday    \n4 2023-01-16 1979-09-23 15821 days     Sunday      \n5 2023-01-23 1970-03-22 19300 days     Sunday      \n6 2023-01-26 1957-04-21 24021 days     Sunday      \n7 2023-01-27 1989-03-07 12379 days     Tuesday     \n8 2023-01-27 1983-11-03 14330 days     Thursday    \n9 2023-01-28 1989-01-31 12415 days     Tuesday"
  },
  {
    "objectID": "slides/23_dates.html#set-up",
    "href": "slides/23_dates.html#set-up",
    "title": "Dates and times",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "slides/23_dates.html#reminder",
    "href": "slides/23_dates.html#reminder",
    "title": "Dates and times",
    "section": "Reminder",
    "text": "Reminder\nDates and times are augmented doubles\n\n(x &lt;- as.Date(\"2023-03-22\"))\n\n[1] \"2023-03-22\"\n\nclass(x)\n\n[1] \"Date\"\n\ntypeof(x)\n\n[1] \"double\"\n\n\n\n\n\n\n\n\n\nNote\n\n\nStandard (ISO-8601) way to represent dates and times is\nYYYY-MM-DD HH:MM:SS, so 2023-03-22 10:30:00"
  },
  {
    "objectID": "slides/23_dates.html#dates-and-times-with-lubridate",
    "href": "slides/23_dates.html#dates-and-times-with-lubridate",
    "title": "Dates and times",
    "section": "Dates and times with {lubridate}",
    "text": "Dates and times with {lubridate}\n\nlibrary(lubridate)\n\n\n\n\n\n\n\n\nCongratulations to {lubridate} for joining {tidyverse} last week in version 2.0.0!"
  },
  {
    "objectID": "slides/23_dates.html#current-datetime",
    "href": "slides/23_dates.html#current-datetime",
    "title": "Dates and times",
    "section": "Current date/time",
    "text": "Current date/time\n\nSys.Date()  # base R\n\n[1] \"2024-11-21\"\n\ntoday() # {lubridate}\n\n[1] \"2024-11-21\"\n\n\n\n\nSys.time()  # base R\n\n[1] \"2024-11-21 13:46:16 CST\"\n\nnow()  # {lubridate}\n\n[1] \"2024-11-21 13:46:16 CST\""
  },
  {
    "objectID": "slides/23_dates.html#creating-datestimes",
    "href": "slides/23_dates.html#creating-datestimes",
    "title": "Dates and times",
    "section": "Creating dates/times",
    "text": "Creating dates/times\n\nas.Date(\"2023-03-22\")  # base R\n\n[1] \"2023-03-22\"\n\nas_date(\"2023-03-22\") # {lubridate}\n\n[1] \"2023-03-22\"\n\nymd(20230322) # {lubridate}\n\n[1] \"2023-03-22\""
  },
  {
    "objectID": "slides/23_dates.html#convert-dates-to-iso-8601",
    "href": "slides/23_dates.html#convert-dates-to-iso-8601",
    "title": "Dates and times",
    "section": "Convert dates to ISO-8601",
    "text": "Convert dates to ISO-8601\n\nymd(\"2017-01-31\")\n\n[1] \"2017-01-31\"\n\nmdy(\"January 31st, 2017\")\n\n[1] \"2017-01-31\"\n\nmdy(\"Jan 31 17\")\n\n[1] \"2017-01-31\"\n\ndmy(\"31-Jan-2017\")\n\n[1] \"2017-01-31\""
  },
  {
    "objectID": "slides/23_dates.html#convert-dates-to-iso-8601-1",
    "href": "slides/23_dates.html#convert-dates-to-iso-8601-1",
    "title": "Dates and times",
    "section": "Convert dates to ISO-8601",
    "text": "Convert dates to ISO-8601\n\n(r_class_schedule &lt;- tibble(meeting = 1:4, date = c(\"23 Jan 2023\", \"25 Jan 2023\", \"27 Jan 2023\", \"30 Jan 2023\"), topic = c(\"Course introduction\", \"Working in RStudio\", \"Coding basics\", \"Workflows\")))\n\n# A tibble: 4 × 3\n  meeting date        topic              \n    &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;              \n1       1 23 Jan 2023 Course introduction\n2       2 25 Jan 2023 Working in RStudio \n3       3 27 Jan 2023 Coding basics      \n4       4 30 Jan 2023 Workflows          \n\n\n\nHow do we change the dates in a data frame?\n\n\n\n(r_class_schedule &lt;- r_class_schedule |&gt;\n   mutate(iso_date = dmy(date)))\n\n# A tibble: 4 × 4\n  meeting date        topic               iso_date  \n    &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;               &lt;date&gt;    \n1       1 23 Jan 2023 Course introduction 2023-01-23\n2       2 25 Jan 2023 Working in RStudio  2023-01-25\n3       3 27 Jan 2023 Coding basics       2023-01-27\n4       4 30 Jan 2023 Workflows           2023-01-30"
  },
  {
    "objectID": "slides/23_dates.html#convert-multiple-formats",
    "href": "slides/23_dates.html#convert-multiple-formats",
    "title": "Dates and times",
    "section": "Convert multiple formats",
    "text": "Convert multiple formats\nWhat if your date column has multiple formats?\n\n(bad_dates &lt;- c(\"Jan 1 2023\", \"2-Jan-2023\"))\n\n[1] \"Jan 1 2023\" \"2-Jan-2023\"\n\nas_date(bad_dates)\n\nWarning: All formats failed to parse. No formats found.\n\n\n[1] NA NA"
  },
  {
    "objectID": "slides/23_dates.html#date-formatting",
    "href": "slides/23_dates.html#date-formatting",
    "title": "Dates and times",
    "section": "Date formatting",
    "text": "Date formatting\nCodes for different components/styles of date components\n\n\nCode\nComponent\n\n\n\n%y\nTwo digit year (23)\n\n\n%Y\nFour digit year (2023)\n\n\n%m\nMonth as number (01-12 or 1-12)\n\n\n%b\nAbbreviated month name (Mar)\n\n\n%B\nFull month name (March)\n\n\n%d\nDay of the month (01-31 or 1-31)"
  },
  {
    "objectID": "slides/23_dates.html#date-formatting-1",
    "href": "slides/23_dates.html#date-formatting-1",
    "title": "Dates and times",
    "section": "Date formatting",
    "text": "Date formatting\nCombine codes to make dates\n2023-03-22 = \"%Y-%m-%d\"\n3/22/23 = \"%m/%d/%y\"\n23 Mar 2023 = \"%d %b %Y\"\nMarch 23, 2023 = \"%B %d, %Y\""
  },
  {
    "objectID": "slides/23_dates.html#date-formatting-2",
    "href": "slides/23_dates.html#date-formatting-2",
    "title": "Dates and times",
    "section": "Date formatting",
    "text": "Date formatting\n\n(bad_dates &lt;- c(\"Jan 01 2023\", \"02-Jan-2023\"))\n\n[1] \"Jan 01 2023\" \"02-Jan-2023\"\n\nas_date(bad_dates, format = \"%b %d %Y\")\n\nWarning: 1 failed to parse.\n\n\n[1] \"2023-01-01\" NA          \n\n\n\n\nas_date(bad_dates, format = c(\"%b %d %Y\", \"%d-%b-%Y\"))\n\n[1] \"2023-01-01\" \"2023-01-02\""
  },
  {
    "objectID": "slides/23_dates.html#convert-times-to-iso-8601",
    "href": "slides/23_dates.html#convert-times-to-iso-8601",
    "title": "Dates and times",
    "section": "Convert times to ISO-8601",
    "text": "Convert times to ISO-8601\n\nhms(\"20:11:59\")\n\n[1] \"20H 11M 59S\"\n\nhm(\"10:30\")\n\n[1] \"10H 30M 0S\""
  },
  {
    "objectID": "slides/23_dates.html#convert-date-times-to-iso-8601",
    "href": "slides/23_dates.html#convert-date-times-to-iso-8601",
    "title": "Dates and times",
    "section": "Convert date-times to ISO-8601",
    "text": "Convert date-times to ISO-8601\n\nas_datetime(\"2023-03-10\")\n\n[1] \"2023-03-10 UTC\"\n\nymd_hms(\"2023-03-10 20:11:59\")\n\n[1] \"2023-03-10 20:11:59 UTC\"\n\nmdy_hm(\"03/22/2023 10:30\")\n\n[1] \"2023-03-22 10:30:00 UTC\""
  },
  {
    "objectID": "slides/23_dates.html#change-time-zone",
    "href": "slides/23_dates.html#change-time-zone",
    "title": "Dates and times",
    "section": "Change time zone",
    "text": "Change time zone\ntz argument\n\nymd_hms(\"2023-03-10 20:11:59\", tz = \"America/Chicago\")\n\n[1] \"2023-03-10 20:11:59 CST\"\n\n\n\nFind system time zone\n\nSys.timezone()\n\n[1] \"America/Chicago\"\n\nmdy_hm(\"03/22/2023 10:30\", tz = Sys.timezone())  \n\n[1] \"2023-03-22 10:30:00 CDT\"\n\n\n\n\n\n\n\n\nWarning\n\n\nSetting tz = Sys.timezone() is dangerous and not reproducible if you are traveling or giving code to others in different time zones."
  },
  {
    "objectID": "slides/23_dates.html#create-dates-from-components",
    "href": "slides/23_dates.html#create-dates-from-components",
    "title": "Dates and times",
    "section": "Create dates from components",
    "text": "Create dates from components\n\nflights |&gt;\n  select(year, month, day, hour, minute)\n\n# A tibble: 336,776 × 5\n    year month   day  hour minute\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  2013     1     1     5     15\n 2  2013     1     1     5     29\n 3  2013     1     1     5     40\n 4  2013     1     1     5     45\n 5  2013     1     1     6      0\n 6  2013     1     1     5     58\n 7  2013     1     1     6      0\n 8  2013     1     1     6      0\n 9  2013     1     1     6      0\n10  2013     1     1     6      0\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/23_dates.html#create-dates-from-components-1",
    "href": "slides/23_dates.html#create-dates-from-components-1",
    "title": "Dates and times",
    "section": "Create dates from components",
    "text": "Create dates from components\nmake_date(), make_datetime()\n\nflights |&gt;\n  select(year, month, day, hour, minute) |&gt;\n  mutate(date = make_date(year, month, day),\n         departure = make_datetime(year, month, day, hour, minute))\n\n# A tibble: 336,776 × 7\n    year month   day  hour minute date       departure          \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;date&gt;     &lt;dttm&gt;             \n 1  2013     1     1     5     15 2013-01-01 2013-01-01 05:15:00\n 2  2013     1     1     5     29 2013-01-01 2013-01-01 05:29:00\n 3  2013     1     1     5     40 2013-01-01 2013-01-01 05:40:00\n 4  2013     1     1     5     45 2013-01-01 2013-01-01 05:45:00\n 5  2013     1     1     6      0 2013-01-01 2013-01-01 06:00:00\n 6  2013     1     1     5     58 2013-01-01 2013-01-01 05:58:00\n 7  2013     1     1     6      0 2013-01-01 2013-01-01 06:00:00\n 8  2013     1     1     6      0 2013-01-01 2013-01-01 06:00:00\n 9  2013     1     1     6      0 2013-01-01 2013-01-01 06:00:00\n10  2013     1     1     6      0 2013-01-01 2013-01-01 06:00:00\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/23_dates.html#extract-datetime-elements",
    "href": "slides/23_dates.html#extract-datetime-elements",
    "title": "Dates and times",
    "section": "Extract date/time elements",
    "text": "Extract date/time elements\nFirst, let’s extract a random sample of departure times\n\n(datetime &lt;- flights |&gt;\n   drop_na(dep_time) |&gt; \n   slice_sample(n = 20) |&gt;\n   mutate(departure = make_datetime(year, month, day, hour, minute)) |&gt; \n   pull(departure))\n\n [1] \"2013-05-02 06:00:00 UTC\" \"2013-09-16 20:00:00 UTC\"\n [3] \"2013-09-18 20:05:00 UTC\" \"2013-01-30 22:49:00 UTC\"\n [5] \"2013-05-13 07:05:00 UTC\" \"2013-04-23 16:00:00 UTC\"\n [7] \"2013-06-04 20:40:00 UTC\" \"2013-08-12 13:30:00 UTC\"\n [9] \"2013-05-07 15:25:00 UTC\" \"2013-04-07 22:25:00 UTC\"\n[11] \"2013-05-21 07:00:00 UTC\" \"2013-04-22 20:00:00 UTC\"\n[13] \"2013-09-09 15:35:00 UTC\" \"2013-07-12 09:59:00 UTC\"\n[15] \"2013-08-06 19:39:00 UTC\" \"2013-12-01 10:56:00 UTC\"\n[17] \"2013-07-28 06:55:00 UTC\" \"2013-12-19 06:30:00 UTC\"\n[19] \"2013-06-05 16:29:00 UTC\" \"2013-09-18 17:25:00 UTC\""
  },
  {
    "objectID": "slides/23_dates.html#extract-datetime-elements-1",
    "href": "slides/23_dates.html#extract-datetime-elements-1",
    "title": "Dates and times",
    "section": "Extract date/time elements",
    "text": "Extract date/time elements\nNow let’s extract components\n\nyear(datetime)\n\n [1] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013\n[16] 2013 2013 2013 2013 2013\n\nmonth(datetime)\n\n [1]  5  9  9  1  5  4  6  8  5  4  5  4  9  7  8 12  7 12  6  9\n\nmonth(datetime, label = TRUE)\n\n [1] May Sep Sep Jan May Apr Jun Aug May Apr May Apr Sep Jul Aug Dec Jul Dec Jun\n[20] Sep\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec"
  },
  {
    "objectID": "slides/23_dates.html#extract-datetime-elements-2",
    "href": "slides/23_dates.html#extract-datetime-elements-2",
    "title": "Dates and times",
    "section": "Extract date/time elements",
    "text": "Extract date/time elements\nNow let’s extract components\n\nmday(datetime)\n\n [1]  2 16 18 30 13 23  4 12  7  7 21 22  9 12  6  1 28 19  5 18\n\nyday(datetime)\n\n [1] 122 259 261  30 133 113 155 224 127  97 141 112 252 193 218 335 209 353 156\n[20] 261\n\nwday(datetime)\n\n [1] 5 2 4 4 2 3 3 2 3 1 3 2 2 6 3 1 1 5 4 4\n\nwday(datetime, label = TRUE, abbr = FALSE)\n\n [1] Thursday  Monday    Wednesday Wednesday Monday    Tuesday   Tuesday  \n [8] Monday    Tuesday   Sunday    Tuesday   Monday    Monday    Friday   \n[15] Tuesday   Sunday    Sunday    Thursday  Wednesday Wednesday\n7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday"
  },
  {
    "objectID": "slides/23_dates.html#extract-datetime-elements-3",
    "href": "slides/23_dates.html#extract-datetime-elements-3",
    "title": "Dates and times",
    "section": "Extract date/time elements",
    "text": "Extract date/time elements\nNow let’s extract components\n\nhour(datetime)\n\n [1]  6 20 20 22  7 16 20 13 15 22  7 20 15  9 19 10  6  6 16 17\n\nminute(datetime)\n\n [1]  0  0  5 49  5  0 40 30 25 25  0  0 35 59 39 56 55 30 29 25\n\nsecond(datetime)\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"
  },
  {
    "objectID": "slides/23_dates.html#create-vectors-of-days-of-the-week",
    "href": "slides/23_dates.html#create-vectors-of-days-of-the-week",
    "title": "Dates and times",
    "section": "Create vectors of days of the week",
    "text": "Create vectors of days of the week\n\nwday(1:7, label = TRUE, abbr = FALSE)\n\n[1] Sunday    Monday    Tuesday   Wednesday Thursday  Friday    Saturday \n7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday\n\nas.character(wday(1:7, label = TRUE, abbr = FALSE))\n\n[1] \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"   \n[7] \"Saturday\" \n\nstringr::str_c(as.character(wday(1:7, label = TRUE, abbr = FALSE)), collapse = \", \")\n\n[1] \"Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday\""
  },
  {
    "objectID": "slides/23_dates.html#set-datetime-elements-with-components",
    "href": "slides/23_dates.html#set-datetime-elements-with-components",
    "title": "Dates and times",
    "section": "Set date/time elements with components",
    "text": "Set date/time elements with components\n\nhead(datetime)\n\n[1] \"2013-05-02 06:00:00 UTC\" \"2013-09-16 20:00:00 UTC\"\n[3] \"2013-09-18 20:05:00 UTC\" \"2013-01-30 22:49:00 UTC\"\n[5] \"2013-05-13 07:05:00 UTC\" \"2013-04-23 16:00:00 UTC\"\n\nyear(datetime) &lt;- 2020\nhead(datetime)\n\n[1] \"2020-05-02 06:00:00 UTC\" \"2020-09-16 20:00:00 UTC\"\n[3] \"2020-09-18 20:05:00 UTC\" \"2020-01-30 22:49:00 UTC\"\n[5] \"2020-05-13 07:05:00 UTC\" \"2020-04-23 16:00:00 UTC\""
  },
  {
    "objectID": "slides/23_dates.html#time-spans-1",
    "href": "slides/23_dates.html#time-spans-1",
    "title": "Dates and times",
    "section": "Time spans",
    "text": "Time spans\nFind or create durations\n\nr_class_schedule$iso_date[2] - r_class_schedule$iso_date[1]\n\nTime difference of 2 days\n\ntoday() - ymd(r_class_schedule$iso_date[1])\n\nTime difference of 668 days\n\nr_class_schedule$iso_date[1] - 7 * 9\n\n[1] \"2022-11-21\"\n\nr_class_schedule$iso_date[1] + 7 * 9\n\n[1] \"2023-03-27\""
  },
  {
    "objectID": "slides/23_dates.html#filter-dates",
    "href": "slides/23_dates.html#filter-dates",
    "title": "Dates and times",
    "section": "Filter dates",
    "text": "Filter dates\n\n(oldsched &lt;- filter(r_class_schedule, iso_date &lt; \"2023-01-30\") |&gt;\n  mutate(week_later = iso_date + 7,\n         days_since = today() - iso_date))\n\n# A tibble: 3 × 6\n  meeting date        topic               iso_date   week_later days_since\n    &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;               &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1       1 23 Jan 2023 Course introduction 2023-01-23 2023-01-30 668 days  \n2       2 25 Jan 2023 Working in RStudio  2023-01-25 2023-02-01 666 days  \n3       3 27 Jan 2023 Coding basics       2023-01-27 2023-02-03 664 days"
  },
  {
    "objectID": "slides/23_dates.html#solving-the-problem",
    "href": "slides/23_dates.html#solving-the-problem",
    "title": "Dates and times",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code generates data2 from data1?\n\n\n\n\ndata1\n\n# A tibble: 12 × 2\n   test_date  birth_date \n   &lt;date&gt;     &lt;chr&gt;      \n 1 2023-01-02 1997-07-14 \n 2 2023-01-02 1998-01-28 \n 3 2023-01-05 1967-07-23 \n 4 2023-01-05 Jan 9, 1960\n 5 2023-01-08 1950-11-09 \n 6 2023-01-14 2001-08-24 \n 7 2023-01-16 1979-09-23 \n 8 2023-01-23 1970-03-22 \n 9 2023-01-26 1957-04-21 \n10 2023-01-27 1989-03-07 \n11 2023-01-27 1983-11-03 \n12 2023-01-28 1989-01-31 \n\n\n\n\n\n\ndata2\n\n# A tibble: 9 × 4\n  test_date  birth_date age_at_testing day_of_birth\n  &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;         &lt;ord&gt;       \n1 2023-01-05 1967-07-23 20255 days     Sunday      \n2 2023-01-05 1960-01-09 23007 days     Saturday    \n3 2023-01-08 1950-11-09 26358 days     Thursday    \n4 2023-01-16 1979-09-23 15821 days     Sunday      \n5 2023-01-23 1970-03-22 19300 days     Sunday      \n6 2023-01-26 1957-04-21 24021 days     Sunday      \n7 2023-01-27 1989-03-07 12379 days     Tuesday     \n8 2023-01-27 1983-11-03 14330 days     Thursday    \n9 2023-01-28 1989-01-31 12415 days     Tuesday"
  },
  {
    "objectID": "slides/23_dates.html#lets-code",
    "href": "slides/23_dates.html#lets-code",
    "title": "Dates and times",
    "section": "Let’s code!",
    "text": "Let’s code!\nDates and times [Rmd]"
  },
  {
    "objectID": "slides/21_patterns.html#the-problem",
    "href": "slides/21_patterns.html#the-problem",
    "title": "Matching patterns",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat is needed to create data2 from data1?\n\n\n\ndata1\n\n# A tibble: 12 × 3\n   time      species  resp \n   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;\n 1 early-day dogfish  yes  \n 2 mid-day   bear dog no   \n 3 late-day  dog      yes  \n 4 daytime   dogfish  no   \n 5 early-day cat      yes  \n 6 mid-day   cat      no   \n 7 late-day  dogfish  no   \n 8 daytime   bear dog no   \n 9 early-day dogfish  &lt;NA&gt; \n10 mid-day   catfish  yes  \n11 late-day  cat      yes  \n12 daytime   bear dog yes  \n\n\n\n\ndata2\n\n# A tibble: 8 × 3\n  time      species  resp   \n  &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;  \n1 early-Day dogfish  yes    \n2 mid-Day   bear dog no     \n3 late-Day  dog      yes    \n4 daytime   dogfish  no     \n5 late-Day  dogfish  no     \n6 daytime   bear dog no     \n7 early-Day dogfish  no data\n8 daytime   bear dog yes"
  },
  {
    "objectID": "slides/21_patterns.html#set-up",
    "href": "slides/21_patterns.html#set-up",
    "title": "Matching patterns",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/21_patterns.html#mental-model",
    "href": "slides/21_patterns.html#mental-model",
    "title": "Matching patterns",
    "section": "Mental model",
    "text": "Mental model"
  },
  {
    "objectID": "slides/21_patterns.html#strings-with-stringr",
    "href": "slides/21_patterns.html#strings-with-stringr",
    "title": "Matching patterns",
    "section": "Strings with {stringr}",
    "text": "Strings with {stringr}\n\nlibrary(stringr)\n\n\n\n\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/21_patterns.html#regular-expressions",
    "href": "slides/21_patterns.html#regular-expressions",
    "title": "Matching patterns",
    "section": "Regular expressions",
    "text": "Regular expressions\nConcise and powerful language for describing patterns within strings\n(regex for short)"
  },
  {
    "objectID": "slides/21_patterns.html#regular-expressions-1",
    "href": "slides/21_patterns.html#regular-expressions-1",
    "title": "Matching patterns",
    "section": "Regular expressions",
    "text": "Regular expressions\nHere’s the regex I used to detect IP addresses: ^(?:(25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])(\\.(?!$)|$)){4}$"
  },
  {
    "objectID": "slides/21_patterns.html#matching-strings",
    "href": "slides/21_patterns.html#matching-strings",
    "title": "Matching patterns",
    "section": "Matching strings",
    "text": "Matching strings\nView string patterns with stringr::str_view_all()\n\n(x &lt;- c(\"apple\", \"banana\", \"pear\", NA))\n\n[1] \"apple\"  \"banana\" \"pear\"   NA      \n\nstr_view_all(x, \"a\")\n\n[1] │ &lt;a&gt;pple\n[2] │ b&lt;a&gt;n&lt;a&gt;n&lt;a&gt;\n[3] │ pe&lt;a&gt;r\n[4] │ NA"
  },
  {
    "objectID": "slides/21_patterns.html#regex-101",
    "href": "slides/21_patterns.html#regex-101",
    "title": "Matching patterns",
    "section": "Regex 101",
    "text": "Regex 101\n. is wildcard\n\nstr_view_all(x, \".a.\")\n\n[1] │ apple\n[2] │ &lt;ban&gt;ana\n[3] │ p&lt;ear&gt;\n[4] │ NA"
  },
  {
    "objectID": "slides/21_patterns.html#regex-101-1",
    "href": "slides/21_patterns.html#regex-101-1",
    "title": "Matching patterns",
    "section": "Regex 101",
    "text": "Regex 101\n^ to match the start of the string (like starts_with())\n$ to match the end of the string (like ends_with())\n\nstr_view_all(x, \"^a\")\n\n[1] │ &lt;a&gt;pple\n[2] │ banana\n[3] │ pear\n[4] │ NA\n\nstr_view_all(x, \"a$\")\n\n[1] │ apple\n[2] │ banan&lt;a&gt;\n[3] │ pear\n[4] │ NA"
  },
  {
    "objectID": "slides/21_patterns.html#regex-101-2",
    "href": "slides/21_patterns.html#regex-101-2",
    "title": "Matching patterns",
    "section": "Regex 101",
    "text": "Regex 101\n| matches one pattern OR another (e.g., this|that)\n\nstr_view_all(x, \"ap|an|ar\")\n\n[1] │ &lt;ap&gt;ple\n[2] │ b&lt;an&gt;&lt;an&gt;a\n[3] │ pe&lt;ar&gt;\n[4] │ NA\n\n\n\nWrap character groups in ()\n\nstr_view_all(\"Are you here or are you there?\", \"(A|a)re\")  \n\n[1] │ &lt;Are&gt; you here or &lt;are&gt; you there?"
  },
  {
    "objectID": "slides/21_patterns.html#regex-101-3",
    "href": "slides/21_patterns.html#regex-101-3",
    "title": "Matching patterns",
    "section": "Regex 101",
    "text": "Regex 101\n\\d matches any digit\n\n# view digits\nstr_view_all(\"March 10, 2020\", \"\\\\d\")\n\n[1] │ March &lt;1&gt;&lt;0&gt;, &lt;2&gt;&lt;0&gt;&lt;2&gt;&lt;0&gt;"
  },
  {
    "objectID": "slides/21_patterns.html#regex-101-4",
    "href": "slides/21_patterns.html#regex-101-4",
    "title": "Matching patterns",
    "section": "Regex 101",
    "text": "Regex 101\n[abc] matches individual characters (a, b, or c)\n\n# view everything with ab or a&lt;space&gt;\nstr_view_all(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[b ]\")\n\n[1] │ &lt;ab&gt;c\n[2] │ a.c\n[3] │ a*c\n[4] │ &lt;a &gt;c"
  },
  {
    "objectID": "slides/21_patterns.html#regex-101-5",
    "href": "slides/21_patterns.html#regex-101-5",
    "title": "Matching patterns",
    "section": "Regex 101",
    "text": "Regex 101\n[^abc] matches individual characters except a, b, or c\n\n# view everything except ab and a&lt;space&gt;\nstr_view_all(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[^b ]\")\n\n[1] │ abc\n[2] │ &lt;a.&gt;c\n[3] │ &lt;a*&gt;c\n[4] │ a c\n\n# view everything except digits\nstr_view_all(\"March 10, 2020\", \"[^\\\\d]\")  \n\n[1] │ &lt;M&gt;&lt;a&gt;&lt;r&gt;&lt;c&gt;&lt;h&gt;&lt; &gt;10&lt;,&gt;&lt; &gt;2020"
  },
  {
    "objectID": "slides/21_patterns.html#detecting-pattern-matches",
    "href": "slides/21_patterns.html#detecting-pattern-matches",
    "title": "Matching patterns",
    "section": "Detecting pattern matches",
    "text": "Detecting pattern matches\nDetect matching elements with stringr::str_detect()\n\nx\n\n[1] \"apple\"  \"banana\" \"pear\"   NA      \n\nstr_detect(x, \"e\")  # results in logical vector\n\n[1]  TRUE FALSE  TRUE    NA\n\n\n\n\nsum(str_detect(x, \"e\"), na.rm = TRUE)  # sum matching elements\n\n[1] 2\n\nmean(str_detect(x, \"e\"), na.rm = TRUE)  # calculate proportion of matches\n\n[1] 0.6666667"
  },
  {
    "objectID": "slides/21_patterns.html#extracting-pattern-matches",
    "href": "slides/21_patterns.html#extracting-pattern-matches",
    "title": "Matching patterns",
    "section": "Extracting pattern matches",
    "text": "Extracting pattern matches\nExtract observations matching pattern with filter() and str_detect()\n\npenguins |&gt;\n  filter(str_detect(sex, \"male\")) |&gt;  # select observations that include \"male\"\n  select(species, island, sex)\n\n# A tibble: 333 × 3\n   species island    sex   \n   &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt; \n 1 Adelie  Torgersen male  \n 2 Adelie  Torgersen female\n 3 Adelie  Torgersen female\n 4 Adelie  Torgersen female\n 5 Adelie  Torgersen male  \n 6 Adelie  Torgersen female\n 7 Adelie  Torgersen male  \n 8 Adelie  Torgersen female\n 9 Adelie  Torgersen male  \n10 Adelie  Torgersen male  \n# ℹ 323 more rows"
  },
  {
    "objectID": "slides/21_patterns.html#extracting-pattern-matches-1",
    "href": "slides/21_patterns.html#extracting-pattern-matches-1",
    "title": "Matching patterns",
    "section": "Extracting pattern matches",
    "text": "Extracting pattern matches\nExtract elements that match a pattern with stringr::str_subset()\n\nhead(words, n = 20)\n\n [1] \"a\"         \"able\"      \"about\"     \"absolute\"  \"accept\"    \"account\"  \n [7] \"achieve\"   \"across\"    \"act\"       \"active\"    \"actual\"    \"add\"      \n[13] \"address\"   \"admit\"     \"advertise\" \"affect\"    \"afford\"    \"after\"    \n[19] \"afternoon\" \"again\"    \n\n\n\n\nstr_subset(words, \"^rec\")  # select elements starting with \"rec\"\n\n[1] \"receive\"   \"recent\"    \"reckon\"    \"recognize\" \"recommend\" \"record\"   \n\nstr_subset(words, \"ing$\")  # select elements ending with \"ing\"\n\n[1] \"bring\"   \"during\"  \"evening\" \"king\"    \"meaning\" \"morning\" \"ring\"   \n[8] \"sing\"    \"thing\""
  },
  {
    "objectID": "slides/21_patterns.html#replacing-pattern-matches",
    "href": "slides/21_patterns.html#replacing-pattern-matches",
    "title": "Matching patterns",
    "section": "Replacing pattern matches",
    "text": "Replacing pattern matches\nReplace matches with new strings with stringr::str_replace() and stringr::str_replace_all()\n\nstr_replace(x, \"[aeiou]\", \"-\")  # replace only first instance of match\n\n[1] \"-pple\"  \"b-nana\" \"p-ar\"   NA      \n\n\n\n\nstr_replace_all(x, \"[aeiou]\", \"-\")  # replace all matches\n\n[1] \"-ppl-\"  \"b-n-n-\" \"p--r\"   NA      \n\nstr_replace_all(x, \"[^aeiou]\", \"-\")  # replace all matches\n\n[1] \"a---e\"  \"-a-a-a\" \"-ea-\"   NA"
  },
  {
    "objectID": "slides/21_patterns.html#replacing-pattern-matches-1",
    "href": "slides/21_patterns.html#replacing-pattern-matches-1",
    "title": "Matching patterns",
    "section": "Replacing pattern matches",
    "text": "Replacing pattern matches\nYou can use this to recode character variables, but…\n\nset.seed(50)\npenguins |&gt;\n  mutate(new_island = str_replace(island, \"Torgersen\", \"Party\")) |&gt; \n  select(species, island, new_island) |&gt; \n  slice_sample(n = 6)\n\n# A tibble: 6 × 3\n  species   island    new_island\n  &lt;fct&gt;     &lt;fct&gt;     &lt;chr&gt;     \n1 Adelie    Torgersen Party     \n2 Chinstrap Dream     Dream     \n3 Adelie    Dream     Dream     \n4 Chinstrap Dream     Dream     \n5 Gentoo    Biscoe    Biscoe    \n6 Gentoo    Biscoe    Biscoe    \n\n\nIt coerces to character data types\n\nI use this A LOT to clean up text data"
  },
  {
    "objectID": "slides/21_patterns.html#replacing-na",
    "href": "slides/21_patterns.html#replacing-na",
    "title": "Matching patterns",
    "section": "Replacing NA\n",
    "text": "Replacing NA\n\nReplace NA with another value with stringr::str_replace_na()\n\nx\n\n[1] \"apple\"  \"banana\" \"pear\"   NA      \n\nstr_replace_na(x)  # by default replaces NA with \"NA\"\n\n[1] \"apple\"  \"banana\" \"pear\"   \"NA\"    \n\nstr_replace_na(x, \"Missing\")  # but you can replace with other strings\n\n[1] \"apple\"   \"banana\"  \"pear\"    \"Missing\""
  },
  {
    "objectID": "slides/21_patterns.html#splitting-strings-1",
    "href": "slides/21_patterns.html#splitting-strings-1",
    "title": "Matching patterns",
    "section": "Splitting strings",
    "text": "Splitting strings\nSplit a string up into pieces with str_split()\n\nhead(sentences, n = 2)\n\n[1] \"The birch canoe slid on the smooth planks.\" \n[2] \"Glue the sheet to the dark blue background.\"\n\nsentences |&gt;\n  head(2) |&gt;\n  str_split(\" \")\n\n[[1]]\n[1] \"The\"     \"birch\"   \"canoe\"   \"slid\"    \"on\"      \"the\"     \"smooth\" \n[8] \"planks.\"\n\n[[2]]\n[1] \"Glue\"        \"the\"         \"sheet\"       \"to\"          \"the\"        \n[6] \"dark\"        \"blue\"        \"background.\"\n\n\n\nNotice this produces a list. Why?"
  },
  {
    "objectID": "slides/21_patterns.html#splitting-strings-2",
    "href": "slides/21_patterns.html#splitting-strings-2",
    "title": "Matching patterns",
    "section": "Splitting strings",
    "text": "Splitting strings\nConvert to matrix with simplify\n\nsentences[c(1:2, 5)] |&gt;\n  str_split(\" \", simplify = TRUE)\n\n     [,1]   [,2]    [,3]    [,4]     [,5]  [,6]    [,7]     [,8]         \n[1,] \"The\"  \"birch\" \"canoe\" \"slid\"   \"on\"  \"the\"   \"smooth\" \"planks.\"    \n[2,] \"Glue\" \"the\"   \"sheet\" \"to\"     \"the\" \"dark\"  \"blue\"   \"background.\"\n[3,] \"Rice\" \"is\"    \"often\" \"served\" \"in\"  \"round\" \"bowls.\" \"\""
  },
  {
    "objectID": "slides/21_patterns.html#solving-the-problem",
    "href": "slides/21_patterns.html#solving-the-problem",
    "title": "Matching patterns",
    "section": "Solving the problem",
    "text": "Solving the problem\n\n\n\ndata1\n\n# A tibble: 12 × 3\n   time      species  resp \n   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;\n 1 early-day dogfish  yes  \n 2 mid-day   bear dog no   \n 3 late-day  dog      yes  \n 4 daytime   dogfish  no   \n 5 early-day cat      yes  \n 6 mid-day   cat      no   \n 7 late-day  dogfish  no   \n 8 daytime   bear dog no   \n 9 early-day dogfish  &lt;NA&gt; \n10 mid-day   catfish  yes  \n11 late-day  cat      yes  \n12 daytime   bear dog yes  \n\n\n\n\ndata2\n\n# A tibble: 8 × 3\n  time      species  resp   \n  &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;  \n1 early-Day dogfish  yes    \n2 mid-Day   bear dog no     \n3 late-Day  dog      yes    \n4 daytime   dogfish  no     \n5 late-Day  dogfish  no     \n6 daytime   bear dog no     \n7 early-Day dogfish  no data\n8 daytime   bear dog yes"
  },
  {
    "objectID": "slides/21_patterns.html#lets-code",
    "href": "slides/21_patterns.html#lets-code",
    "title": "Matching patterns",
    "section": "Let’s code!",
    "text": "Let’s code!\nMatching patterns [Rmd]"
  },
  {
    "objectID": "slides/19_numbers.html#the-problem",
    "href": "slides/19_numbers.html#the-problem",
    "title": "Numbers",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat is needed to create data2 from data1?\n\n\n\ndata1\n\n# A tibble: 12 × 3\n     val1   val2    val3\n    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 0.773  0.470  0.00431\n 2 0.827  0.751  0.00923\n 3 0.746  0.220  0.00814\n 4 0.953  0.199  0.00767\n 5 0.298  0.894  0.00221\n 6 0.860  0.0149 0.00499\n 7 0.0460 0.956  0.00779\n 8 0.947  0.162  0.00875\n 9 0.511  0.189  0.00986\n10 0.712  0.0969 0.00862\n11 0.944  0.370  0.00209\n12 0.834  0.585  0.00420\n\n\n\n\ndata2\n\n# A tibble: 12 × 3\n   percent_val1 log_val2 val3   \n          &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;  \n 1         77.3  -0.756  4.3e-03\n 2         82.7  -0.287  9.2e-03\n 3         74.6  -1.51   8.1e-03\n 4         95.3  -1.61   7.7e-03\n 5         29.8  -0.113  2.2e-03\n 6         86.0  -4.20   5.0e-03\n 7          4.6  -0.0452 7.8e-03\n 8         94.7  -1.82   8.7e-03\n 9         51.1  -1.67   9.9e-03\n10         71.2  -2.33   8.6e-03\n11         94.4  -0.994  2.1e-03\n12         83.4  -0.536  4.2e-03"
  },
  {
    "objectID": "slides/19_numbers.html#set-up",
    "href": "slides/19_numbers.html#set-up",
    "title": "Numbers",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "slides/19_numbers.html#types-of-numbers",
    "href": "slides/19_numbers.html#types-of-numbers",
    "title": "Numbers",
    "section": "Types of numbers",
    "text": "Types of numbers\nDoubles are floating point numbers\n\n\n\n\n\n\nNote\n\n\nFloating point number: a number without a fixed number of digits after the decimal point\n\n\n\nFloating point numbers ≈ scientific notation"
  },
  {
    "objectID": "slides/19_numbers.html#types-of-numbers-1",
    "href": "slides/19_numbers.html#types-of-numbers-1",
    "title": "Numbers",
    "section": "Types of numbers",
    "text": "Types of numbers\nComputer memory is limited, so you cannot store numbers with infinite precision and floating points are stored imprecisely\n\nsqrt(2) ^ 2 == 2\n\n[1] FALSE\n\n1 / 49 * 49 == 1\n\n[1] FALSE"
  },
  {
    "objectID": "slides/19_numbers.html#comparing-numbers",
    "href": "slides/19_numbers.html#comparing-numbers",
    "title": "Numbers",
    "section": "Comparing numbers",
    "text": "Comparing numbers\n\n\n\nx &lt;- 1\ny &lt;- 1.00000000000001\nz &lt;- 1.001\n\n\n\nx == y\n\n[1] FALSE\n\nall.equal(x, y)\n\n[1] TRUE\n\nall.equal(x, z)\n\n[1] \"Mean relative difference: 0.001\"\n\nall.equal(x, z, tolerance = 1e-2)\n\n[1] TRUE\n\n\n\n\n\n\nsqrt(2) ^ 2 == 2\n\n[1] FALSE\n\nall.equal(sqrt(2) ^ 2, 2)\n\n[1] TRUE\n\ndplyr::near(sqrt(2) ^ 2, 2)\n\n[1] TRUE"
  },
  {
    "objectID": "slides/19_numbers.html#counts",
    "href": "slides/19_numbers.html#counts",
    "title": "Numbers",
    "section": "Counts",
    "text": "Counts\nAs a reminder, we’ve already seen how to use dplyr::count()\n\ncount(flights, carrier)\n\n# A tibble: 16 × 2\n   carrier     n\n   &lt;chr&gt;   &lt;int&gt;\n 1 9E      18460\n 2 AA      32729\n 3 AS        714\n 4 B6      54635\n 5 DL      48110\n 6 EV      54173\n 7 F9        685\n 8 FL       3260\n 9 HA        342\n10 MQ      26397\n11 OO         32\n12 UA      58665\n13 US      20536\n14 VX       5162\n15 WN      12275\n16 YV        601"
  },
  {
    "objectID": "slides/19_numbers.html#counts-1",
    "href": "slides/19_numbers.html#counts-1",
    "title": "Numbers",
    "section": "Counts",
    "text": "Counts\n\n\nWe can also automatically sort by count.\n\ncount(flights, carrier, sort = TRUE)\n\n# A tibble: 16 × 2\n   carrier     n\n   &lt;chr&gt;   &lt;int&gt;\n 1 UA      58665\n 2 B6      54635\n 3 EV      54173\n 4 DL      48110\n 5 AA      32729\n 6 MQ      26397\n 7 US      20536\n 8 9E      18460\n 9 WN      12275\n10 VX       5162\n11 FL       3260\n12 AS        714\n13 F9        685\n14 YV        601\n15 HA        342\n16 OO         32\n\n\n\nAnd sum up totals instead of just count\n\ncount(flights, carrier, wt = distance)\n\n# A tibble: 16 × 2\n   carrier        n\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 9E       9788152\n 2 AA      43864584\n 3 AS       1715028\n 4 B6      58384137\n 5 DL      59507317\n 6 EV      30498951\n 7 F9       1109700\n 8 FL       2167344\n 9 HA       1704186\n10 MQ      15033955\n11 OO         16026\n12 UA      89705524\n13 US      11365778\n14 VX      12902327\n15 WN      12229203\n16 YV        225395"
  },
  {
    "objectID": "slides/19_numbers.html#counts-2",
    "href": "slides/19_numbers.html#counts-2",
    "title": "Numbers",
    "section": "Counts",
    "text": "Counts\n\n\nRemember n() counts inside a summarise()\n\nflights |&gt; \n  group_by(carrier) |&gt; \n  summarise(n = n())\n\n# A tibble: 16 × 2\n   carrier     n\n   &lt;chr&gt;   &lt;int&gt;\n 1 9E      18460\n 2 AA      32729\n 3 AS        714\n 4 B6      54635\n 5 DL      48110\n 6 EV      54173\n 7 F9        685\n 8 FL       3260\n 9 HA        342\n10 MQ      26397\n11 OO         32\n12 UA      58665\n13 US      20536\n14 VX       5162\n15 WN      12275\n16 YV        601\n\n\n\n\nn_distinct() counts instances within a group\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarise(carriers = n_distinct(carrier))\n\n# A tibble: 105 × 2\n   dest  carriers\n   &lt;chr&gt;    &lt;int&gt;\n 1 ABQ          1\n 2 ACK          1\n 3 ALB          1\n 4 ANC          1\n 5 ATL          7\n 6 AUS          6\n 7 AVL          2\n 8 BDL          2\n 9 BGR          2\n10 BHM          1\n# ℹ 95 more rows"
  },
  {
    "objectID": "slides/19_numbers.html#counting-nas",
    "href": "slides/19_numbers.html#counting-nas",
    "title": "Numbers",
    "section": "Counting NAs",
    "text": "Counting NAs\nTo count NAs, you can sum() up TRUE responses to is.na()\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(n_cancelled = sum(is.na(dep_time)))\n\n# A tibble: 105 × 2\n   dest  n_cancelled\n   &lt;chr&gt;       &lt;int&gt;\n 1 ABQ             0\n 2 ACK             0\n 3 ALB            20\n 4 ANC             0\n 5 ATL           317\n 6 AUS            21\n 7 AVL            12\n 8 BDL            31\n 9 BGR            15\n10 BHM            25\n# ℹ 95 more rows"
  },
  {
    "objectID": "slides/19_numbers.html#counting-nas-1",
    "href": "slides/19_numbers.html#counting-nas-1",
    "title": "Numbers",
    "section": "Counting NAs",
    "text": "Counting NAs\nThis trick can be used for any logical vector\n\nsum(flights$month == 1)\n\n[1] 27004\n\nnrow(filter(flights, month == 1))\n\n[1] 27004"
  },
  {
    "objectID": "slides/19_numbers.html#operations",
    "href": "slides/19_numbers.html#operations",
    "title": "Numbers",
    "section": "Operations",
    "text": "Operations\nMathematical operators are recycled across all elements in a vector\n\n0:10 * 5\n\n [1]  0  5 10 15 20 25 30 35 40 45 50\n\n\n\nYou can operate with vectors &gt; 1, but the larger vector must be a multiple of the smaller vector\n\n0:10 * c(5, 6)\n\nWarning in 0:10 * c(5, 6): longer object length is not a multiple of shorter\nobject length\n\n\n [1]  0  6 10 18 20 30 30 42 40 54 50\n\n\n\n0:11 * c(5, 6)\n\n [1]  0  6 10 18 20 30 30 42 40 54 50 66"
  },
  {
    "objectID": "slides/19_numbers.html#mathematical-transformations",
    "href": "slides/19_numbers.html#mathematical-transformations",
    "title": "Numbers",
    "section": "Mathematical transformations",
    "text": "Mathematical transformations\n\n\n\nsqrt()\nlog()\nlog10()\nlog2()\nsin()\nasin()\n\n\n\nsqrt(seq(0, 100, 10))\n\n [1]  0.000000  3.162278  4.472136  5.477226  6.324555  7.071068  7.745967\n [8]  8.366600  8.944272  9.486833 10.000000\n\nlog(runif(10))\n\n [1] -0.3921567 -0.3017750 -2.4044192 -0.6672081 -0.3630729 -1.9276563\n [7] -1.0672688 -4.2340097 -0.8112143 -1.0013072\n\nasin(sqrt(runif(10)))\n\n [1] 0.8077234 1.1635879 0.1599809 0.8139120 0.5528058 0.6495491 1.2270613\n [8] 0.9685195 0.7673122 0.8240033"
  },
  {
    "objectID": "slides/19_numbers.html#rounding",
    "href": "slides/19_numbers.html#rounding",
    "title": "Numbers",
    "section": "Rounding",
    "text": "Rounding\nControl significant digits with round()\n\nround(123.456, 2)  # two digits\n\n[1] 123.46\n\nround(123.456, 1)  # one digit\n\n[1] 123.5\n\nround(123.456) # whole number\n\n[1] 123\n\nround(123.456, -1) # round to nearest ten\n\n[1] 120\n\nround(123.456, -2) # round to nearest hundred\n\n[1] 100"
  },
  {
    "objectID": "slides/19_numbers.html#formatting",
    "href": "slides/19_numbers.html#formatting",
    "title": "Numbers",
    "section": "Formatting",
    "text": "Formatting\nWhen numbers get too big, too small, or need other formatting, use format()\n\n\n\n(x &lt;- 0.0020)\n\n[1] 0.002\n\nformat(x, scientific = TRUE)\n\n[1] \"2e-03\"\n\nformat(x, nsmall = 4)\n\n[1] \"0.0020\"\n\n\n\n\n\n(y &lt;- 12345678.9)\n\n[1] 12345679\n\nformat(y, scientific = TRUE, \n       digits = 3)\n\n[1] \"1.23e+07\"\n\nformat(y, big.mark = \",\")\n\n[1] \"12,345,679\""
  },
  {
    "objectID": "slides/19_numbers.html#cutting-numbers-into-ranges",
    "href": "slides/19_numbers.html#cutting-numbers-into-ranges",
    "title": "Numbers",
    "section": "Cutting numbers into ranges",
    "text": "Cutting numbers into ranges\nIf you need to bin numbers into ranges, use cut()\n\nset.seed(1)\n(x &lt;- runif(12, min = 0, max = 100))\n\n [1] 26.550866 37.212390 57.285336 90.820779 20.168193 89.838968 94.467527\n [8] 66.079779 62.911404  6.178627 20.597457 17.655675\n\ncut(x, breaks = c(0, 33, 66, 100))\n\n [1] (0,33]   (33,66]  (33,66]  (66,100] (0,33]   (66,100] (66,100] (66,100]\n [9] (33,66]  (0,33]   (0,33]   (0,33]  \nLevels: (0,33] (33,66] (66,100]\n\n\n\n\ncut(x, breaks = c(0, 33, 66, 100), labels = c(\"Low\", \"Medium\", \"High\"))\n\n [1] Low    Medium Medium High   Low    High   High   High   Medium Low   \n[11] Low    Low   \nLevels: Low Medium High"
  },
  {
    "objectID": "slides/19_numbers.html#solving-the-problem",
    "href": "slides/19_numbers.html#solving-the-problem",
    "title": "Numbers",
    "section": "Solving the problem",
    "text": "Solving the problem\n\n\n\ndata1\n\n# A tibble: 12 × 3\n     val1   val2    val3\n    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 0.773  0.470  0.00431\n 2 0.827  0.751  0.00923\n 3 0.746  0.220  0.00814\n 4 0.953  0.199  0.00767\n 5 0.298  0.894  0.00221\n 6 0.860  0.0149 0.00499\n 7 0.0460 0.956  0.00779\n 8 0.947  0.162  0.00875\n 9 0.511  0.189  0.00986\n10 0.712  0.0969 0.00862\n11 0.944  0.370  0.00209\n12 0.834  0.585  0.00420\n\n\n\n\ndata2\n\n# A tibble: 12 × 3\n   percent_val1 log_val2 val3   \n          &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;  \n 1         77.3  -0.756  4.3e-03\n 2         82.7  -0.287  9.2e-03\n 3         74.6  -1.51   8.1e-03\n 4         95.3  -1.61   7.7e-03\n 5         29.8  -0.113  2.2e-03\n 6         86.0  -4.20   5.0e-03\n 7          4.6  -0.0452 7.8e-03\n 8         94.7  -1.82   8.7e-03\n 9         51.1  -1.67   9.9e-03\n10         71.2  -2.33   8.6e-03\n11         94.4  -0.994  2.1e-03\n12         83.4  -0.536  4.2e-03"
  },
  {
    "objectID": "slides/19_numbers.html#lets-code",
    "href": "slides/19_numbers.html#lets-code",
    "title": "Numbers",
    "section": "Let’s code!",
    "text": "Let’s code!\nNumbers [Rmd]"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#the-problem",
    "href": "slides/17_mergingcolumns.html#the-problem",
    "title": "Merging columns",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat is needed to create data3 from data1 and data2?\n\n\n\ndata1\n\n# A tibble: 12 × 3\n      id  cond  resp\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1     1     1 0.689\n 2     1     2 0.284\n 3     1     3 0.166\n 4     2     1 0.331\n 5     2     2 0.665\n 6     2     3 0.969\n 7     3     1 0.453\n 8     3     2 0.877\n 9     3     3 0.37 \n10     4     1 0.65 \n11     4     2 0.156\n12     4     3 0.76 \n\n\n\n\ndata2\n\n# A tibble: 6 × 2\n     id   age\n  &lt;int&gt; &lt;int&gt;\n1     1    50\n2     2    48\n3     3    65\n4     4    33\n5     5    20\n6     6    24\n\n\n\n\ndata3\n\n# A tibble: 12 × 4\n      id   age  cond  resp\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1     1    50     1 0.689\n 2     1    50     2 0.284\n 3     1    50     3 0.166\n 4     2    48     1 0.331\n 5     2    48     2 0.665\n 6     2    48     3 0.969\n 7     3    65     1 0.453\n 8     3    65     2 0.877\n 9     3    65     3 0.37 \n10     4    33     1 0.65 \n11     4    33     2 0.156\n12     4    33     3 0.76"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#mental-model-of-merging",
    "href": "slides/17_mergingcolumns.html#mental-model-of-merging",
    "title": "Merging columns",
    "section": "Mental model of merging",
    "text": "Mental model of merging"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#set-up",
    "href": "slides/17_mergingcolumns.html#set-up",
    "title": "Merging columns",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(dplyr)\nlibrary(nycflights13)\n(flights2 &lt;- select(flights, year:dep_time, carrier, tailnum))\n\n# A tibble: 336,776 × 6\n    year month   day dep_time carrier tailnum\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013     1     1      517 UA      N14228 \n 2  2013     1     1      533 UA      N24211 \n 3  2013     1     1      542 AA      N619AA \n 4  2013     1     1      544 B6      N804JB \n 5  2013     1     1      554 DL      N668DN \n 6  2013     1     1      554 UA      N39463 \n 7  2013     1     1      555 B6      N516JB \n 8  2013     1     1      557 EV      N829AS \n 9  2013     1     1      557 B6      N593JB \n10  2013     1     1      558 AA      N3ALAA \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#set-up-1",
    "href": "slides/17_mergingcolumns.html#set-up-1",
    "title": "Merging columns",
    "section": "Set-up",
    "text": "Set-up\n\n(planes2 &lt;- select(planes, tailnum, year, model, seats))\n\n# A tibble: 3,322 × 4\n   tailnum  year model     seats\n   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;     &lt;int&gt;\n 1 N10156   2004 EMB-145XR    55\n 2 N102UW   1998 A320-214    182\n 3 N103US   1999 A320-214    182\n 4 N104UW   1999 A320-214    182\n 5 N10575   2002 EMB-145LR    55\n 6 N105UW   1999 A320-214    182\n 7 N107US   1999 A320-214    182\n 8 N108UW   1999 A320-214    182\n 9 N109UW   1999 A320-214    182\n10 N110UW   1999 A320-214    182\n# ℹ 3,312 more rows"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#joining-with-dplyr",
    "href": "slides/17_mergingcolumns.html#joining-with-dplyr",
    "title": "Merging columns",
    "section": "Joining with {dplyr}",
    "text": "Joining with {dplyr}\n\nlibrary(dplyr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Garrick Aden-Buie"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#merging-data-1",
    "href": "slides/17_mergingcolumns.html#merging-data-1",
    "title": "Merging columns",
    "section": "Merging data",
    "text": "Merging data\n\nlibrary(nycflights13)"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#keys",
    "href": "slides/17_mergingcolumns.html#keys",
    "title": "Merging columns",
    "section": "Keys",
    "text": "Keys\n\nUnique identifiers of observations\nKeys may take some work to clean first\nDouble check keys for uniqueness/duplicates\nCreate surrogate key if no primary key exists"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#joins",
    "href": "slides/17_mergingcolumns.html#joins",
    "title": "Merging columns",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#mutating-joins",
    "href": "slides/17_mergingcolumns.html#mutating-joins",
    "title": "Merging columns",
    "section": "Mutating joins",
    "text": "Mutating joins\nAffects columns"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#mutating-joins-1",
    "href": "slides/17_mergingcolumns.html#mutating-joins-1",
    "title": "Merging columns",
    "section": "Mutating joins",
    "text": "Mutating joins\nAffects columns"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#inner-joins",
    "href": "slides/17_mergingcolumns.html#inner-joins",
    "title": "Merging columns",
    "section": "Inner joins",
    "text": "Inner joins\nKeep only matching observations"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#inner-joins-1",
    "href": "slides/17_mergingcolumns.html#inner-joins-1",
    "title": "Merging columns",
    "section": "Inner joins",
    "text": "Inner joins\n\n\n\n\nx\n\n# A tibble: 3 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n    key val_y\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 y1   \n2     2 y2   \n3     4 y3   \n\n\n\n\n\ninner_join(x, y, by = \"key\")\n\n# A tibble: 2 × 3\n    key val_x val_y\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n\n\n\nx |&gt; \n  inner_join(y, by = \"key\")\n\n# A tibble: 2 × 3\n    key val_x val_y\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#inner-joins-2",
    "href": "slides/17_mergingcolumns.html#inner-joins-2",
    "title": "Merging columns",
    "section": "Inner joins",
    "text": "Inner joins\n\n\nglimpse(flights2)\n\nRows: 336,776\nColumns: 6\n$ year     &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, 558, 5…\n$ carrier  &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"AA\", \"…\n$ tailnum  &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N39463\", \"…\n\nglimpse(planes2)\n\nRows: 3,322\nColumns: 4\n$ tailnum &lt;chr&gt; \"N10156\", \"N102UW\", \"N103US\", \"N104UW\", \"N10575\", \"N105UW\", \"N…\n$ year    &lt;int&gt; 2004, 1998, 1999, 1999, 2002, 1999, 1999, 1999, 1999, 1999, 20…\n$ model   &lt;chr&gt; \"EMB-145XR\", \"A320-214\", \"A320-214\", \"A320-214\", \"EMB-145LR\", …\n$ seats   &lt;int&gt; 55, 182, 182, 182, 55, 182, 182, 182, 182, 182, 55, 55, 55, 55…"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#inner-joins-3",
    "href": "slides/17_mergingcolumns.html#inner-joins-3",
    "title": "Merging columns",
    "section": "Inner joins",
    "text": "Inner joins\n\nflights2 |&gt;\n  inner_join(planes2, by = \"tailnum\")\n\n# A tibble: 284,170 × 9\n   year.x month   day dep_time carrier tailnum year.y model       seats\n    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt;\n 1   2013     1     1      517 UA      N14228    1999 737-824       149\n 2   2013     1     1      533 UA      N24211    1998 737-824       149\n 3   2013     1     1      542 AA      N619AA    1990 757-223       178\n 4   2013     1     1      544 B6      N804JB    2012 A320-232      200\n 5   2013     1     1      554 DL      N668DN    1991 757-232       178\n 6   2013     1     1      554 UA      N39463    2012 737-924ER     191\n 7   2013     1     1      555 B6      N516JB    2000 A320-232      200\n 8   2013     1     1      557 EV      N829AS    1998 CL-600-2B19    55\n 9   2013     1     1      557 B6      N593JB    2004 A320-232      200\n10   2013     1     1      558 B6      N793JB    2011 A320-232      200\n# ℹ 284,160 more rows\n\n\n\nWhat do you notice about the result?"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#inner-joins-4",
    "href": "slides/17_mergingcolumns.html#inner-joins-4",
    "title": "Merging columns",
    "section": "Inner joins",
    "text": "Inner joins\n\n\n\n\n\n\nWarning\n\n\nOnly use inner joins when you want the intersection of the two data sets!"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#outer-joins",
    "href": "slides/17_mergingcolumns.html#outer-joins",
    "title": "Merging columns",
    "section": "Outer joins",
    "text": "Outer joins\n\n\nKeep observations that appear in at least one of the tables\n\nLeft\nRight\nFull"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#left-joins",
    "href": "slides/17_mergingcolumns.html#left-joins",
    "title": "Merging columns",
    "section": "Left joins",
    "text": "Left joins\nKeep only left observations"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#left-joins-1",
    "href": "slides/17_mergingcolumns.html#left-joins-1",
    "title": "Merging columns",
    "section": "Left joins",
    "text": "Left joins\n\n\n\n\nx\n\n# A tibble: 3 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n    key val_y\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 y1   \n2     2 y2   \n3     4 y3   \n\n\n\n\nleft_join(x, y, by = \"key\")\n\n# A tibble: 3 × 3\n    key val_x val_y\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    &lt;NA&gt;"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#left-joins-2",
    "href": "slides/17_mergingcolumns.html#left-joins-2",
    "title": "Merging columns",
    "section": "Left joins",
    "text": "Left joins\n\nhead(flights2)\n\n# A tibble: 6 × 6\n   year month   day dep_time carrier tailnum\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n1  2013     1     1      517 UA      N14228 \n2  2013     1     1      533 UA      N24211 \n3  2013     1     1      542 AA      N619AA \n4  2013     1     1      544 B6      N804JB \n5  2013     1     1      554 DL      N668DN \n6  2013     1     1      554 UA      N39463 \n\nhead(planes2)\n\n# A tibble: 6 × 4\n  tailnum  year model     seats\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;     &lt;int&gt;\n1 N10156   2004 EMB-145XR    55\n2 N102UW   1998 A320-214    182\n3 N103US   1999 A320-214    182\n4 N104UW   1999 A320-214    182\n5 N10575   2002 EMB-145LR    55\n6 N105UW   1999 A320-214    182"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#left-joins-3",
    "href": "slides/17_mergingcolumns.html#left-joins-3",
    "title": "Merging columns",
    "section": "Left joins",
    "text": "Left joins\n\nflights2 |&gt;\n  left_join(planes2, by = \"tailnum\")\n\n# A tibble: 336,776 × 9\n   year.x month   day dep_time carrier tailnum year.y model       seats\n    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt;\n 1   2013     1     1      517 UA      N14228    1999 737-824       149\n 2   2013     1     1      533 UA      N24211    1998 737-824       149\n 3   2013     1     1      542 AA      N619AA    1990 757-223       178\n 4   2013     1     1      544 B6      N804JB    2012 A320-232      200\n 5   2013     1     1      554 DL      N668DN    1991 757-232       178\n 6   2013     1     1      554 UA      N39463    2012 737-924ER     191\n 7   2013     1     1      555 B6      N516JB    2000 A320-232      200\n 8   2013     1     1      557 EV      N829AS    1998 CL-600-2B19    55\n 9   2013     1     1      557 B6      N593JB    2004 A320-232      200\n10   2013     1     1      558 AA      N3ALAA      NA &lt;NA&gt;           NA\n# ℹ 336,766 more rows\n\n\n\n\n\n\n\n\n\nWarning\n\n\nSelect columns used to join with argument by"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#inner-joins-5",
    "href": "slides/17_mergingcolumns.html#inner-joins-5",
    "title": "Merging columns",
    "section": "Inner joins",
    "text": "Inner joins\nOtherwise, it uses all shared columns, which may be wrong\n\nflights2 |&gt;\n  left_join(planes2)\n\n# A tibble: 336,776 × 8\n    year month   day dep_time carrier tailnum model seats\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n 1  2013     1     1      517 UA      N14228  &lt;NA&gt;     NA\n 2  2013     1     1      533 UA      N24211  &lt;NA&gt;     NA\n 3  2013     1     1      542 AA      N619AA  &lt;NA&gt;     NA\n 4  2013     1     1      544 B6      N804JB  &lt;NA&gt;     NA\n 5  2013     1     1      554 DL      N668DN  &lt;NA&gt;     NA\n 6  2013     1     1      554 UA      N39463  &lt;NA&gt;     NA\n 7  2013     1     1      555 B6      N516JB  &lt;NA&gt;     NA\n 8  2013     1     1      557 EV      N829AS  &lt;NA&gt;     NA\n 9  2013     1     1      557 B6      N593JB  &lt;NA&gt;     NA\n10  2013     1     1      558 AA      N3ALAA  &lt;NA&gt;     NA\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#right-joins",
    "href": "slides/17_mergingcolumns.html#right-joins",
    "title": "Merging columns",
    "section": "Right joins",
    "text": "Right joins\nKeep only right observations"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#right-joins-1",
    "href": "slides/17_mergingcolumns.html#right-joins-1",
    "title": "Merging columns",
    "section": "Right joins",
    "text": "Right joins\n\n\n\n\nx\n\n# A tibble: 3 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n    key val_y\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 y1   \n2     2 y2   \n3     4 y3   \n\n\n\n\nright_join(x, y, by = \"key\")\n\n# A tibble: 3 × 3\n    key val_x val_y\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n3     4 &lt;NA&gt;  y3"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#full-joins",
    "href": "slides/17_mergingcolumns.html#full-joins",
    "title": "Merging columns",
    "section": "Full joins",
    "text": "Full joins\nKeep all observations"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#full-joins-1",
    "href": "slides/17_mergingcolumns.html#full-joins-1",
    "title": "Merging columns",
    "section": "Full joins",
    "text": "Full joins\n\n\n\n\nx\n\n# A tibble: 3 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n    key val_y\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 y1   \n2     2 y2   \n3     4 y3   \n\n\n\n\nfull_join(x, y, by = \"key\")\n\n# A tibble: 4 × 3\n    key val_x val_y\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    &lt;NA&gt; \n4     4 &lt;NA&gt;  y3"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#solving-the-problem",
    "href": "slides/17_mergingcolumns.html#solving-the-problem",
    "title": "Merging columns",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code combines data1 and data2 into data3?\n\n\n\ndata1\n\n# A tibble: 12 × 3\n      id  cond  resp\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1     1     1 0.689\n 2     1     2 0.284\n 3     1     3 0.166\n 4     2     1 0.331\n 5     2     2 0.665\n 6     2     3 0.969\n 7     3     1 0.453\n 8     3     2 0.877\n 9     3     3 0.37 \n10     4     1 0.65 \n11     4     2 0.156\n12     4     3 0.76 \n\n\n\n\ndata2\n\n# A tibble: 6 × 2\n     id   age\n  &lt;int&gt; &lt;int&gt;\n1     1    50\n2     2    48\n3     3    65\n4     4    33\n5     5    20\n6     6    24\n\n\n\n\ndata3\n\n# A tibble: 12 × 4\n      id   age  cond  resp\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1     1    50     1 0.689\n 2     1    50     2 0.284\n 3     1    50     3 0.166\n 4     2    48     1 0.331\n 5     2    48     2 0.665\n 6     2    48     3 0.969\n 7     3    65     1 0.453\n 8     3    65     2 0.877\n 9     3    65     3 0.37 \n10     4    33     1 0.65 \n11     4    33     2 0.156\n12     4    33     3 0.76"
  },
  {
    "objectID": "slides/17_mergingcolumns.html#lets-code",
    "href": "slides/17_mergingcolumns.html#lets-code",
    "title": "Merging columns",
    "section": "Let’s code!",
    "text": "Let’s code!\nMerging columns [Rmd]"
  },
  {
    "objectID": "slides/15_pivoting.html#how-do-i-wrangle-that",
    "href": "slides/15_pivoting.html#how-do-i-wrangle-that",
    "title": "Pivoting data",
    "section": "How do I wrangle that?",
    "text": "How do I wrangle that?\n\n\nreturn subset of rows based on position in data frame\nreturn subset of rows based on column values\nreturn subset of columns based on position in data frame\nreturn subset of columns based on name\nreorder rows by column values\nreorder columns manually\ncreate new columns\naggregate rows with summary functions"
  },
  {
    "objectID": "slides/15_pivoting.html#mental-model-of-data-analysis",
    "href": "slides/15_pivoting.html#mental-model-of-data-analysis",
    "title": "Pivoting data",
    "section": "Mental model of data analysis",
    "text": "Mental model of data analysis"
  },
  {
    "objectID": "slides/15_pivoting.html#the-problem",
    "href": "slides/15_pivoting.html#the-problem",
    "title": "Pivoting data",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat needs to happen to create data2 from data1?\n\n\n\ndata1\n\n# A tibble: 4 × 4\n     id cond1 cond2 cond3\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 0.935 0.896 0.422\n2     2 0.599 0.493 0.539\n3     3 0.933 0.798 0.724\n4     4 0.337 0.890 0.705\n\n\n\n\ndata2\n\n   id condition  response\n1   1     cond1 0.9349457\n2   1     cond2 0.8955915\n3   1     cond3 0.4221161\n4   2     cond1 0.5992728\n5   2     cond2 0.4928767\n6   2     cond3 0.5392186\n7   3     cond1 0.9325012\n8   3     cond2 0.7983170\n9   3     cond3 0.7238427\n10  4     cond1 0.3368520\n11  4     cond2 0.8904755\n12  4     cond3 0.7046291"
  },
  {
    "objectID": "slides/15_pivoting.html#mental-model-of-tidy-data",
    "href": "slides/15_pivoting.html#mental-model-of-tidy-data",
    "title": "Pivoting data",
    "section": "Mental model of tidy data",
    "text": "Mental model of tidy data"
  },
  {
    "objectID": "slides/15_pivoting.html#tidying-data-with-tidyr-and-dplyr",
    "href": "slides/15_pivoting.html#tidying-data-with-tidyr-and-dplyr",
    "title": "Pivoting data",
    "section": "Tidying data with {tidyr} and {dplyr}",
    "text": "Tidying data with {tidyr} and {dplyr}\n\nlibrary(tidyr)\nlibrary(dplyr)\n\n\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/15_pivoting.html#what-is-tidy-data",
    "href": "slides/15_pivoting.html#what-is-tidy-data",
    "title": "Pivoting data",
    "section": "What is tidy data?",
    "text": "What is tidy data?\n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell"
  },
  {
    "objectID": "slides/15_pivoting.html#tidy-data-1",
    "href": "slides/15_pivoting.html#tidy-data-1",
    "title": "Pivoting data",
    "section": "Tidy data",
    "text": "Tidy data\nEvery variable is a column, every observation is a row, and every value is a cell\n\n\n\n\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\n\n\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583"
  },
  {
    "objectID": "slides/15_pivoting.html#tidy-data-2",
    "href": "slides/15_pivoting.html#tidy-data-2",
    "title": "Pivoting data",
    "section": "Tidy data",
    "text": "Tidy data\nEvery variable is a column, every observation is a row, and every value is a cell\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583"
  },
  {
    "objectID": "slides/15_pivoting.html#tidy-data-3",
    "href": "slides/15_pivoting.html#tidy-data-3",
    "title": "Pivoting data",
    "section": "Tidy data",
    "text": "Tidy data\nEvery variable is a column, every observation is a row, and every value is a cell\n\n\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\n\ntable4b\n\n# A tibble: 3 × 3\n  country         `1999`     `2000`\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan   19987071   20595360\n2 Brazil       172006362  174504898\n3 China       1272915272 1280428583"
  },
  {
    "objectID": "slides/15_pivoting.html#tidy-data-4",
    "href": "slides/15_pivoting.html#tidy-data-4",
    "title": "Pivoting data",
    "section": "Tidy data",
    "text": "Tidy data\n\nThink about tidy from a model perspective\nTidyverse assumes tidy data\nEasier to analyze and plot tidy data\nBut sometimes easier to store non-tidy data"
  },
  {
    "objectID": "slides/15_pivoting.html#pivoting-data-1",
    "href": "slides/15_pivoting.html#pivoting-data-1",
    "title": "Pivoting data",
    "section": "Pivoting data",
    "text": "Pivoting data"
  },
  {
    "objectID": "slides/15_pivoting.html#pivoting-data-2",
    "href": "slides/15_pivoting.html#pivoting-data-2",
    "title": "Pivoting data",
    "section": "Pivoting data",
    "text": "Pivoting data\n\n\n\nSource: Garrick Aden-Buie"
  },
  {
    "objectID": "slides/15_pivoting.html#wide-data",
    "href": "slides/15_pivoting.html#wide-data",
    "title": "Pivoting data",
    "section": "Wide data",
    "text": "Wide data\n\n\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\nWhy is table4a not tidy?"
  },
  {
    "objectID": "slides/15_pivoting.html#wide-data-1",
    "href": "slides/15_pivoting.html#wide-data-1",
    "title": "Pivoting data",
    "section": "Wide data",
    "text": "Wide data\nUse pivot_longer()\n\n\npivot_longer(table4a, cols = c(`1999`, `2000`), \n             names_to = \"year\", values_to = \"cases\")\n\n# A tibble: 6 × 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766"
  },
  {
    "objectID": "slides/15_pivoting.html#long-data",
    "href": "slides/15_pivoting.html#long-data",
    "title": "Pivoting data",
    "section": "Long data",
    "text": "Long data\n\n\n\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\n\nWhy is table2 not tidy?"
  },
  {
    "objectID": "slides/15_pivoting.html#long-data-1",
    "href": "slides/15_pivoting.html#long-data-1",
    "title": "Pivoting data",
    "section": "Long data",
    "text": "Long data\nUse pivot_wider()\n\n\npivot_wider(table2, id_cols = c(\"country\", \"year\"), \n            names_from = type, values_from = count)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583"
  },
  {
    "objectID": "slides/15_pivoting.html#solving-the-problem",
    "href": "slides/15_pivoting.html#solving-the-problem",
    "title": "Pivoting data",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code turns data1 into data2? And vice versa?\n\n\n\ndata1\n\n# A tibble: 4 × 4\n     id cond1 cond2 cond3\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 0.935 0.896 0.422\n2     2 0.599 0.493 0.539\n3     3 0.933 0.798 0.724\n4     4 0.337 0.890 0.705\n\n\n\n\ndata2\n\n   id condition  response\n1   1     cond1 0.9349457\n2   1     cond2 0.8955915\n3   1     cond3 0.4221161\n4   2     cond1 0.5992728\n5   2     cond2 0.4928767\n6   2     cond3 0.5392186\n7   3     cond1 0.9325012\n8   3     cond2 0.7983170\n9   3     cond3 0.7238427\n10  4     cond1 0.3368520\n11  4     cond2 0.8904755\n12  4     cond3 0.7046291"
  },
  {
    "objectID": "slides/15_pivoting.html#lets-code",
    "href": "slides/15_pivoting.html#lets-code",
    "title": "Pivoting data",
    "section": "Let’s code!",
    "text": "Let’s code!\nPivoting data [Rmd]"
  },
  {
    "objectID": "slides/13_filtering.html#the-problem",
    "href": "slides/13_filtering.html#the-problem",
    "title": "Filtering rows",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets? What can we use to create data2 from data1?\n\n\n\ndata1\n\n  cond id       date\n1    2  1 2022-02-03\n2    3  2 2022-02-09\n3    3  3 2022-02-15\n4    1  4 2022-02-02\n5    2  5 2022-02-20\n6    2  6 2022-02-18\n7    2  7 2022-01-18\n8    1  8 2022-01-17\n\n\n\n\ndata2\n\n         cond id    month       date\n1 Condition 2  1 February 2022-02-03\n2 Condition 3  2 February 2022-02-09\n3 Condition 3  3 February 2022-02-15\n4 Condition 1  4 February 2022-02-02\n5 Condition 2  5 February 2022-02-20\n6 Condition 2  6 February 2022-02-18\n7 Condition 2  7  January 2022-01-18\n8 Condition 1  8  January 2022-01-17"
  },
  {
    "objectID": "slides/13_filtering.html#the-problem-1",
    "href": "slides/13_filtering.html#the-problem-1",
    "title": "Filtering rows",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets? What can we use to create data3 from data1?\n\n\n\ndata1\n\n  cond id       date\n1    2  1 2022-02-03\n2    3  2 2022-02-09\n3    3  3 2022-02-15\n4    1  4 2022-02-02\n5    2  5 2022-02-20\n6    2  6 2022-02-18\n7    2  7 2022-01-18\n8    1  8 2022-01-17\n\n\n\n\ndata3\n\n  id cond\n1  1    2\n2  2    3\n3  3    3\n4  4    1\n5  5    2\n6  6    2\n7  7    2\n8  8    1"
  },
  {
    "objectID": "slides/13_filtering.html#the-problem-2",
    "href": "slides/13_filtering.html#the-problem-2",
    "title": "Filtering rows",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets? What needs to happen to create data4 from data1?\n\n\n\ndata1\n\n  cond id       date\n1    2  1 2022-02-03\n2    3  2 2022-02-09\n3    3  3 2022-02-15\n4    1  4 2022-02-02\n5    2  5 2022-02-20\n6    2  6 2022-02-18\n7    2  7 2022-01-18\n8    1  8 2022-01-17\n\n\n\n\ndata4\n\n  cond id       date\n1    1  8 2022-01-17\n2    2  7 2022-01-18\n3    1  4 2022-02-02\n4    2  1 2022-02-03\n5    2  6 2022-02-18\n6    2  5 2022-02-20"
  },
  {
    "objectID": "slides/13_filtering.html#data-wrangling",
    "href": "slides/13_filtering.html#data-wrangling",
    "title": "Filtering rows",
    "section": "Data wrangling",
    "text": "Data wrangling"
  },
  {
    "objectID": "slides/13_filtering.html#set-up",
    "href": "slides/13_filtering.html#set-up",
    "title": "Filtering rows",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(dplyr)\nlibrary(nycflights13)\n(flights2 &lt;- select(flights, year:dep_delay, air_time))\n\n# A tibble: 336,776 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     1     1      517            515         2      227\n 2  2013     1     1      533            529         4      227\n 3  2013     1     1      542            540         2      160\n 4  2013     1     1      544            545        -1      183\n 5  2013     1     1      554            600        -6      116\n 6  2013     1     1      554            558        -4      150\n 7  2013     1     1      555            600        -5      158\n 8  2013     1     1      557            600        -3       53\n 9  2013     1     1      557            600        -3      140\n10  2013     1     1      558            600        -2      138\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter",
    "href": "slides/13_filtering.html#filter",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()"
  },
  {
    "objectID": "slides/13_filtering.html#filter-1",
    "href": "slides/13_filtering.html#filter-1",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\n\nfilter(flights2, dep_time == sched_dep_time)\n\n# A tibble: 16,514 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     1     1      559            559         0       44\n 2  2013     1     1      600            600         0      152\n 3  2013     1     1      600            600         0      134\n 4  2013     1     1      607            607         0      157\n 5  2013     1     1      615            615         0      182\n 6  2013     1     1      615            615         0      120\n 7  2013     1     1      635            635         0      248\n 8  2013     1     1      655            655         0      294\n 9  2013     1     1      739            739         0      249\n10  2013     1     1      745            745         0      378\n# ℹ 16,504 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-2",
    "href": "slides/13_filtering.html#filter-2",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nMultiple conditions\n\nfilter(flights2, dep_delay &lt; 0 & month == 2)\n\n# A tibble: 13,397 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     2     1      456            500        -4       98\n 2  2013     2     1      520            525        -5      209\n 3  2013     2     1      527            530        -3      233\n 4  2013     2     1      532            540        -8      195\n 5  2013     2     1      552            600        -8       58\n 6  2013     2     1      552            600        -8      227\n 7  2013     2     1      552            600        -8       42\n 8  2013     2     1      553            600        -7      134\n 9  2013     2     1      553            600        -7      125\n10  2013     2     1      553            600        -7       49\n# ℹ 13,387 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-3",
    "href": "slides/13_filtering.html#filter-3",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nLogical OR\n\nfilter(flights2, month == 11 | month == 12)\n\n# A tibble: 55,403 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013    11     1        5           2359         6      205\n 2  2013    11     1       35           2250       105       36\n 3  2013    11     1      455            500        -5       88\n 4  2013    11     1      539            545        -6      229\n 5  2013    11     1      542            545        -3      147\n 6  2013    11     1      549            600       -11      359\n 7  2013    11     1      550            600       -10       57\n 8  2013    11     1      554            600        -6       40\n 9  2013    11     1      554            600        -6      126\n10  2013    11     1      554            600        -6       93\n# ℹ 55,393 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-4",
    "href": "slides/13_filtering.html#filter-4",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nLogical %in%\n\nfilter(flights2, month %in% c(11, 12))\n\n# A tibble: 55,403 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013    11     1        5           2359         6      205\n 2  2013    11     1       35           2250       105       36\n 3  2013    11     1      455            500        -5       88\n 4  2013    11     1      539            545        -6      229\n 5  2013    11     1      542            545        -3      147\n 6  2013    11     1      549            600       -11      359\n 7  2013    11     1      550            600       -10       57\n 8  2013    11     1      554            600        -6       40\n 9  2013    11     1      554            600        -6      126\n10  2013    11     1      554            600        -6       93\n# ℹ 55,393 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-5",
    "href": "slides/13_filtering.html#filter-5",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nNegating conditional\n\nfilter(flights2, month != 1)\n\n# A tibble: 309,772 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013    10     1      447            500       -13       69\n 2  2013    10     1      522            517         5      174\n 3  2013    10     1      536            545        -9      132\n 4  2013    10     1      539            545        -6      172\n 5  2013    10     1      539            545        -6      186\n 6  2013    10     1      544            550        -6      191\n 7  2013    10     1      549            600       -11       46\n 8  2013    10     1      550            600       -10       38\n 9  2013    10     1      550            600       -10       39\n10  2013    10     1      551            600        -9      117\n# ℹ 309,762 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-6",
    "href": "slides/13_filtering.html#filter-6",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nNegating multiple conditionals\n\nfilter(flights2, month != 1 & day != 1)\n\n# A tibble: 299,578 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013    10     2      449            500       -11       73\n 2  2013    10     2      513            517        -4      180\n 3  2013    10     2      537            545        -8      190\n 4  2013    10     2      540            545        -5      181\n 5  2013    10     2      543            545        -2      134\n 6  2013    10     2      546            550        -4      192\n 7  2013    10     2      548            600       -12       48\n 8  2013    10     2      548            600       -12       42\n 9  2013    10     2      550            600       -10       32\n10  2013    10     2      552            600        -8       40\n# ℹ 299,568 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-7",
    "href": "slides/13_filtering.html#filter-7",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nCheck if NA with is.na()\n\n\nfilter(flights2, is.na(dep_time))\n\n# A tibble: 8,255 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     1     1       NA           1630        NA       NA\n 2  2013     1     1       NA           1935        NA       NA\n 3  2013     1     1       NA           1500        NA       NA\n 4  2013     1     1       NA            600        NA       NA\n 5  2013     1     2       NA           1540        NA       NA\n 6  2013     1     2       NA           1620        NA       NA\n 7  2013     1     2       NA           1355        NA       NA\n 8  2013     1     2       NA           1420        NA       NA\n 9  2013     1     2       NA           1321        NA       NA\n10  2013     1     2       NA           1545        NA       NA\n# ℹ 8,245 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#filter-8",
    "href": "slides/13_filtering.html#filter-8",
    "title": "Filtering rows",
    "section": "filter()",
    "text": "filter()\nCheck if NA across multiple columns with is.na() and if_any()\n\n\nfilter(flights2, if_any(everything(), is.na))\n\n# A tibble: 9,430 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     1     1     1525           1530        -5       NA\n 2  2013     1     1     1528           1459        29       NA\n 3  2013     1     1     1740           1745        -5       NA\n 4  2013     1     1     1807           1738        29       NA\n 5  2013     1     1     1939           1840        59       NA\n 6  2013     1     1     1952           1930        22       NA\n 7  2013     1     1     2016           1930        46       NA\n 8  2013     1     1       NA           1630        NA       NA\n 9  2013     1     1       NA           1935        NA       NA\n10  2013     1     1       NA           1500        NA       NA\n# ℹ 9,420 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#drop_na",
    "href": "slides/13_filtering.html#drop_na",
    "title": "Filtering rows",
    "section": "drop_na()",
    "text": "drop_na()\nFilter column with any NAs with drop_na()\n\n\nnrow(flights2)\n\n[1] 336776\n\nnrow(drop_na(flights2))\n\n[1] 327346\n\n\n\n\nnrow(drop_na(flights, dep_time))\n\n[1] 328521"
  },
  {
    "objectID": "slides/13_filtering.html#arrange",
    "href": "slides/13_filtering.html#arrange",
    "title": "Filtering rows",
    "section": "arrange()",
    "text": "arrange()"
  },
  {
    "objectID": "slides/13_filtering.html#arrange-1",
    "href": "slides/13_filtering.html#arrange-1",
    "title": "Filtering rows",
    "section": "arrange()",
    "text": "arrange()\n\narrange(flights2, sched_dep_time)\n\n# A tibble: 336,776 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     7    27       NA            106        NA       NA\n 2  2013     1     2      458            500        -2      108\n 3  2013     1     3      458            500        -2       94\n 4  2013     1     4      456            500        -4       77\n 5  2013     1     5      458            500        -2       85\n 6  2013     1     6      458            500        -2       88\n 7  2013     1     7      454            500        -6       86\n 8  2013     1     8      454            500        -6       77\n 9  2013     1     9      457            500        -3       87\n10  2013     1    10      450            500       -10       78\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#arrange-2",
    "href": "slides/13_filtering.html#arrange-2",
    "title": "Filtering rows",
    "section": "arrange()",
    "text": "arrange()\nSort multiple rows\n\narrange(flights2, sched_dep_time, dep_time)\n\n# A tibble: 336,776 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     7    27       NA            106        NA       NA\n 2  2013     5     8      445            500       -15       78\n 3  2013     5     5      446            500       -14       90\n 4  2013     9     4      446            500       -14       79\n 5  2013    10     1      447            500       -13       69\n 6  2013     9    19      447            500       -13       81\n 7  2013     1    29      448            500       -12       88\n 8  2013    12    27      448            500       -12       92\n 9  2013     5     7      448            500       -12       80\n10  2013    10     2      449            500       -11       73\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#arrange-3",
    "href": "slides/13_filtering.html#arrange-3",
    "title": "Filtering rows",
    "section": "arrange()",
    "text": "arrange()\nSort in descending order\n\narrange(flights2, desc(dep_time))\n\n# A tibble: 336,776 × 7\n    year month   day dep_time sched_dep_time dep_delay air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013    10    30     2400           2359         1      182\n 2  2013    11    27     2400           2359         1      230\n 3  2013    12     5     2400           2359         1      182\n 4  2013    12     9     2400           2359         1      195\n 5  2013    12     9     2400           2250        70       41\n 6  2013    12    13     2400           2359         1      192\n 7  2013    12    19     2400           2359         1      193\n 8  2013    12    29     2400           1700       420      161\n 9  2013     2     7     2400           2359         1      186\n10  2013     2     7     2400           2359         1      194\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/13_filtering.html#solving-the-problem",
    "href": "slides/13_filtering.html#solving-the-problem",
    "title": "Filtering rows",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code turns data1 into data4?\n\n\n\ndata1\n\n  cond id       date\n1    2  1 2022-02-03\n2    3  2 2022-02-09\n3    3  3 2022-02-15\n4    1  4 2022-02-02\n5    2  5 2022-02-20\n6    2  6 2022-02-18\n7    2  7 2022-01-18\n8    1  8 2022-01-17\n\n\n\n\ndata4\n\n  cond id       date\n1    1  8 2022-01-17\n2    2  7 2022-01-18\n3    1  4 2022-02-02\n4    2  1 2022-02-03\n5    2  6 2022-02-18\n6    2  5 2022-02-20"
  },
  {
    "objectID": "slides/13_filtering.html#lets-code",
    "href": "slides/13_filtering.html#lets-code",
    "title": "Filtering rows",
    "section": "Let’s code!",
    "text": "Let’s code!\nFiltering rows [Rmd]"
  },
  {
    "objectID": "slides/11_mutating.html#data-wrangling",
    "href": "slides/11_mutating.html#data-wrangling",
    "title": "Mutating columns",
    "section": "Data wrangling",
    "text": "Data wrangling"
  },
  {
    "objectID": "slides/11_mutating.html#mental-model-of-mutating-columns",
    "href": "slides/11_mutating.html#mental-model-of-mutating-columns",
    "title": "Mutating columns",
    "section": "Mental model of mutating columns",
    "text": "Mental model of mutating columns"
  },
  {
    "objectID": "slides/11_mutating.html#set-up",
    "href": "slides/11_mutating.html#set-up",
    "title": "Mutating columns",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(dplyr)\nlibrary(nycflights13)\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…"
  },
  {
    "objectID": "slides/11_mutating.html#changing-and-creating-columns",
    "href": "slides/11_mutating.html#changing-and-creating-columns",
    "title": "Mutating columns",
    "section": "Changing and creating columns",
    "text": "Changing and creating columns\ndplyr::mutate()"
  },
  {
    "objectID": "slides/11_mutating.html#changing-existing-columns",
    "href": "slides/11_mutating.html#changing-existing-columns",
    "title": "Mutating columns",
    "section": "Changing existing columns",
    "text": "Changing existing columns"
  },
  {
    "objectID": "slides/11_mutating.html#changing-existing-columns-1",
    "href": "slides/11_mutating.html#changing-existing-columns-1",
    "title": "Mutating columns",
    "section": "Changing existing columns",
    "text": "Changing existing columns\n\nmutate(flights, month = as.character(month))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013 1         1      517            515         2      830            819\n 2  2013 1         1      533            529         4      850            830\n 3  2013 1         1      542            540         2      923            850\n 4  2013 1         1      544            545        -1     1004           1022\n 5  2013 1         1      554            600        -6      812            837\n 6  2013 1         1      554            558        -4      740            728\n 7  2013 1         1      555            600        -5      913            854\n 8  2013 1         1      557            600        -3      709            723\n 9  2013 1         1      557            600        -3      838            846\n10  2013 1         1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#changing-existing-columns-2",
    "href": "slides/11_mutating.html#changing-existing-columns-2",
    "title": "Mutating columns",
    "section": "Changing existing columns",
    "text": "Changing existing columns\nConditional changes\nifelse()\n\nmutate(flights, month = ifelse(month &lt; 10, # conditional statement\n                               paste0(\"0\", month), # what to do if TRUE\n                               as.character(month))) # what to do if FALSE\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013 01        1      517            515         2      830            819\n 2  2013 01        1      533            529         4      850            830\n 3  2013 01        1      542            540         2      923            850\n 4  2013 01        1      544            545        -1     1004           1022\n 5  2013 01        1      554            600        -6      812            837\n 6  2013 01        1      554            558        -4      740            728\n 7  2013 01        1      555            600        -5      913            854\n 8  2013 01        1      557            600        -3      709            723\n 9  2013 01        1      557            600        -3      838            846\n10  2013 01        1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#changing-existing-columns-3",
    "href": "slides/11_mutating.html#changing-existing-columns-3",
    "title": "Mutating columns",
    "section": "Changing existing columns",
    "text": "Changing existing columns\nConditional changes\ndplyr::if_else()\n\nmutate(flights, month = if_else(month &lt; 10,  # conditional statement\n                                paste0(\"0\", month),  # what to do if TRUE\n                                as.character(month),  # what to do if FALSE\n                                NA)) # what to do if missing\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013 01        1      517            515         2      830            819\n 2  2013 01        1      533            529         4      850            830\n 3  2013 01        1      542            540         2      923            850\n 4  2013 01        1      544            545        -1     1004           1022\n 5  2013 01        1      554            600        -6      812            837\n 6  2013 01        1      554            558        -4      740            728\n 7  2013 01        1      555            600        -5      913            854\n 8  2013 01        1      557            600        -3      709            723\n 9  2013 01        1      557            600        -3      838            846\n10  2013 01        1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#changing-existing-columns-4",
    "href": "slides/11_mutating.html#changing-existing-columns-4",
    "title": "Mutating columns",
    "section": "Changing existing columns",
    "text": "Changing existing columns\nMultiple changes\n\nmutate(flights, \n       month = if_else(month &lt; 10, paste0(\"0\", month), as.character(month), NA),\n       day = if_else(day &lt; 10, paste0(\"0\", day), as.character(day), NA)\n)\n\n# A tibble: 336,776 × 19\n    year month day   dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013 01    01         517            515         2      830            819\n 2  2013 01    01         533            529         4      850            830\n 3  2013 01    01         542            540         2      923            850\n 4  2013 01    01         544            545        -1     1004           1022\n 5  2013 01    01         554            600        -6      812            837\n 6  2013 01    01         554            558        -4      740            728\n 7  2013 01    01         555            600        -5      913            854\n 8  2013 01    01         557            600        -3      709            723\n 9  2013 01    01         557            600        -3      838            846\n10  2013 01    01         558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns",
    "href": "slides/11_mutating.html#creating-new-columns",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns-1",
    "href": "slides/11_mutating.html#creating-new-columns-1",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns\n\nmutate(flights, speed = distance / air_time * 60)\n\n# A tibble: 336,776 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, speed &lt;dbl&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns-2",
    "href": "slides/11_mutating.html#creating-new-columns-2",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns\nMove column when creating\n\nmutate(flights, speed = distance / air_time * 60, .after = day)\n\n# A tibble: 336,776 × 20\n    year month   day speed dep_time sched_dep_time dep_delay arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1  2013     1     1  370.      517            515         2      830\n 2  2013     1     1  374.      533            529         4      850\n 3  2013     1     1  408.      542            540         2      923\n 4  2013     1     1  517.      544            545        -1     1004\n 5  2013     1     1  394.      554            600        -6      812\n 6  2013     1     1  288.      554            558        -4      740\n 7  2013     1     1  404.      555            600        -5      913\n 8  2013     1     1  259.      557            600        -3      709\n 9  2013     1     1  405.      557            600        -3      838\n10  2013     1     1  319.      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns-3",
    "href": "slides/11_mutating.html#creating-new-columns-3",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns\nConditionals with multiple outcomes\ndplyr::case_when\n\nmutate(flights, season = case_when(month %in% c(3:5) ~ \"spring\",\n                                   month %in% c(6:8) ~ \"summer\",\n                                   month %in% c(9:11) ~ \"fall\",\n                                   month %in% c(12, 1:2) ~ \"winter\"),\n       .after = day)\n\n# A tibble: 336,776 × 20\n    year month   day season dep_time sched_dep_time dep_delay arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;     &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1  2013     1     1 winter      517            515         2      830\n 2  2013     1     1 winter      533            529         4      850\n 3  2013     1     1 winter      542            540         2      923\n 4  2013     1     1 winter      544            545        -1     1004\n 5  2013     1     1 winter      554            600        -6      812\n 6  2013     1     1 winter      554            558        -4      740\n 7  2013     1     1 winter      555            600        -5      913\n 8  2013     1     1 winter      557            600        -3      709\n 9  2013     1     1 winter      557            600        -3      838\n10  2013     1     1 winter      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns-4",
    "href": "slides/11_mutating.html#creating-new-columns-4",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns\nMultiple columns\n\nmutate(flights, speed = distance / air_time * 60, .after = dep_time) %&gt;%\n  mutate(month = if_else(month &lt; 10, paste0(\"0\", month), as.character(month), NA),\n         day = if_else(day &lt; 10, paste0(\"0\", day), as.character(day), NA),\n         date = paste(year, month, day, sep = \"-\"), \n         .after = day)\n\n# A tibble: 336,776 × 21\n    year month day   date       dep_time speed sched_dep_time dep_delay arr_time\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1  2013 01    01    2013-01-01      517  370.            515         2      830\n 2  2013 01    01    2013-01-01      533  374.            529         4      850\n 3  2013 01    01    2013-01-01      542  408.            540         2      923\n 4  2013 01    01    2013-01-01      544  517.            545        -1     1004\n 5  2013 01    01    2013-01-01      554  394.            600        -6      812\n 6  2013 01    01    2013-01-01      554  288.            558        -4      740\n 7  2013 01    01    2013-01-01      555  404.            600        -5      913\n 8  2013 01    01    2013-01-01      557  259.            600        -3      709\n 9  2013 01    01    2013-01-01      557  405.            600        -3      838\n10  2013 01    01    2013-01-01      558  319.            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns-5",
    "href": "slides/11_mutating.html#creating-new-columns-5",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns\nRemove old columns\n\nmutate(flights, date = paste(year, month, day, sep = \"-\"), \n       .before = 1, \n       .keep = \"unused\")\n\n# A tibble: 336,776 × 17\n   date     dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n   &lt;chr&gt;       &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1 2013-1-1      517            515         2      830            819        11\n 2 2013-1-1      533            529         4      850            830        20\n 3 2013-1-1      542            540         2      923            850        33\n 4 2013-1-1      544            545        -1     1004           1022       -18\n 5 2013-1-1      554            600        -6      812            837       -25\n 6 2013-1-1      554            558        -4      740            728        12\n 7 2013-1-1      555            600        -5      913            854        19\n 8 2013-1-1      557            600        -3      709            723       -14\n 9 2013-1-1      557            600        -3      838            846        -8\n10 2013-1-1      558            600        -2      753            745         8\n# ℹ 336,766 more rows\n# ℹ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,\n#   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#creating-new-columns-6",
    "href": "slides/11_mutating.html#creating-new-columns-6",
    "title": "Mutating columns",
    "section": "Creating new columns",
    "text": "Creating new columns\nKeep only new column\n\nmutate(flights, date = paste(year, month, day, sep = \"-\"), \n       .keep = \"none\")\n\n# A tibble: 336,776 × 1\n   date    \n   &lt;chr&gt;   \n 1 2013-1-1\n 2 2013-1-1\n 3 2013-1-1\n 4 2013-1-1\n 5 2013-1-1\n 6 2013-1-1\n 7 2013-1-1\n 8 2013-1-1\n 9 2013-1-1\n10 2013-1-1\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/11_mutating.html#apply-functions-to-multiple-columns",
    "href": "slides/11_mutating.html#apply-functions-to-multiple-columns",
    "title": "Mutating columns",
    "section": "Apply functions to multiple columns",
    "text": "Apply functions to multiple columns\n\nmutate(flights, min_dep_time = min(dep_time, sched_dep_time, na.rm = TRUE), \n       .after = arr_time)\n\n# A tibble: 336,776 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time min_dep_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;        &lt;int&gt;\n 1  2013     1     1      517            515         2      830            1\n 2  2013     1     1      533            529         4      850            1\n 3  2013     1     1      542            540         2      923            1\n 4  2013     1     1      544            545        -1     1004            1\n 5  2013     1     1      554            600        -6      812            1\n 6  2013     1     1      554            558        -4      740            1\n 7  2013     1     1      555            600        -5      913            1\n 8  2013     1     1      557            600        -3      709            1\n 9  2013     1     1      557            600        -3      838            1\n10  2013     1     1      558            600        -2      753            1\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#apply-functions-to-multiple-columns-1",
    "href": "slides/11_mutating.html#apply-functions-to-multiple-columns-1",
    "title": "Mutating columns",
    "section": "Apply functions to multiple columns",
    "text": "Apply functions to multiple columns\ndplyr::rowwise()\n\nrowwise(flights) %&gt;% \n  mutate(min_dep_time = min(dep_time, sched_dep_time), .after = arr_time)\n\n# A tibble: 336,776 × 20\n# Rowwise: \n    year month   day dep_time sched_dep_time dep_delay arr_time min_dep_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;        &lt;int&gt;\n 1  2013     1     1      517            515         2      830          515\n 2  2013     1     1      533            529         4      850          529\n 3  2013     1     1      542            540         2      923          540\n 4  2013     1     1      544            545        -1     1004          544\n 5  2013     1     1      554            600        -6      812          554\n 6  2013     1     1      554            558        -4      740          554\n 7  2013     1     1      555            600        -5      913          555\n 8  2013     1     1      557            600        -3      709          557\n 9  2013     1     1      557            600        -3      838          557\n10  2013     1     1      558            600        -2      753          558\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#changing-multiple-columns",
    "href": "slides/11_mutating.html#changing-multiple-columns",
    "title": "Mutating columns",
    "section": "Changing multiple columns",
    "text": "Changing multiple columns\ndplyr::across()\n\nmutate(flights, across(contains(\"_time\"), as.character))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;         \n 1  2013     1     1 517      515                    2 830      819           \n 2  2013     1     1 533      529                    4 850      830           \n 3  2013     1     1 542      540                    2 923      850           \n 4  2013     1     1 544      545                   -1 1004     1022          \n 5  2013     1     1 554      600                   -6 812      837           \n 6  2013     1     1 554      558                   -4 740      728           \n 7  2013     1     1 555      600                   -5 913      854           \n 8  2013     1     1 557      600                   -3 709      723           \n 9  2013     1     1 557      600                   -3 838      846           \n10  2013     1     1 558      600                   -2 753      745           \n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;chr&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#changing-multiple-columns-1",
    "href": "slides/11_mutating.html#changing-multiple-columns-1",
    "title": "Mutating columns",
    "section": "Changing multiple columns",
    "text": "Changing multiple columns\ndplyr::across()\nWhat if you need to pass arguments to your function?\n\nmutate(flights, across(contains(\"_time\"), ~ .x / 60))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1  2013     1     1     8.62           8.58         2     13.8           13.6\n 2  2013     1     1     8.88           8.82         4     14.2           13.8\n 3  2013     1     1     9.03           9            2     15.4           14.2\n 4  2013     1     1     9.07           9.08        -1     16.7           17.0\n 5  2013     1     1     9.23          10           -6     13.5           14.0\n 6  2013     1     1     9.23           9.3         -4     12.3           12.1\n 7  2013     1     1     9.25          10           -5     15.2           14.2\n 8  2013     1     1     9.28          10           -3     11.8           12.0\n 9  2013     1     1     9.28          10           -3     14.0           14.1\n10  2013     1     1     9.3           10           -2     12.6           12.4\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/11_mutating.html#changing-multiple-columns-2",
    "href": "slides/11_mutating.html#changing-multiple-columns-2",
    "title": "Mutating columns",
    "section": "Changing multiple columns",
    "text": "Changing multiple columns\ndplyr::across()\nWhat if you need to pass arguments to your function?\n\nprint(mutate(flights, across(contains(\"_time\"), ~ .x / 60)), n = 5)\n\n\n\n\n\n\n\nNote\n\n\n\nStart with ~\n\nReplace where the column name should be with .x\n\nNote dividing these numbers by 60 doesn’t make sense—just an example"
  },
  {
    "objectID": "slides/11_mutating.html#mental-model-of-mutating-columns-1",
    "href": "slides/11_mutating.html#mental-model-of-mutating-columns-1",
    "title": "Mutating columns",
    "section": "Mental model of mutating columns",
    "text": "Mental model of mutating columns"
  },
  {
    "objectID": "slides/11_mutating.html#lets-code",
    "href": "slides/11_mutating.html#lets-code",
    "title": "Mutating columns",
    "section": "Let’s code!",
    "text": "Let’s code!\nMutating data [Rmd]"
  },
  {
    "objectID": "slides/09_validating.html#mental-model-of-importing-data",
    "href": "slides/09_validating.html#mental-model-of-importing-data",
    "title": "Validating data",
    "section": "Mental model of importing data",
    "text": "Mental model of importing data"
  },
  {
    "objectID": "slides/09_validating.html#set-up",
    "href": "slides/09_validating.html#set-up",
    "title": "Validating data",
    "section": "Set up",
    "text": "Set up\nImport dog breed traits data\n\n(mydf &lt;- readr::read_csv(here::here(\"data/dog_breed_traits.csv\")))\n\n# A tibble: 195 × 17\n   Breed    Affectionate With Fa…¹ Good With Young Chil…² `Good With Other Dogs`\n   &lt;chr&gt;                     &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n 1 Retriev…                      5                      5                      5\n 2 French …                      5                      5                      4\n 3 German …                      5                      5                      3\n 4 Retriev…                      5                      5                      5\n 5 Bulldogs                      4                      3                      3\n 6 Poodles                       5                      5                      3\n 7 Beagles                       3                      5                      5\n 8 Rottwei…                      5                      3                      3\n 9 Pointer…                      5                      5                      4\n10 Dachshu…                      5                      3                      4\n# ℹ 185 more rows\n# ℹ abbreviated names: ¹​`Affectionate With Family`, ²​`Good With Young Children`\n# ℹ 13 more variables: `Shedding Level` &lt;dbl&gt;, `Coat Grooming Frequency` &lt;dbl&gt;,\n#   `Drooling Level` &lt;dbl&gt;, `Coat Type` &lt;chr&gt;, `Coat Length` &lt;chr&gt;,\n#   `Openness To Strangers` &lt;dbl&gt;, `Playfulness Level` &lt;dbl&gt;,\n#   `Watchdog/Protective Nature` &lt;dbl&gt;, `Adaptability Level` &lt;dbl&gt;,\n#   `Trainability Level` &lt;dbl&gt;, `Energy Level` &lt;dbl&gt;, `Barking Level` &lt;dbl&gt;, …"
  },
  {
    "objectID": "slides/09_validating.html#set-up-1",
    "href": "slides/09_validating.html#set-up-1",
    "title": "Validating data",
    "section": "Set up",
    "text": "Set up\nAlso load {palmerpenguins} for access to penguins\n\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/09_validating.html#data-validation-1",
    "href": "slides/09_validating.html#data-validation-1",
    "title": "Validating data",
    "section": "Data validation",
    "text": "Data validation\nCheck that your imported data are correct/valid/reasonable\n\nDimensions\nData types\nRanges and constraints\nAllowed values (code lists)\nColumn dependencies\nCompleteness/uniqueness\nMissing values"
  },
  {
    "objectID": "slides/09_validating.html#dimensions",
    "href": "slides/09_validating.html#dimensions",
    "title": "Validating data",
    "section": "Dimensions",
    "text": "Dimensions\nDoes the data frame have the correct dimensions?\nHow do we check dimensions of a data frame?\n\n\ndim(mydf)\n\n[1] 195  17"
  },
  {
    "objectID": "slides/09_validating.html#data-types",
    "href": "slides/09_validating.html#data-types",
    "title": "Validating data",
    "section": "Data types",
    "text": "Data types\nDo the data columns have the correct data types?\nHow do we check data types of a data frame?\n\n\nstr(mydf)\n\nspc_tbl_ [195 × 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Breed                     : chr [1:195] \"Retrievers (Labrador)\" \"French Bulldogs\" \"German Shepherd Dogs\" \"Retrievers (Golden)\" ...\n $ Affectionate With Family  : num [1:195] 5 5 5 5 4 5 3 5 5 5 ...\n $ Good With Young Children  : num [1:195] 5 5 5 5 3 5 5 3 5 3 ...\n $ Good With Other Dogs      : num [1:195] 5 4 3 5 3 3 5 3 4 4 ...\n $ Shedding Level            : num [1:195] 4 3 4 4 3 1 3 3 3 2 ...\n $ Coat Grooming Frequency   : num [1:195] 2 1 2 2 3 4 2 1 2 2 ...\n $ Drooling Level            : num [1:195] 2 3 2 2 3 1 1 3 2 2 ...\n $ Coat Type                 : chr [1:195] \"Double\" \"Smooth\" \"Double\" \"Double\" ...\n $ Coat Length               : chr [1:195] \"Short\" \"Short\" \"Medium\" \"Medium\" ...\n $ Openness To Strangers     : num [1:195] 5 5 3 5 4 5 3 3 4 4 ...\n $ Playfulness Level         : num [1:195] 5 5 4 4 4 5 4 4 4 4 ...\n $ Watchdog/Protective Nature: num [1:195] 3 3 5 3 3 5 2 5 4 4 ...\n $ Adaptability Level        : num [1:195] 5 5 5 5 3 4 4 4 4 4 ...\n $ Trainability Level        : num [1:195] 5 4 5 5 4 5 3 5 5 4 ...\n $ Energy Level              : num [1:195] 5 3 5 3 3 4 4 3 5 3 ...\n $ Barking Level             : num [1:195] 3 1 3 1 2 4 4 1 3 5 ...\n $ Mental Stimulation Needs  : num [1:195] 4 3 5 4 3 5 4 5 5 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Breed = col_character(),\n  ..   `Affectionate With Family` = col_double(),\n  ..   `Good With Young Children` = col_double(),\n  ..   `Good With Other Dogs` = col_double(),\n  ..   `Shedding Level` = col_double(),\n  ..   `Coat Grooming Frequency` = col_double(),\n  ..   `Drooling Level` = col_double(),\n  ..   `Coat Type` = col_character(),\n  ..   `Coat Length` = col_character(),\n  ..   `Openness To Strangers` = col_double(),\n  ..   `Playfulness Level` = col_double(),\n  ..   `Watchdog/Protective Nature` = col_double(),\n  ..   `Adaptability Level` = col_double(),\n  ..   `Trainability Level` = col_double(),\n  ..   `Energy Level` = col_double(),\n  ..   `Barking Level` = col_double(),\n  ..   `Mental Stimulation Needs` = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "slides/09_validating.html#data-types-1",
    "href": "slides/09_validating.html#data-types-1",
    "title": "Validating data",
    "section": "Data types",
    "text": "Data types\nDo the data columns have the correct data types?\nTest specific data type for individual columns\n\nis.numeric(mydf$`2013 Rank`)\n\n[1] FALSE"
  },
  {
    "objectID": "slides/09_validating.html#ranges-and-constraints",
    "href": "slides/09_validating.html#ranges-and-constraints",
    "title": "Validating data",
    "section": "Ranges and constraints",
    "text": "Ranges and constraints\nDo numerical column values have the correct range and/or other constraints?\n\n\n\n\n\n\n\nNote\n\n\nUseful to check for Likert scales and measures of age (especially coming out of Qualtrics).\n\n\n\n\nrange(mydf$`Drooling Level`)\n\n[1] 1 5"
  },
  {
    "objectID": "slides/09_validating.html#allowed-values-code-lists",
    "href": "slides/09_validating.html#allowed-values-code-lists",
    "title": "Validating data",
    "section": "Allowed values (code lists)",
    "text": "Allowed values (code lists)\nDo categorical column values have the correct possible values?\n\n\n\n\n\n\n\nNote\n\n\nUseful to check for when users can enter text instead of choose options.\n\n\n\n\n(recorded_coats &lt;- unique(mydf$`Coat Type`))\n\n[1] \"Double\"   \"Smooth\"   \"Curly\"    \"Silky\"    \"Wavy\"     \"Wiry\"     \"Hairless\"\n[8] \"Rough\"    \"Corded\"  \n\n\n\nallowed_coats &lt;- c(\"Smooth\", \"Curly\", \"Silky\", \"Wavy\", \"Wiry\", \"Rough\")\nrecorded_coats %in% allowed_coats\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE"
  },
  {
    "objectID": "slides/09_validating.html#column-dependencies",
    "href": "slides/09_validating.html#column-dependencies",
    "title": "Validating data",
    "section": "Column dependencies",
    "text": "Column dependencies\nDo column dependencies match up?\nE.g., if “other” is selected in choice column, does other column have an entry?\n\ndf$choice == \"other\" & !is.na(df$other)"
  },
  {
    "objectID": "slides/09_validating.html#completeness",
    "href": "slides/09_validating.html#completeness",
    "title": "Validating data",
    "section": "Completeness",
    "text": "Completeness\nAre all expected observations included?\nHow do we test this?\n\n\nobserved_subjects %in% expected_subjects"
  },
  {
    "objectID": "slides/09_validating.html#uniqueness",
    "href": "slides/09_validating.html#uniqueness",
    "title": "Validating data",
    "section": "Uniqueness",
    "text": "Uniqueness\nAre there duplicate observations?\n\nduplicated(mydf$Breed)\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[169] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[193] FALSE FALSE FALSE\n\n\n\n\nmydf[duplicated(mydf$Breed), ]\n\n# A tibble: 0 × 17\n# ℹ 17 variables: Breed &lt;chr&gt;, Affectionate With Family &lt;dbl&gt;,\n#   Good With Young Children &lt;dbl&gt;, Good With Other Dogs &lt;dbl&gt;,\n#   Shedding Level &lt;dbl&gt;, Coat Grooming Frequency &lt;dbl&gt;, Drooling Level &lt;dbl&gt;,\n#   Coat Type &lt;chr&gt;, Coat Length &lt;chr&gt;, Openness To Strangers &lt;dbl&gt;,\n#   Playfulness Level &lt;dbl&gt;, Watchdog/Protective Nature &lt;dbl&gt;,\n#   Adaptability Level &lt;dbl&gt;, Trainability Level &lt;dbl&gt;, Energy Level &lt;dbl&gt;,\n#   Barking Level &lt;dbl&gt;, Mental Stimulation Needs &lt;dbl&gt;"
  },
  {
    "objectID": "slides/09_validating.html#missing-values",
    "href": "slides/09_validating.html#missing-values",
    "title": "Validating data",
    "section": "Missing values",
    "text": "Missing values\nAre there values with missing data?\n\nis.na(penguins$bill_length_mm)\n\n\n\npenguins[is.na(penguins$bill_length_mm), ]\n\n# A tibble: 2 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen             NA            NA                NA          NA\n2 Gentoo  Biscoe                NA            NA                NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/09_validating.html#missing-values-1",
    "href": "slides/09_validating.html#missing-values-1",
    "title": "Validating data",
    "section": "Missing values",
    "text": "Missing values\nAre there values with missing data?\n\npenguins[!complete.cases(penguins), ]\n\n# A tibble: 11 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           NA            NA                  NA          NA\n 2 Adelie  Torgersen           34.1          18.1               193        3475\n 3 Adelie  Torgersen           42            20.2               190        4250\n 4 Adelie  Torgersen           37.8          17.1               186        3300\n 5 Adelie  Torgersen           37.8          17.3               180        3700\n 6 Adelie  Dream               37.5          18.9               179        2975\n 7 Gentoo  Biscoe              44.5          14.3               216        4100\n 8 Gentoo  Biscoe              46.2          14.4               214        4650\n 9 Gentoo  Biscoe              47.3          13.8               216        4725\n10 Gentoo  Biscoe              44.5          15.7               217        4875\n11 Gentoo  Biscoe              NA            NA                  NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/09_validating.html#summarizing-data-1",
    "href": "slides/09_validating.html#summarizing-data-1",
    "title": "Validating data",
    "section": "Summarizing data",
    "text": "Summarizing data\nhead()\n\nhead(mydf)\n\n# A tibble: 6 × 17\n  Breed     Affectionate With Fa…¹ Good With Young Chil…² `Good With Other Dogs`\n  &lt;chr&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Retrieve…                      5                      5                      5\n2 French B…                      5                      5                      4\n3 German S…                      5                      5                      3\n4 Retrieve…                      5                      5                      5\n5 Bulldogs                       4                      3                      3\n6 Poodles                        5                      5                      3\n# ℹ abbreviated names: ¹​`Affectionate With Family`, ²​`Good With Young Children`\n# ℹ 13 more variables: `Shedding Level` &lt;dbl&gt;, `Coat Grooming Frequency` &lt;dbl&gt;,\n#   `Drooling Level` &lt;dbl&gt;, `Coat Type` &lt;chr&gt;, `Coat Length` &lt;chr&gt;,\n#   `Openness To Strangers` &lt;dbl&gt;, `Playfulness Level` &lt;dbl&gt;,\n#   `Watchdog/Protective Nature` &lt;dbl&gt;, `Adaptability Level` &lt;dbl&gt;,\n#   `Trainability Level` &lt;dbl&gt;, `Energy Level` &lt;dbl&gt;, `Barking Level` &lt;dbl&gt;,\n#   `Mental Stimulation Needs` &lt;dbl&gt;"
  },
  {
    "objectID": "slides/09_validating.html#summarizing-data-2",
    "href": "slides/09_validating.html#summarizing-data-2",
    "title": "Validating data",
    "section": "Summarizing data",
    "text": "Summarizing data\nglimpse()\n\ntibble::glimpse(mydf)\n\nRows: 195\nColumns: 17\n$ Breed                        &lt;chr&gt; \"Retrievers (Labrador)\", \"French Bulldogs…\n$ `Affectionate With Family`   &lt;dbl&gt; 5, 5, 5, 5, 4, 5, 3, 5, 5, 5, 5, 3, 5, 4,…\n$ `Good With Young Children`   &lt;dbl&gt; 5, 5, 5, 5, 3, 5, 5, 3, 5, 3, 3, 5, 5, 5,…\n$ `Good With Other Dogs`       &lt;dbl&gt; 5, 4, 3, 5, 3, 3, 5, 3, 4, 4, 4, 3, 3, 3,…\n$ `Shedding Level`             &lt;dbl&gt; 4, 3, 4, 4, 3, 1, 3, 3, 3, 2, 4, 3, 1, 2,…\n$ `Coat Grooming Frequency`    &lt;dbl&gt; 2, 1, 2, 2, 3, 4, 2, 1, 2, 2, 2, 2, 5, 2,…\n$ `Drooling Level`             &lt;dbl&gt; 2, 3, 2, 2, 3, 1, 1, 3, 2, 2, 1, 1, 1, 3,…\n$ `Coat Type`                  &lt;chr&gt; \"Double\", \"Smooth\", \"Double\", \"Double\", \"…\n$ `Coat Length`                &lt;chr&gt; \"Short\", \"Short\", \"Medium\", \"Medium\", \"Sh…\n$ `Openness To Strangers`      &lt;dbl&gt; 5, 5, 3, 5, 4, 5, 3, 3, 4, 4, 4, 3, 5, 4,…\n$ `Playfulness Level`          &lt;dbl&gt; 5, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ `Watchdog/Protective Nature` &lt;dbl&gt; 3, 3, 5, 3, 3, 5, 2, 5, 4, 4, 5, 3, 5, 4,…\n$ `Adaptability Level`         &lt;dbl&gt; 5, 5, 5, 5, 3, 4, 4, 4, 4, 4, 4, 3, 5, 3,…\n$ `Trainability Level`         &lt;dbl&gt; 5, 4, 5, 5, 4, 5, 3, 5, 5, 4, 4, 5, 4, 4,…\n$ `Energy Level`               &lt;dbl&gt; 5, 3, 5, 3, 3, 4, 4, 3, 5, 3, 4, 5, 4, 4,…\n$ `Barking Level`              &lt;dbl&gt; 3, 1, 3, 1, 2, 4, 4, 1, 3, 5, 4, 3, 4, 3,…\n$ `Mental Stimulation Needs`   &lt;dbl&gt; 4, 3, 5, 4, 3, 5, 4, 5, 5, 3, 4, 5, 4, 4,…"
  },
  {
    "objectID": "slides/09_validating.html#summarizing-data-3",
    "href": "slides/09_validating.html#summarizing-data-3",
    "title": "Validating data",
    "section": "Summarizing data",
    "text": "Summarizing data\nsummary()\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2"
  },
  {
    "objectID": "slides/09_validating.html#skimr",
    "href": "slides/09_validating.html#skimr",
    "title": "Validating data",
    "section": "{skimr}",
    "text": "{skimr}\nView info about your data\n\nlibrary(skimr)\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇"
  },
  {
    "objectID": "slides/09_validating.html#validate",
    "href": "slides/09_validating.html#validate",
    "title": "Validating data",
    "section": "{validate}",
    "text": "{validate}\n\nCreate rules about dimensions, data types, ranges, code lists, etc.\nConfront your data with the rules\nSummarize/visualize validation"
  },
  {
    "objectID": "slides/09_validating.html#assertr",
    "href": "slides/09_validating.html#assertr",
    "title": "Validating data",
    "section": "{assertr}",
    "text": "{assertr}\n\nAssertions: tests of data embedded in functions\n\n\nlibrary(assertr)\nverify(penguins, has_all_names(\"species\", \"island\", \"sex\"))\nverify(penguins, nrow(penguins) &gt; 100)\nverify(penguins, bill_length_mm &gt; 0)\ninsist(penguins, within_n_sds(4), bill_length_mm)\nassert(penguins, in_set(2007, 2008, 2009), year)"
  },
  {
    "objectID": "slides/09_validating.html#excluder",
    "href": "slides/09_validating.html#excluder",
    "title": "Validating data",
    "section": "{excluder}",
    "text": "{excluder}\nWorking with Qualtrics data can be … challenging.\n{excluder} helps:\n\n\nget rid of initial rows with remove_label_rows()\n\nuse Qualtrics labels as column names with use_labels()\n\ndeidentify data with deidentify()\n\nview, mark, or exclude data based on: preview status, survey progress, survey completion time, IP address country, geolocation, duplicate IP address, and screen resolution"
  },
  {
    "objectID": "slides/09_validating.html#datareporter",
    "href": "slides/09_validating.html#datareporter",
    "title": "Validating data",
    "section": "{dataReporter}",
    "text": "{dataReporter}"
  },
  {
    "objectID": "slides/09_validating.html#datareporter-1",
    "href": "slides/09_validating.html#datareporter-1",
    "title": "Validating data",
    "section": "{dataReporter}",
    "text": "{dataReporter}"
  },
  {
    "objectID": "slides/09_validating.html#datareporter-2",
    "href": "slides/09_validating.html#datareporter-2",
    "title": "Validating data",
    "section": "{dataReporter}",
    "text": "{dataReporter}\n\ndataReporter::makeCodebook(mydf3, file = here(\"06_codebook.Rmd\"))"
  },
  {
    "objectID": "slides/09_validating.html#lets-code",
    "href": "slides/09_validating.html#lets-code",
    "title": "Validating data",
    "section": "Let’s code!",
    "text": "Let’s code!\nValidating data [Rmd]"
  },
  {
    "objectID": "slides/07_datastructures.html#mental-model-of-data-types",
    "href": "slides/07_datastructures.html#mental-model-of-data-types",
    "title": "Data structures",
    "section": "Mental model of data types",
    "text": "Mental model of data types"
  },
  {
    "objectID": "slides/07_datastructures.html#vectors-1",
    "href": "slides/07_datastructures.html#vectors-1",
    "title": "Data structures",
    "section": "Vectors",
    "text": "Vectors\n\n\nActually, everything in R is a vector\n\n\nvector = atomic vector\n\n\nelements with a single dimension of the same data type"
  },
  {
    "objectID": "slides/07_datastructures.html#create-vectors-with-c",
    "href": "slides/07_datastructures.html#create-vectors-with-c",
    "title": "Data structures",
    "section": "Create vectors with c()\n",
    "text": "Create vectors with c()\n\nNumeric vectors\n\n(myvec1 &lt;- c(1, 5, 3, 6))\n\n[1] 1 5 3 6\n\n(myvec2 &lt;- c(11, 14, 18, 12))\n\n[1] 11 14 18 12\n\n\n\nc(myvec1, myvec2)\n\n[1]  1  5  3  6 11 14 18 12"
  },
  {
    "objectID": "slides/07_datastructures.html#create-vectors-with-c-1",
    "href": "slides/07_datastructures.html#create-vectors-with-c-1",
    "title": "Data structures",
    "section": "Create vectors with c()\n",
    "text": "Create vectors with c()\n\nCharacter vectors\n\n(myvec3 &lt;- c(\"a\", \"b\", \"c\"))\n\n[1] \"a\" \"b\" \"c\""
  },
  {
    "objectID": "slides/07_datastructures.html#create-vectors-with-c-2",
    "href": "slides/07_datastructures.html#create-vectors-with-c-2",
    "title": "Data structures",
    "section": "Create vectors with c()\n",
    "text": "Create vectors with c()\n\n\n\n\n\n\n\nStrain your brain\n\n\nWhat do you think will happen if you combine myvec2 and myvec3?\n\n\n\n\nmyvec2\n\n[1] 11 14 18 12\n\nmyvec3\n\n[1] \"a\" \"b\" \"c\"\n\n\n\nc(myvec2, myvec3)\n\n\n\n\n[1] \"11\" \"14\" \"18\" \"12\" \"a\"  \"b\"  \"c\" \n\n\nNumeric vector myvec2 converts to character vector to combine with myvec3"
  },
  {
    "objectID": "slides/07_datastructures.html#create-sequences-with-seq",
    "href": "slides/07_datastructures.html#create-sequences-with-seq",
    "title": "Data structures",
    "section": "Create sequences with seq()\n",
    "text": "Create sequences with seq()\n\n\nseq(from = 0, to = 20, by = 5)\n\n[1]  0  5 10 15 20\n\nseq(from = 20, to = 0, by = -5)\n\n[1] 20 15 10  5  0\n\nseq(0, 1, 0.2)\n\n[1] 0.0 0.2 0.4 0.6 0.8 1.0"
  },
  {
    "objectID": "slides/07_datastructures.html#create-sequences-with",
    "href": "slides/07_datastructures.html#create-sequences-with",
    "title": "Data structures",
    "section": "Create sequences with :\n",
    "text": "Create sequences with :\n\nSequences with increments of 1\n\n4:9\n\n[1] 4 5 6 7 8 9\n\n9:4\n\n[1] 9 8 7 6 5 4\n\n\n\n\n\n\n\n\n\nTry it!\n\n\nMake a sequence from 0 to 100 in steps of 10."
  },
  {
    "objectID": "slides/07_datastructures.html#create-repetitions-with-rep",
    "href": "slides/07_datastructures.html#create-repetitions-with-rep",
    "title": "Data structures",
    "section": "Create repetitions with rep()\n",
    "text": "Create repetitions with rep()\n\nRepeat single numbers\n\nrep(0, times = 10)\n\n [1] 0 0 0 0 0 0 0 0 0 0"
  },
  {
    "objectID": "slides/07_datastructures.html#create-repetitions-with-rep-1",
    "href": "slides/07_datastructures.html#create-repetitions-with-rep-1",
    "title": "Data structures",
    "section": "Create repetitions with rep()\n",
    "text": "Create repetitions with rep()\n\nRepeat vectors\n\nrep(myvec3, times = 3)\n\n[1] \"a\" \"b\" \"c\" \"a\" \"b\" \"c\" \"a\" \"b\" \"c\"\n\nrep(c(\"d\", \"e\", \"f\"), times = 3)\n\n[1] \"d\" \"e\" \"f\" \"d\" \"e\" \"f\" \"d\" \"e\" \"f\""
  },
  {
    "objectID": "slides/07_datastructures.html#create-repetitions-with-rep-2",
    "href": "slides/07_datastructures.html#create-repetitions-with-rep-2",
    "title": "Data structures",
    "section": "Create repetitions with rep()\n",
    "text": "Create repetitions with rep()\n\nRepeat sequences\n\nrep(1:4, times = 3)\n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4\n\n\n\nrep(1:4, each = 3)\n\n [1] 1 1 1 2 2 2 3 3 3 4 4 4\n\n\n\n\n\n\n\n\n\nTry it!\n\n\nCreate a repetition of “yes” and “no” with 10 instance of each, alternating between the two. Then make one with 10 “yes” and then 10 “no”."
  },
  {
    "objectID": "slides/07_datastructures.html#working-with-vectors",
    "href": "slides/07_datastructures.html#working-with-vectors",
    "title": "Data structures",
    "section": "Working with vectors",
    "text": "Working with vectors\nFind vector length with length()\n\n\nmyvec3\n\n[1] \"a\" \"b\" \"c\"\n\nlength(myvec3)\n\n[1] 3\n\n\n\n\n\n\n\n\n\nTry it!\n\n\nHow long is the combined vector of myvec1 and myvec2?"
  },
  {
    "objectID": "slides/07_datastructures.html#checking-typeof-and-str",
    "href": "slides/07_datastructures.html#checking-typeof-and-str",
    "title": "Data structures",
    "section": "Checking typeof() and str()\n",
    "text": "Checking typeof() and str()\n\n\n\n\nmyvec2\n\n[1] 11 14 18 12\n\ntypeof(myvec2)\n\n[1] \"double\"\n\nstr(myvec2)\n\n num [1:4] 11 14 18 12\n\n\n\n\nmyvec3\n\n[1] \"a\" \"b\" \"c\"\n\ntypeof(myvec3)\n\n[1] \"character\"\n\nstr(myvec3)\n\n chr [1:3] \"a\" \"b\" \"c\""
  },
  {
    "objectID": "slides/07_datastructures.html#index-with",
    "href": "slides/07_datastructures.html#index-with",
    "title": "Data structures",
    "section": "Index with []\n",
    "text": "Index with []\n\nTracks the content of a specific element (starting with 1)\n\n\nmyvec2\n\n[1] 11 14 18 12\n\nmyvec2[2]\n\n[1] 14\n\n\n\n\nAllows subsetting\n\nmyvec2[2:4]\n\n[1] 14 18 12\n\nmyvec2[c(4, 1, 3)]\n\n[1] 12 11 18\n\n\n\n\nAllows reassignment\n\nmyvec2[2] &lt;- NA\nmyvec2\n\n[1] 11 NA 18 12"
  },
  {
    "objectID": "slides/07_datastructures.html#lists",
    "href": "slides/07_datastructures.html#lists",
    "title": "Data structures",
    "section": "Lists",
    "text": "Lists\nRecursive vectors (vectors of vectors) potentially with different data types\n\n\n(mylist &lt;- list(a = 1:4, b = c(4, 3, 8, 5), c = LETTERS[10:15], d = c(\"yes\", \"yes\")))\n\n$a\n[1] 1 2 3 4\n\n$b\n[1] 4 3 8 5\n\n$c\n[1] \"J\" \"K\" \"L\" \"M\" \"N\" \"O\"\n\n$d\n[1] \"yes\" \"yes\""
  },
  {
    "objectID": "slides/07_datastructures.html#working-with-lists",
    "href": "slides/07_datastructures.html#working-with-lists",
    "title": "Data structures",
    "section": "Working with lists",
    "text": "Working with lists\n\ntypeof(mylist)\n\n[1] \"list\"\n\ntypeof(mylist$b)\n\n[1] \"double\"\n\nstr(mylist)\n\nList of 4\n $ a: int [1:4] 1 2 3 4\n $ b: num [1:4] 4 3 8 5\n $ c: chr [1:6] \"J\" \"K\" \"L\" \"M\" ...\n $ d: chr [1:2] \"yes\" \"yes\""
  },
  {
    "objectID": "slides/07_datastructures.html#data-frames",
    "href": "slides/07_datastructures.html#data-frames",
    "title": "Data structures",
    "section": "Data frames",
    "text": "Data frames\nList of named vectors of the same length (rectangular)\n\nmydf &lt;- data.frame(\n  datetime = as.Date(c(\"2021-04-21 11:56:12\", \"2021-04-21 14:57:44\", \"2021-04-22 03:09:56\", \"2021-04-22 12:39:22\")),\n  session_complete = as.logical(c(\"TRUE\", \"TRUE\", \"TRUE\", \"FALSE\")),\n  condition = as.factor(c(\"control\", \"control\", \"experimental\", \"experimental\")),\n  mean_response = c(17.53, 24.45, 19.82, NA),\n  age = c(19, 20, 19, NA),\n  comments = c(\"none\", \"Great study\", \"toooo long\", NA)\n  )"
  },
  {
    "objectID": "slides/07_datastructures.html#data-frames-1",
    "href": "slides/07_datastructures.html#data-frames-1",
    "title": "Data structures",
    "section": "Data frames",
    "text": "Data frames\nList of named vectors of the same length (rectangular)\n\nmydf\n\n    datetime session_complete    condition mean_response age    comments\n1 2021-04-21             TRUE      control         17.53  19        none\n2 2021-04-21             TRUE      control         24.45  20 Great study\n3 2021-04-22             TRUE experimental         19.82  19  toooo long\n4 2021-04-22            FALSE experimental            NA  NA        &lt;NA&gt;\n\n\n\n\ntypeof(mydf)\n\n[1] \"list\"\n\nstr(mydf)\n\n'data.frame':   4 obs. of  6 variables:\n $ datetime        : Date, format: \"2021-04-21\" \"2021-04-21\" ...\n $ session_complete: logi  TRUE TRUE TRUE FALSE\n $ condition       : Factor w/ 2 levels \"control\",\"experimental\": 1 1 2 2\n $ mean_response   : num  17.5 24.4 19.8 NA\n $ age             : num  19 20 19 NA\n $ comments        : chr  \"none\" \"Great study\" \"toooo long\" NA"
  },
  {
    "objectID": "slides/07_datastructures.html#creating-data-frames",
    "href": "slides/07_datastructures.html#creating-data-frames",
    "title": "Data structures",
    "section": "Creating data frames",
    "text": "Creating data frames\n\n\nCreate new vectors\n\n(mydf1 &lt;- data.frame(subject = 1:3, \n                     response = 8:6))\n\n  subject response\n1       1        8\n2       2        7\n3       3        6\n\n\n\n\nCombine existing vectors\n\nvar1 &lt;- c(1:6)\nvar2 &lt;- c(6:1)\nvar3 &lt;- c(21:26)\nmydf2 &lt;- data.frame(var1, var2, \n                    resp = var3)\nmydf2\n\n  var1 var2 resp\n1    1    6   21\n2    2    5   22\n3    3    4   23\n4    4    3   24\n5    5    2   25\n6    6    1   26"
  },
  {
    "objectID": "slides/07_datastructures.html#index-with-row-column",
    "href": "slides/07_datastructures.html#index-with-row-column",
    "title": "Data structures",
    "section": "Index with [row, column]\n",
    "text": "Index with [row, column]\n\n\nmydf1\n\n  subject response\n1       1        8\n2       2        7\n3       3        6\n\nmydf1[2, 1] \n\n[1] 2\n\nmydf1[2, 1] &lt;- 6\nmydf1\n\n  subject response\n1       1        8\n2       6        7\n3       3        6"
  },
  {
    "objectID": "slides/07_datastructures.html#index-with-row-column-1",
    "href": "slides/07_datastructures.html#index-with-row-column-1",
    "title": "Data structures",
    "section": "Index with [row, column]\n",
    "text": "Index with [row, column]\n\n\n\nExtract whole rows/columns\n\nmydf1[2, ] \n\n  subject response\n2       6        7\n\nmydf1[, 2] \n\n[1] 8 7 6\n\n\n\n\nExtract subsets\n\nmydf1[2:3, 2]\n\n[1] 7 6\n\nmydf1[2:3, 1:2]\n\n  subject response\n2       6        7\n3       3        6"
  },
  {
    "objectID": "slides/07_datastructures.html#working-with-data-frames",
    "href": "slides/07_datastructures.html#working-with-data-frames",
    "title": "Data structures",
    "section": "Working with data frames",
    "text": "Working with data frames\nBut extract columns by name with $\n\n\nmydf1$response \n\n[1] 8 7 6\n\nmydf1$response[2] \n\n[1] 7\n\nmydf1$response[2:3] \n\n[1] 7 6\n\n\n\n\n\n\n\n\n\nStrain your brain\n\n\nWhy should you use column names rather than number?"
  },
  {
    "objectID": "slides/07_datastructures.html#working-with-data-frames-1",
    "href": "slides/07_datastructures.html#working-with-data-frames-1",
    "title": "Data structures",
    "section": "Working with data frames",
    "text": "Working with data frames\nView first rows with head()\n\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAdd the argument n = 10 to head(mtcars). What does this do?"
  },
  {
    "objectID": "slides/07_datastructures.html#working-with-data-frames-2",
    "href": "slides/07_datastructures.html#working-with-data-frames-2",
    "title": "Data structures",
    "section": "Working with data frames",
    "text": "Working with data frames\nView dimensions\n\ndim(mtcars)\n\n[1] 32 11\n\nnrow(mtcars)\n\n[1] 32\n\nncol(mtcars)\n\n[1] 11"
  },
  {
    "objectID": "slides/07_datastructures.html#tibbles",
    "href": "slides/07_datastructures.html#tibbles",
    "title": "Data structures",
    "section": "Tibbles",
    "text": "Tibbles\nTibbles are just tidyverse versions of data frames\n\n\n\nmydf2\n\n  var1 var2 resp\n1    1    6   21\n2    2    5   22\n3    3    4   23\n4    4    3   24\n5    5    2   25\n6    6    1   26\n\n\n\n\n(mytibble &lt;- tibble::tibble(mydf2))\n\n# A tibble: 6 × 3\n   var1  var2  resp\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     6    21\n2     2     5    22\n3     3     4    23\n4     4     3    24\n5     5     2    25\n6     6     1    26"
  },
  {
    "objectID": "slides/07_datastructures.html#mental-model-of-data-in-r",
    "href": "slides/07_datastructures.html#mental-model-of-data-in-r",
    "title": "Data structures",
    "section": "Mental model of data in R",
    "text": "Mental model of data in R"
  },
  {
    "objectID": "slides/07_datastructures.html#lets-code",
    "href": "slides/07_datastructures.html#lets-code",
    "title": "Data structures",
    "section": "Let’s code!",
    "text": "Let’s code!\nData structures coding [Rmd]"
  },
  {
    "objectID": "slides/05_rmarkdown.html#mental-model-of-file-directories",
    "href": "slides/05_rmarkdown.html#mental-model-of-file-directories",
    "title": "Literate programming",
    "section": "Mental model of file directories",
    "text": "Mental model of file directories"
  },
  {
    "objectID": "slides/05_rmarkdown.html#computer-files",
    "href": "slides/05_rmarkdown.html#computer-files",
    "title": "Literate programming",
    "section": "Computer files",
    "text": "Computer files\nAll files are collections of 1s and 0s"
  },
  {
    "objectID": "slides/05_rmarkdown.html#plain-text",
    "href": "slides/05_rmarkdown.html#plain-text",
    "title": "Literate programming",
    "section": "Plain text",
    "text": "Plain text\n\nOnly characters with no formatting\nViewable in text editor\nUsed for plain text storage (.txt, .csv) and coding (.R, .Rmd, .py, .m, .cpp)"
  },
  {
    "objectID": "slides/05_rmarkdown.html#binary",
    "href": "slides/05_rmarkdown.html#binary",
    "title": "Literate programming",
    "section": "Binary",
    "text": "Binary\n\n1s and 0s are converted to images, audio, formatted text\nWSYIWYG\nBinary document files: .docx, .xlsx, .pptx, .pdf, .png, .jpg"
  },
  {
    "objectID": "slides/05_rmarkdown.html#interacting-with-r-1",
    "href": "slides/05_rmarkdown.html#interacting-with-r-1",
    "title": "Literate programming",
    "section": "Interacting with R",
    "text": "Interacting with R\n\nConsole\nR scripts (.R)\nR Markdown files (.Rmd)"
  },
  {
    "objectID": "slides/05_rmarkdown.html#console",
    "href": "slides/05_rmarkdown.html#console",
    "title": "Literate programming",
    "section": "Console",
    "text": "Console"
  },
  {
    "objectID": "slides/05_rmarkdown.html#scripts",
    "href": "slides/05_rmarkdown.html#scripts",
    "title": "Literate programming",
    "section": "Scripts",
    "text": "Scripts"
  },
  {
    "objectID": "slides/05_rmarkdown.html#scripts-1",
    "href": "slides/05_rmarkdown.html#scripts-1",
    "title": "Literate programming",
    "section": "Scripts",
    "text": "Scripts\nRun commands\nLine-by-line or selected code\nCtrl/Cmd+Enter\nAll code above cursor\nCtrl/Cmd+Alt/Opt+B\nAll code below cursor\nCtrl/Cmd+Alt/Opt+E"
  },
  {
    "objectID": "slides/05_rmarkdown.html#scripts-2",
    "href": "slides/05_rmarkdown.html#scripts-2",
    "title": "Literate programming",
    "section": "Scripts",
    "text": "Scripts\nRun commands\nSourcing runs whole script\nCtrl/Cmd+Shift+S"
  },
  {
    "objectID": "slides/05_rmarkdown.html#comments",
    "href": "slides/05_rmarkdown.html#comments",
    "title": "Literate programming",
    "section": "Comments",
    "text": "Comments\nComments are not executed by R\n\n2+2 # this is a comment--I can say stuff that isn't run. use me often!\n# this is also a comment--I can be on my own line!"
  },
  {
    "objectID": "slides/05_rmarkdown.html#lets-code",
    "href": "slides/05_rmarkdown.html#lets-code",
    "title": "Literate programming",
    "section": "Let’s code!",
    "text": "Let’s code!\n\n\nOpen course RStudio project.\nCreate new R script and save as test.R.\nType library(palmerpenguins).\nIs palmerpenguins loaded? How can you check?\nRun the line to load palmerpenguins.\nType print(penguins).\nSource the whole script.\nComment out the print(penguins) line.\nSource the script."
  },
  {
    "objectID": "slides/05_rmarkdown.html#literate-programming-1",
    "href": "slides/05_rmarkdown.html#literate-programming-1",
    "title": "Literate programming",
    "section": "Literate programming",
    "text": "Literate programming\n\nAn article [. . . ] in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures — Buckheit & Donoho (1995)\n\n\n\n\nBuckheit, J., & Donoho, D. L. (1995). WaveLab and reproducible research. In A. Antoniadis & G. Oppenheim (Eds.), Wavelets and Statistics (pp. 55–81). Springer-Verlag."
  },
  {
    "objectID": "slides/05_rmarkdown.html#why-use-literate-programming",
    "href": "slides/05_rmarkdown.html#why-use-literate-programming",
    "title": "Literate programming",
    "section": "Why use literate programming?",
    "text": "Why use literate programming?\n\nDirect connection between computations and presentation\nUpdating presentation is a breeze\nTransparent and reproducible\nPlain text less corruptable\nEasily create different kinds of output styles and files\nEasily switch between different templates"
  },
  {
    "objectID": "slides/05_rmarkdown.html#mental-model-of-r-markdown",
    "href": "slides/05_rmarkdown.html#mental-model-of-r-markdown",
    "title": "Literate programming",
    "section": "Mental model of R Markdown",
    "text": "Mental model of R Markdown"
  },
  {
    "objectID": "slides/05_rmarkdown.html#markdown",
    "href": "slides/05_rmarkdown.html#markdown",
    "title": "Literate programming",
    "section": "Markdown",
    "text": "Markdown\nHuman-readable markup that can be converted to formatted file types"
  },
  {
    "objectID": "slides/05_rmarkdown.html#markdown-1",
    "href": "slides/05_rmarkdown.html#markdown-1",
    "title": "Literate programming",
    "section": "Markdown",
    "text": "Markdown\nSee Markdown tutorial for Markdown syntax\nComments\nMarkdown uses HTML syntax for comments\n&lt;!-- comment here --&gt;"
  },
  {
    "objectID": "slides/05_rmarkdown.html#visual-editor",
    "href": "slides/05_rmarkdown.html#visual-editor",
    "title": "Literate programming",
    "section": "Visual editor",
    "text": "Visual editor"
  },
  {
    "objectID": "slides/05_rmarkdown.html#r-markdown",
    "href": "slides/05_rmarkdown.html#r-markdown",
    "title": "Literate programming",
    "section": "R Markdown",
    "text": "R Markdown\nHuman-readable markup that embeds R code and output into formatted file types"
  },
  {
    "objectID": "slides/05_rmarkdown.html#from-text-to-document",
    "href": "slides/05_rmarkdown.html#from-text-to-document",
    "title": "Literate programming",
    "section": "From text to document",
    "text": "From text to document\n\n\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/05_rmarkdown.html#inline-r-code",
    "href": "slides/05_rmarkdown.html#inline-r-code",
    "title": "Literate programming",
    "section": "Inline R code",
    "text": "Inline R code\nEmbed R code directly within your text with `r `\n\n\nCode:\nThe answer to 2 + 2 is `r 2 + 2`\n\n\nOutput:\nThe answer to 2 + 2 is 4."
  },
  {
    "objectID": "slides/05_rmarkdown.html#r-code-chunks",
    "href": "slides/05_rmarkdown.html#r-code-chunks",
    "title": "Literate programming",
    "section": "R code chunks",
    "text": "R code chunks\nWrite large chunks of R code outside of text\n\nCode:\n```{r}rnorm(10, mean = 0, sd = 1)```\n\n\nOutput:\n\n\n [1] -1.0138893 -0.2518792  1.0637089 -0.8048641 -0.3552777  0.8047327\n [7]  0.8152206  0.4381556  0.8739436 -0.3512369"
  },
  {
    "objectID": "slides/05_rmarkdown.html#embed-figures",
    "href": "slides/05_rmarkdown.html#embed-figures",
    "title": "Literate programming",
    "section": "Embed figures",
    "text": "Embed figures\n```{r}plot(1:10, 2:11)```"
  },
  {
    "objectID": "slides/05_rmarkdown.html#mental-model-of-r-markdown-1",
    "href": "slides/05_rmarkdown.html#mental-model-of-r-markdown-1",
    "title": "Literate programming",
    "section": "Mental model of R Markdown",
    "text": "Mental model of R Markdown"
  },
  {
    "objectID": "slides/05_rmarkdown.html#lets-code-1",
    "href": "slides/05_rmarkdown.html#lets-code-1",
    "title": "Literate programming",
    "section": "Let’s code!",
    "text": "Let’s code!\n\n\nCreate new R Markdown file.\nType “The mean of the first 9 digits is `r mean(1:9)`.”\nKnit/render the document.\nCreate a new code chunk.\nInside the code chunk, load the palmerpenguins package and print the penguins data set.\nRun the code chunk without knitting the file.\nKnit/render the file."
  },
  {
    "objectID": "slides/03_coding.html#review-mental-model-of-rstudio",
    "href": "slides/03_coding.html#review-mental-model-of-rstudio",
    "title": "Coding basics",
    "section": "Review: Mental model of RStudio",
    "text": "Review: Mental model of RStudio"
  },
  {
    "objectID": "slides/03_coding.html#coding-actions",
    "href": "slides/03_coding.html#coding-actions",
    "title": "Coding basics",
    "section": "Coding actions",
    "text": "Coding actions\n\n\nTo evaluate means to send code to the R interpreter to process\n\n\n2 + 2 is evaluated by submitting the numbers 2 and 2 to the addition function\n\n\nTo return means to output the results\n\nAfter 2 + 2 is evaluated, the number 4 is returned\n\n\nTo print means to return the output to the console\n\nOutput can be returned without being printed"
  },
  {
    "objectID": "slides/03_coding.html#comments",
    "href": "slides/03_coding.html#comments",
    "title": "Coding basics",
    "section": "Comments",
    "text": "Comments\n\nEverything on a line after a hashtag # is a comment\nComments are not evaluated\nComments can be used as notes for the reader and to prevent code from being evaluated\n\n\n# we're about to add 2 and 2\n2 + 2 # looky there, we added 2 and 2\n\n[1] 4\n\n# 2 + 2  the hashtag was before the code here, so the code was not evaluated"
  },
  {
    "objectID": "slides/03_coding.html#functions",
    "href": "slides/03_coding.html#functions",
    "title": "Coding basics",
    "section": "Functions",
    "text": "Functions\nPerform computations and return output\n\nSys.Date()\n\n[1] \"2025-01-07\"\n\n\n\n\ngetwd()\n\n[1] \"/media/jstevens/data/jstevens/OneDrive/active_sync/teach/psyc_971--data_science_visualization_in_r/dpavir_2025/slides\""
  },
  {
    "objectID": "slides/03_coding.html#arguments",
    "href": "slides/03_coding.html#arguments",
    "title": "Coding basics",
    "section": "Arguments",
    "text": "Arguments\nInformation needed by functions\n\nThey include argument names and values\n\nread.csv(file = \"mypath/myfile.csv\")\ndplyr::filter(.data = mydata, mycolumn == \"Sophomore\")\nplot(x = x, y = y)\nwrite.csv(x = mydata, file = \"mypath/myfile.csv\")\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf you give argument values in correct order, you don’t need to include argument names. But it’s usually a good idea anyway.\n\nread.csv(\"mypath/myfile.csv\")\ndplyr::filter(mydata, mycolumn == \"Sophomore\")\nplot(x, y)\nwrite.csv(mydata, \"mypath/myfile.csv\")"
  },
  {
    "objectID": "slides/03_coding.html#objects",
    "href": "slides/03_coding.html#objects",
    "title": "Coding basics",
    "section": "Objects",
    "text": "Objects\nVariables created to store information\n\nmydata &lt;- read.csv(file = \"mypath/myfile.csv\")\ntrimmed_data &lt;- dplyr::filter(.data = mydata, mycolumn == \"Sophomore\")\nmyplot &lt;- plot(x = x, y = y)"
  },
  {
    "objectID": "slides/03_coding.html#assignment",
    "href": "slides/03_coding.html#assignment",
    "title": "Coding basics",
    "section": "Assignment",
    "text": "Assignment\nAssign a value or set of values to an object\n\n# the best way\nx &lt;- 9\n# avoid this\ny = 10\n# definitely don't do this\n11 -&gt; z\n\n\n\n\n\n\n\n\nNote\n\n\nYou can assign multiple objects at the same time:\n\n# chain assignments of the same value to different objects\na &lt;- b &lt;- c &lt;- 0"
  },
  {
    "objectID": "slides/03_coding.html#assignment-1",
    "href": "slides/03_coding.html#assignment-1",
    "title": "Coding basics",
    "section": "Assignment",
    "text": "Assignment\nViewing object contents while assigning\n\nx &lt;- 9  # assign value 9 to object x\n\n\n\nx  # print contents of object x to console\n\n[1] 9\n\n\n\n\n\n(x &lt;- 9)  # add parentheses to print to console when assigning\n\n[1] 9"
  },
  {
    "objectID": "slides/03_coding.html#mental-model-of-coding",
    "href": "slides/03_coding.html#mental-model-of-coding",
    "title": "Coding basics",
    "section": "Mental model of coding",
    "text": "Mental model of coding"
  },
  {
    "objectID": "slides/03_coding.html#who-are-we-coding-for",
    "href": "slides/03_coding.html#who-are-we-coding-for",
    "title": "Coding basics",
    "section": "Who are we coding for?",
    "text": "Who are we coding for?\n\n\nComputer\nOurselves\nOthers"
  },
  {
    "objectID": "slides/03_coding.html#how-to-write-good-code",
    "href": "slides/03_coding.html#how-to-write-good-code",
    "title": "Coding basics",
    "section": "How to write good code",
    "text": "How to write good code\nThe Fundamental Theorem of Readability\n\n\nCode should be written to minimize the time it would take for someone else to understand it.\n\n\nFrom: The Art of Readable Code by Boswell et al. 2011"
  },
  {
    "objectID": "slides/03_coding.html#principles-of-writing-good-code",
    "href": "slides/03_coding.html#principles-of-writing-good-code",
    "title": "Coding basics",
    "section": "Principles of writing good code",
    "text": "Principles of writing good code\n\n\nWrite less code\nAvoid repetition\nUse clear syntax\nUse good names\nUse comments"
  },
  {
    "objectID": "slides/03_coding.html#coding-style-spacing",
    "href": "slides/03_coding.html#coding-style-spacing",
    "title": "Coding basics",
    "section": "Coding style: Spacing",
    "text": "Coding style: Spacing\n\n\nmean1&lt;-mean (x[1,4:10],na.rm=TRUE)+0.5\n\n\n\n\nmean1 &lt;- mean(x[1, 4:10], na.rm = TRUE) + 0.5"
  },
  {
    "objectID": "slides/03_coding.html#coding-style-clarity",
    "href": "slides/03_coding.html#coding-style-clarity",
    "title": "Coding basics",
    "section": "Coding style: Clarity",
    "text": "Coding style: Clarity\n\n\nmean(x, T)\n\n\n\n\nmean(x, na.rm = TRUE)"
  },
  {
    "objectID": "slides/03_coding.html#coding-style-indenting",
    "href": "slides/03_coding.html#coding-style-indenting",
    "title": "Coding basics",
    "section": "Coding style: Indenting",
    "text": "Coding style: Indenting\n\n\nfor(i in 1:10) {\nfor(j in 1:5) {\nprint(x[i, j])\n}\n}\n\n\n\n\nfor(i in 1:10) {\n  for(j in 1:5) {\n    print(x[i, j])\n  }\n}"
  },
  {
    "objectID": "slides/03_coding.html#coding-style-line-breaks",
    "href": "slides/03_coding.html#coding-style-line-breaks",
    "title": "Coding basics",
    "section": "Coding style: Line breaks",
    "text": "Coding style: Line breaks\n\n\nif (x &gt; 5) {print(\"Too big!\")}\n\n\n\n\nif (x &gt; 5) {\n  print(\"Too big!\")\n}"
  },
  {
    "objectID": "slides/03_coding.html#coding-style",
    "href": "slides/03_coding.html#coding-style",
    "title": "Coding basics",
    "section": "Coding style",
    "text": "Coding style\nThe tidyverse style guide\n\nUse &lt;- as assignment operator\nUse space between operators (*, =, ==) and after commas\nDo not use space between function and parentheses \nUse indents to separate nested components (Ctrl+I)\nWrite out argument names\nWrite out TRUE and FALSE\nUse \", not ', for quoting text unless it already contains double quotes"
  },
  {
    "objectID": "slides/03_coding.html#naming-things-1",
    "href": "slides/03_coding.html#naming-things-1",
    "title": "Coding basics",
    "section": "Naming things",
    "text": "Naming things\nCore principles for naming objects, data columns, files, folders\n\nBe nice to machines\nBe nice to humans\nMake sorting and searching easy\n\n\n\nSources: Naming things: Jenny Bryan, Project structure: Danille Navarro"
  },
  {
    "objectID": "slides/03_coding.html#be-nice-to-machines",
    "href": "slides/03_coding.html#be-nice-to-machines",
    "title": "Coding basics",
    "section": "Be nice to machines",
    "text": "Be nice to machines\n\n\navoid spaces, special characters, and accented characters\n\n\nmy_file.R not My filé$.R\n\n\n\navoid case sensitivity\n\n\nfoo.R and Foo.R\n\n\n\nuse consistent, searchable text chunks\n\nexpt1_cond2_subj114.csv\n\n\ncan’t start with a number"
  },
  {
    "objectID": "slides/03_coding.html#be-nice-to-humans",
    "href": "slides/03_coding.html#be-nice-to-humans",
    "title": "Coding basics",
    "section": "Be nice to humans",
    "text": "Be nice to humans\n\n\nbe descriptive (not x) but not too descriptive (this_is_my_object)\n\n\n\n\nseparate words (preferably using snake_case) \n\n\n\n\n\navoid capital letters (case matters: a ≠ A)\n\n\n\n\nuse human readable names that contain content (slugs)\n\nprelim_analysis_expt1.R"
  },
  {
    "objectID": "slides/03_coding.html#make-sorting-and-searching-easy",
    "href": "slides/03_coding.html#make-sorting-and-searching-easy",
    "title": "Coding basics",
    "section": "Make sorting and searching easy",
    "text": "Make sorting and searching easy\n\n\nuse ISO 8601 standard for date YYYY-MM-DD\n\nno, really—always use ISO 8601 standard for date!!\nuse ISO 8601 dates before or after slugs\n\n2021-04-06_prelim_analysis_expt1.Rmd\nprelim_analysis_expt1_2021-04-06.Rmd\n\n\nuse padded numbers as prefixes\n\n01_preface.Rmd\n02_introduction.Rmd"
  },
  {
    "objectID": "slides/03_coding.html#mental-model-of-coding-1",
    "href": "slides/03_coding.html#mental-model-of-coding-1",
    "title": "Coding basics",
    "section": "Mental model of coding",
    "text": "Mental model of coding"
  },
  {
    "objectID": "slides/03_coding.html#lets-code",
    "href": "slides/03_coding.html#lets-code",
    "title": "Coding basics",
    "section": "Let’s code!",
    "text": "Let’s code!\nCoding basics [Rmd file]"
  },
  {
    "objectID": "slides/01_introduction.html#course-goal",
    "href": "slides/01_introduction.html#course-goal",
    "title": "Data Processing and Visualization in R",
    "section": "Course goal",
    "text": "Course goal\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/01_introduction.html#course-information",
    "href": "slides/01_introduction.html#course-information",
    "title": "Data Processing and Visualization in R",
    "section": "Course information",
    "text": "Course information\nCourse structure and materials\n\n\nBefore class: Readings and presentations\nDuring class: Coding\nAfter class: Exercises\nCourse website: dpavir.org\n\nResources"
  },
  {
    "objectID": "slides/01_introduction.html#course-information-1",
    "href": "slides/01_introduction.html#course-information-1",
    "title": "Data Processing and Visualization in R",
    "section": "Course information",
    "text": "Course information\nAssignments\n\n\nLearning journal\nExercises\nCheck-ins\nProjects"
  },
  {
    "objectID": "slides/01_introduction.html#course-information-2",
    "href": "slides/01_introduction.html#course-information-2",
    "title": "Data Processing and Visualization in R",
    "section": "Course information",
    "text": "Course information\nAssignments\n\nCReativity"
  },
  {
    "objectID": "slides/01_introduction.html#course-information-3",
    "href": "slides/01_introduction.html#course-information-3",
    "title": "Data Processing and Visualization in R",
    "section": "Course information",
    "text": "Course information\nDiversity, inclusion, wellness\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/01_introduction.html#questions",
    "href": "slides/01_introduction.html#questions",
    "title": "Data Processing and Visualization in R",
    "section": "Questions",
    "text": "Questions\nQuestions about R or the course?"
  },
  {
    "objectID": "slides/01_introduction.html#conventions",
    "href": "slides/01_introduction.html#conventions",
    "title": "Data Processing and Visualization in R",
    "section": "Conventions",
    "text": "Conventions\n\nAll code is in monospace font text\nR functions end with parentheses: function()\nDirectory names end with slash: home/\nPackage names are surrounded by curly braces: {tidyverse}\nKeyboard buttons separate keys with a plus: Ctrl+S\nThese are parentheses (), brackets [], and braces {}\nLinks are in light blue text"
  },
  {
    "objectID": "slides/01_introduction.html#mental-model-of-r",
    "href": "slides/01_introduction.html#mental-model-of-r",
    "title": "Data Processing and Visualization in R",
    "section": "Mental model of R",
    "text": "Mental model of R"
  },
  {
    "objectID": "slides/01_introduction.html#base-r-vs.-tidyverse",
    "href": "slides/01_introduction.html#base-r-vs.-tidyverse",
    "title": "Data Processing and Visualization in R",
    "section": "Base R vs. tidyverse",
    "text": "Base R vs. tidyverse"
  },
  {
    "objectID": "slides/01_introduction.html#lets-code",
    "href": "slides/01_introduction.html#lets-code",
    "title": "Data Processing and Visualization in R",
    "section": "Let’s code!",
    "text": "Let’s code!\nIntroduction coding [Rmd file]"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Data Processing and Visualization in R",
    "section": "",
    "text": "Note this is tentative!\n\n\n\n\n\n\nWeek\nDate\nModule\nTopic\n\n\n\n\n1\n2025-01-20\n1\nMLK Day\n\n\n\n2025-01-22\n1\nCourse introduction\n\n\n\n2025-01-24\n1\nWorking in RStudio\n\n\n2\n2025-01-27\n1\nCoding basics\n\n\n\n2025-01-29\n1\nWorkflows\n\n\n\n2025-01-31\n1\nLiterate programming\n\n\n3\n2025-02-03\n2\nData types\n\n\n\n2025-02-05\n2\nData structures\n\n\n\n2025-02-07\n2\nImporting data\n\n\n4\n2025-02-10\n2\nValidating data\n\n\n\n2025-02-12\n3\nSelecting columns\n\n\n\n2025-02-14\n3\nMutating columns\n\n\n5\n2025-02-17\n3\nPiping commands\n\n\n\n2025-02-19\n3\nFiltering rows\n\n\n\n2025-02-21\n3\nSummarizing rows\n\n\n6\n2025-02-24\n4\nPivoting data\n\n\n\n2025-02-26\n4\nSeparating data\n\n\n\n2025-02-28\n4\nMerging columns\n\n\n7\n2025-03-03\n4\nMerging rows\n\n\n\n2025-03-05\n5\nNumbers\n\n\n\n2025-03-07\n5\nStrings\n\n\n8\n2025-03-10\n5\nMatching patterns\n\n\n\n2025-03-12\n5\nFactors\n\n\n\n2025-03-14\n5\nProject workday\n\n\n9\n2025-03-17\n\nSpring break\n\n\n\n2025-03-19\n\nSpring break\n\n\n\n2025-03-21\n\nSpring break\n\n\n10\n2025-03-24\n6\nFunctions\n\n\n\n2025-03-26\n6\nIteration\n\n\n\n2025-03-28\n7\nGrammar of graphics I\n\n\n11\n2025-03-31\n7\nGrammar of graphics II\n\n\n\n2025-04-02\n7\nDesign and themes\n\n\n\n2025-04-04\n7\nColor\n\n\n12\n2025-04-07\n8\nPlotting distributions: histograms\n\n\n\n2025-04-09\n8\nPlotting distributions: boxplots\n\n\n\n2025-04-11\n8\nPlotting amounts: bar charts\n\n\n13\n2025-04-14\n8\nPlotting x-y data: associations\n\n\n\n2025-04-16\n\nNebraska Symposium\n\n\n\n2025-04-18\n8\nPlotting x-y data: time series\n\n\n14\n2025-04-21\n8\nPlotting x-y data: categories\n\n\n\n2025-04-23\n9\nAdjusting axes\n\n\n\n2025-04-25\n9\nAnnotating plots\n\n\n15\n2025-04-28\n9\nPlotting challenge\n\n\n\n2025-04-30\n10\nTables\n\n\n\n2025-05-02\n10\nPublications\n\n\n16\n2025-05-05\n10\nAdvanced R Markdown\n\n\n\n2025-05-07\n11\nStatistics I\n\n\n\n2025-05-09\n11\nStatistics II"
  },
  {
    "objectID": "schedule.html#course-schedule",
    "href": "schedule.html#course-schedule",
    "title": "Data Processing and Visualization in R",
    "section": "",
    "text": "Note this is tentative!\n\n\n\n\n\n\nWeek\nDate\nModule\nTopic\n\n\n\n\n1\n2025-01-20\n1\nMLK Day\n\n\n\n2025-01-22\n1\nCourse introduction\n\n\n\n2025-01-24\n1\nWorking in RStudio\n\n\n2\n2025-01-27\n1\nCoding basics\n\n\n\n2025-01-29\n1\nWorkflows\n\n\n\n2025-01-31\n1\nLiterate programming\n\n\n3\n2025-02-03\n2\nData types\n\n\n\n2025-02-05\n2\nData structures\n\n\n\n2025-02-07\n2\nImporting data\n\n\n4\n2025-02-10\n2\nValidating data\n\n\n\n2025-02-12\n3\nSelecting columns\n\n\n\n2025-02-14\n3\nMutating columns\n\n\n5\n2025-02-17\n3\nPiping commands\n\n\n\n2025-02-19\n3\nFiltering rows\n\n\n\n2025-02-21\n3\nSummarizing rows\n\n\n6\n2025-02-24\n4\nPivoting data\n\n\n\n2025-02-26\n4\nSeparating data\n\n\n\n2025-02-28\n4\nMerging columns\n\n\n7\n2025-03-03\n4\nMerging rows\n\n\n\n2025-03-05\n5\nNumbers\n\n\n\n2025-03-07\n5\nStrings\n\n\n8\n2025-03-10\n5\nMatching patterns\n\n\n\n2025-03-12\n5\nFactors\n\n\n\n2025-03-14\n5\nProject workday\n\n\n9\n2025-03-17\n\nSpring break\n\n\n\n2025-03-19\n\nSpring break\n\n\n\n2025-03-21\n\nSpring break\n\n\n10\n2025-03-24\n6\nFunctions\n\n\n\n2025-03-26\n6\nIteration\n\n\n\n2025-03-28\n7\nGrammar of graphics I\n\n\n11\n2025-03-31\n7\nGrammar of graphics II\n\n\n\n2025-04-02\n7\nDesign and themes\n\n\n\n2025-04-04\n7\nColor\n\n\n12\n2025-04-07\n8\nPlotting distributions: histograms\n\n\n\n2025-04-09\n8\nPlotting distributions: boxplots\n\n\n\n2025-04-11\n8\nPlotting amounts: bar charts\n\n\n13\n2025-04-14\n8\nPlotting x-y data: associations\n\n\n\n2025-04-16\n\nNebraska Symposium\n\n\n\n2025-04-18\n8\nPlotting x-y data: time series\n\n\n14\n2025-04-21\n8\nPlotting x-y data: categories\n\n\n\n2025-04-23\n9\nAdjusting axes\n\n\n\n2025-04-25\n9\nAnnotating plots\n\n\n15\n2025-04-28\n9\nPlotting challenge\n\n\n\n2025-04-30\n10\nTables\n\n\n\n2025-05-02\n10\nPublications\n\n\n16\n2025-05-05\n10\nAdvanced R Markdown\n\n\n\n2025-05-07\n11\nStatistics I\n\n\n\n2025-05-09\n11\nStatistics II"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Readings, slides, code, exercises",
    "section": "",
    "text": "Module 1: R basics\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nGetting started with R\nBefore 2025-01-22\nSIDS 1  Wickham 2020\nSlides\nNone\nNone\n\n\nIntroduction\n2025-01-22\nR4DS2 1\nSlides\nCode\nExercises\n\n\nWorking with RStudio\n2025-01-24\nRYWM 1\nSlides\nCode\nExercises\n\n\nCoding basics\n2025-01-27\nR4DS2 3  7.1 - 7.2\nSlides\nCode\nExercises\n\n\nWorkflows\n2025-01-29\nR4DS2 9\nSlides\nNone\nExercises\n\n\nLiterate programming\n2025-01-31\nR Markdown  Markdown tutorial\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 2: Working with data\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nData types\n2025-02-03\nR4DS1 20\nSlides\nCode\nExercises\n\n\nData structures\n2025-02-05\nPWR 13\nSlides\nCode\nExercises\n\n\nImporting data\n2025-02-07\nR4DS2 22\nSlides\nCode\nExercises\n\n\nValidating data\n2025-02-10\nWikipedia\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 3: Cleaning and wrangling data\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nSelecting columns\n2025-02-12\nR4DS2 4.3.2 - 4.3.4\nSlides\nCode\nExercises\n\n\nMutating columns\n2025-02-14\nR4DS2 4.3.1\nSlides\nCode\nExercises\n\n\nPiping commands\n2025-02-17\nR4DS2 5\nSlides\nCode\nExercises\n\n\nFiltering rows\n2025-02-19\nR4DS2 4.2\nSlides\nCode\nExercises\n\n\nSummarizing rows\n2025-02-21\nR4DS2 4.4\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 4: Tidy data\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nPivoting data\n2023-02-24\nR4DS2 6\nSlides\nCode\nExercises\n\n\nSeparating data\n2025-02-26\nR4DS1 12.4 - 12.5\nSlides\nCode\nExercises\n\n\nMerging columns\n2025-02-28\nR4DS2 21.1 - 21.3.2\nSlides\nCode\nExercises\n\n\nMerging rows\n2025-03-03\nR4DS2 21.3.3 - 21.5\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 5: Transforming data values\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nNumbers\n2025-03-05\nR4DS2 14\nSlides\nCode\nNone\n\n\nStrings\n2025-03-07\nR4DS2 15\nSlides\nCode\nExercises\n\n\nMatching patterns\n2025-03-10\nR4DS2 16\nSlides\nCode\nExercises\n\n\nFactors\n2025-03-12\nR4DS2 17\nSlides\nCode\nExercises\n\n\nDates and times\n2025-03-14\nR4DS2 18\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 6: Programming\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nFunctions\n2025-03-24\nR4DS1 19\nSlides\nCode\nExercises\n\n\nIteration\n2025-03-26\nR4DS2 27\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 7: Grammar of graphics\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nGrammar of graphics I\n2025-03-28\nR4DS2 2  11\nSlides\nCode\nExercises\n\n\nGrammar of graphics II\n2025-03-31\nFDV 1, 2  3\nSlides\nCode\nExercises\n\n\nDesign and themes\n2025-04-02\nFDV 17, 25, 26, 29\nSlides, Script\nCode\nExercises\n\n\nColor\n2025-04-04\nFDV 4, 19  Cookbook for R\nSlides\nCode\nExercises\n\n\n\n\n\n\nModule 8: Plotting data\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nPlotting distributions: histograms\n2025-04-07\nFDV 7\nScript\nCode\nExercises\n\n\nPlotting distributions: boxplots\n2025-04-09\nFDV 9\nScript\nCode\nExercises\n\n\nPlotting amounts: bar charts\n2025-04-11\nFDV 6\nScript\nCode\nExercises\n\n\nPlotting x-y data: associations\n2025-04-14\nFDV 12\nScript\nCode\nExercises\n\n\nPlotting x-y data: time series\n2025-04-16\nFDV 13, 14\nScript\nCode\nExercises\n\n\nPlotting x-y data: categories\n2025-04-18\nRaincloud Plots\nScript\nCode\nExercises\n\n\n\n\n\n\nModule 9: Customizing plots\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nAdjusting axes\n2025-04-21\nFDV 21, 24\nScript\nCode\nExercises\n\n\nAnnotating plots\n2025-04-23\nFDV 22.1 - 22.2, R4DS2 13\nScript\nCode\nExercises\n\n\nDealing with overlap\n2025-04-25\nFDV 18, 20\nScript\n\nExercises\n\n\nPlotting challenge\n2023-05-01\n\nCode\n\n\n\n\n\n\n\n\nModule 10: Tables, documents, and presentations\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nTables\n2025-04-28\nFDV 22.3  RMC 10.1\nSlides\nCode\n\n\n\nPublications\n2025-05-02\npapaja manual 1\nSlides\nCode\n\n\n\nAdvanced R Markdown\n2025-05-05\nR4DS2 30\nSlides\n\n\n\n\n\n\n\n\nModule 11: Statistics\n\n\n\n\nTopic\nDate\nReadings\nSlides\nCode\nExercises\n\n\n\n\nStatistics I\n2025-05-07\n\n\n\n\n\n\nStatistics II\n2025-05-09\n\n\n\n\n\n\n\n\nFDV = Fundamentals of Data Visualization, R4DS1 = R for Data Science 1st edition, R4DS1 = R for Data Science 2nd edition, PWR = Programming with R, RMC = R Markdown Cookbook, RYWM = RYouWithMe, SIDS = Statistical Inference via Data Science"
  },
  {
    "objectID": "code/02_rstudio.html",
    "href": "code/02_rstudio.html",
    "title": "Working in RStudio",
    "section": "",
    "text": "Install the {papaja} package.\nFind the help page for the apa_num() function from {papaja}. What does it do?\nWhat is the keyboard shortcut for restarting R?\nWhat does the keyboard shortcut Ctrl/Cmd+Enter/Return do?\nType cor() in the console, and place your cursor in the word cor. Now press F1. What happened? Place your cursor back on cor and press F2. What happened?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Processing and Visualization in R",
    "section": "",
    "text": "Welcome! This course introduces students to the fundamental concepts and methods used in the R statistical software package to process, visualize, and disseminate data. The course is based around R for Data Science and Fundamentals of Data Visualization and assumes no prior coding experience."
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "Data Processing and Visualization in R",
    "section": "Course materials",
    "text": "Course materials\n\nSyllabus (with course schedule)\nClass meetings\nReadings, slides, code, exercises\nResources"
  },
  {
    "objectID": "index.html#course-modules",
    "href": "index.html#course-modules",
    "title": "Data Processing and Visualization in R",
    "section": "Course modules",
    "text": "Course modules\n\nR basics\nWorking with data\nCleaning and wrangling data\nTidy data\nTransforming data values\nProgramming\nGrammar of graphics\nPlotting data\nCustomizing plots\nTables, documents, and presentations\nStatistics\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Data Processing and Visualization in R",
    "section": "Instructor",
    "text": "Instructor\nJeffrey (Jeff) Stevens is a Professor in the Department of Psychology and the Center for Brain, Biology & Behavior at the University of Nebraska-Lincoln. He is also a Data Science Mentor at Posit (formerly RStudio), a company that develops open source data science tools such as RStudio IDE and tidyverse. Jeff has been using R since 2010 (and the predecessor S-PLUS since 1998) and integrating it into his documents and presentations since then. He has also developed three R packages available on CRAN: {excluder} helps researchers exclude participant data collected from online surveys; {flashr} creates flashcards for learning terms and descriptions to help people learn and remember what R functions do; and {cocoon} helps researchers extract, format, and print statistics in their R Markdown or Quarto documents."
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Data Processing and Visualization in R",
    "section": "Citation",
    "text": "Citation\nIf you use materials from this site, please cite:\n\nStevens, J.R. (2025). Data Processing and Visualization in R. http://dpavir.org"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Data Processing and Visualization in R",
    "section": "License",
    "text": "License\nAll materials presented here are released under the Creative Commons Attribution 4.0 International Public License (CC BY 4.0). You are free to:\n\nShare — copy and redistribute the material in any medium or format\nAdapt — remix, transform, and build upon the material for any purpose, even commercially.\n\nUnder the following terms:\n\nAttribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits."
  },
  {
    "objectID": "meetings.html",
    "href": "meetings.html",
    "title": "Class meetings",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "To install all of the course packages:\n\nIf you are using Windows, first install RTools.\nThen copy and paste the following line to install most of the packages needed for the course (click the little clipboard in top right corner to copy everything).\nWarning: it may take a while for these to install, so don’t start this if you need access to your R session (or open another R session to do this).\n\n\ninstall.packages(c(\"here\", \"palmerpenguins\", \"remotes\", \"tidyverse\", \"knitr\", \"rmarkdown\", \"papaja\", \"tinytex\", \"dataReporter\", \"qualtRics\", \"readxl\", \"nycflights13\", \"ggthemes\", \"patchwork\", \"gt\"))\n\nClick Full package list below to see all packages with links to their websites.\n\nFull package list\n\n\n{here}\n{palmerpenguins}\n{remotes}\n{tidyverse}\n\n\n{knitr}\n{rmarkdown}\n{papaja}\n{tinytex}\n\n\n{dataReporter}\n{qualtRics}\n{readxl}\n\n\n{nycflights13}\n\n\n{ggthemes}\n{patchwork}\n{gt}"
  },
  {
    "objectID": "resources.html#packages",
    "href": "resources.html#packages",
    "title": "Resources",
    "section": "",
    "text": "To install all of the course packages:\n\nIf you are using Windows, first install RTools.\nThen copy and paste the following line to install most of the packages needed for the course (click the little clipboard in top right corner to copy everything).\nWarning: it may take a while for these to install, so don’t start this if you need access to your R session (or open another R session to do this).\n\n\ninstall.packages(c(\"here\", \"palmerpenguins\", \"remotes\", \"tidyverse\", \"knitr\", \"rmarkdown\", \"papaja\", \"tinytex\", \"dataReporter\", \"qualtRics\", \"readxl\", \"nycflights13\", \"ggthemes\", \"patchwork\", \"gt\"))\n\nClick Full package list below to see all packages with links to their websites.\n\nFull package list\n\n\n{here}\n{palmerpenguins}\n{remotes}\n{tidyverse}\n\n\n{knitr}\n{rmarkdown}\n{papaja}\n{tinytex}\n\n\n{dataReporter}\n{qualtRics}\n{readxl}\n\n\n{nycflights13}\n\n\n{ggthemes}\n{patchwork}\n{gt}"
  },
  {
    "objectID": "resources.html#glossary",
    "href": "resources.html#glossary",
    "title": "Resources",
    "section": "Glossary",
    "text": "Glossary\nIf you want to find definitions of the terms that we use in the course, check out the PsyTeachR Glossary"
  },
  {
    "objectID": "resources.html#function-list",
    "href": "resources.html#function-list",
    "title": "Resources",
    "section": "Function list",
    "text": "Function list\nThis is a list of all of the functions that we will be learning throughout the course. Note these may change as we progress through the course. Click Full function list below to see all functions with links to their websites.\n\nFull function list\nPackages\n\n\ninstall.packages(): install R packages\n\nlibrary(): load R packages\n\n:: export variable from package for use\nData types\n\n\n&gt;, &gt;=, &lt;, &lt;=, ==, !=, %in%: logical operators that output TRUE or FALSE\n\n\ntypeof(), class(), str(): outputs object type, class, and structure\n\nis.numeric(), is.character(), is.factor(): checks whether object is numeric, character, factor\n\nas.numeric(), as.character(), as.factor(): coerces (converts) object to numeric, character, factor\n\nis.na(): checks whether object is NA and outputs logical\nData structures\n\n\n[]: index elements in vector, matrix, data frame, tibble\n\n$: index column by name in data frame, tibble, list\n\n:, seq(), rep(): creates sequences and repetitions of numbers\n\nlength(): outputs length of vector\n\ndim(), nrow(), ncol(): outputs dimensions, number of rows, number of columns of matrices, data frames, tibbles\n\ncolnames(): outputs (and can assign) column names\n\nhead(), tail(), dplyr::glimpse(): outputs compressed views of data frames, tibbles\n\nc(), list(), data.frame(), tibble::tibble(): creates vectors, matrices, data frames, tibbles\nImporting data\n\n\nhere::here(): starts path at project directory\n\nread.csv(), write.csv(), readr::read_csv(), readr::write_csv(): imports and writes CSV files\n\nreadxl::read_excel(): imports Excel files\nValidating data\n\n\nrange(), min(), max(): finds range, minimum, and maximum of vector\n\nunique(): returns vector of unique (not duplicated) elements\n\nduplicated(): returns logical vector of duplicated elements\n\nwhich(): returns indices of which elements of a logical vector are TRUE\n\n\nsummary(): when applied to day, gives summary statistics\n\nskimr::skim(): outputs overview of data\n\ndataReporter::makeCodebook(): creates codebook of data\nCleaning columns\n\n\ndplyr::select(): selects subset of columns from data frame, tibble\n\ndplyr::everything(), dplyr::contains(), dplyr::starts_with(), dplyr::ends_with(): helper functions for select()\n\n\ndplyr::relocate(), dplyr::rename(): moves and renames columns in data frame, tibble\n\ndplyr::mutate(), dplyr::transmute(): applies function to change existing column or create new column\n\ndplyr::across(): applies function across multiple columns inside mutate()\n\n\ndplyr::rowwise(): applies function to each row\n\n%&gt;%: pipe operator that transfers output to the next command\n\ndplyr::pull(): creates a vector from a data frame/tibble column\nWrangling rows\n\n\ndplyr::filter(): filters subset of rows from data frame, tibble\n\ndplyr::if_any(): apply function to columns and return TRUE if any values are TRUE\n\ntidyr::drop_na(): drop rows containing missing values\n\ndplyr::arrange(), dplyr::desc(): sorts rows by column variable, in descending order\n\ndplyr::group_by(): groups data by column levels\n\ndplyr::summarise(): applies function over whole column or group\nTidy data\n\n\ntidyr::pivot_longer(), tidyr::pivot_wider(): reshapes data to be longer or wider\n\ntidyr::separate(), tidyr::unite(): separates or combines column data with separator\n\ndplyr::coalesce(): find the first non-missing element\n\ntidyr::complete(), tidyr::expand(), tidyr::nesting(): finds all unique combinations of levels\nMerging data\n\n\ndplyr::inner_join(), dplyr::left_join(), dplyr::right_join(){target=“_blank”}, dplyr::full_join(): mutating joins that merge data frames\n\ndplyr::semi_join(), dplyr::anti_join(): filtering joins that filter data frame based on another data frame\n\ndplyr::join_by(): join data frames with different names for key columns (requires {dplyer} v. 1.1.0 or higher)\n\ntibble::add_row(): manually add rows of data\n\ndplyr::bind_rows(), dplyr::bind_cols(): binds rows or columns to data frame\n\ndplyr::intersect(), dplyr::setdiff(), dplyr::union(), dplyr::union_all(): set operations to find overlap, differences, and combinations of data sets\nNumbers\n\n\ndplyr::count(), dplyr::n(), dplyr::n_distinct(): count instances of group levels\n\nround(): round digits\n\nformat(): format numbers\n\ncut(): bin numbers into ranges\nStrings\n\n\nstringr::str_length(): finds the number of characters in a string\n\nstringr::str_sub(): extracts parts of strings based on character position\n\nstringr::str_to_lower(), stringr::str_to_upper(): converts all letters to lowercase or uppercase\n\nstringr::str_to_title(), stringr::str_to_sentence(): converts strings to title or sentence case\n\nstringr::str_c(): combine character vectors into single string\n\nstringr::str_glue(): combines strings with R output\n\npaste(), paste0(): combines strings with R output\n\nstringr::str_detect(), stringr::str_subset(), stringr::str_extract(): detects, subsets, and extracts strings\n\nstringr::str_replace(), stringr::str_replace_all(): replaces patterns with strings\n\nstringr::str_split(): splits strings based on separators\nFactors\n\n\nlevels(): prints factor levels\n\nforcats::fct_inorder(), forcats::fct_rev(): orders levels by order in data or in reverse of current order\n\nforcats::fct_relevel(): manually reorders levels\n\nforcats::fct_reorder(): orders levels based on another variable\n\nforcats::fct_recode(): recodes level with new value\n\nforcats::fct_collapse(): recodes multiple levels into single new value\n\nforcats::fct_lump_n(), forcats::fct_lump_prop(),forcats::fct_lump_min(): lumps infrequent levels into level “Other”\nDates and times\n\n\nlubridate::today(), lubridate::now(): print today’s date or time\n\nlubridate::as_date(), lubridate::as_datetime(): create date or date-time object\n\nlubridate::mdy(), lubridate::dmy(), lubridate::ymd(): convert various date formats to YYYY-MM-DD\n\nlubridate::hms(), lubridate::hm(): convert times to HH:MM:SS\n\nlubridate::mdy_hm(), lubridate::mdy_hms(): converts various date-time formats to YYYY-MM-DD HH:MM:SS\n\nlubridate::year(), lubridate::month(), lubridate::day(), lubridate::wday(): extracts year, month, day, or weekday from date\n\nlubridate::hour(), lubridate::minute(), lubridate::second(): extracts hour, minute, second from date\nIteration\n\n\nfor(): create for loops\n\npurrr::map(), purrr::map_dbl(), purrr::map_chr(), purrr::map_df(): map functions to vector, data frame, or list and return list, numeric vector, character vector, or data frame\n\nsplit(): divide data frame into groups in a list\n\ndir(): return files in a directory\nGrammar of graphics\n\n\nggplot2::ggplot(): creates a ggplot\n\n+: pipe operator for ggplots\n\nggplot2::aes(): defines aesthetic properties of plot\n\nalpha, color, fill, linesize, linetype, shape, size arguments: properties for geometric objects\n\nggplot2::theme(): Modify components of a theme\n\nggplot2::ggsave(): saves ggplot to file\nColor\n\n\nggplot2::scale_color_brewer(), ggplot2::scale_fill_brewer(): uses existing qualitative colors scales for color and fill\n\nggplot2::scale_color_manual(), ggplot2::scale_fill_manual(): sets manual colors for color and fill\n\nggplot2::scale_color_gradient(), ggplot2::scale_fill_gradient(): sets sequential color gradient for color and fill\n\nggplot2::scale_color_distiller(), ggplot2::scale_fill_distiller(): sets diverging color scale for color and fill\nVisualizing distributions\n\n\nggplot2::geom_histogram(): plots histograms\n\nggplot2::geom_freqpoly(): plots frequency polygons\n\nggplot2::geom_density(): plots density plot\n\nggplot2::geom_boxplot(): plots boxplot\n\nggplot2::geom_violin(): plots violin plot\n\nggplot2::stat_summary(): plots summaries of data (e.g., means \\(\\pm\\) standard error)\nVisualizing amounts and proportions\n\n\ndplyr::count(): calculates counts of data by variables\n\nggplot2::geom_bar(): plots bar plot with raw data\n\nggplot2::geom_col(): plots bar plot with counts\n\nposition argument: controls whether data are stacked, dodged, jittered, nudged\n\nggplot2::geom_point(): plots scatterplots\n\nggplot2::coord_flip(): flips x and y coordinates\nVisualizing x-y data\n\n\nggplot2::geom_abline(): plots line with slope and intercept\n\npairs(): plots correlation plots\n\nGGally::ggpairs(): plots correlation plots\n\nggplot2::geom_tile(): plots tile plot\n\nggcorrplot::ggcorrplot(): plots correlation heatmaps\n\nggplot2::geom_line(): plots line plot\n\nggplot2::geom_area(): plots area under curve or line plot\n\nggplot2::geom_count(): plots overlapping points as size\n\nggplot2::geom_smooth(): plots fitted lines and curves\n\nggplot2::geom_rug(): plots rug plot\n\nggplot2::geom_pointrange(): plots point and error bar\n\nggplot2::geom_jitter(): plots jittered points\n\nggbeeswarm::geom_beeswarm(): plots beeswarm plots\n\ngghalves::geom_half_violin(), gghalves::geom_half_dotplot(): plots raincloud plots\nFinessing plots\n\n\nggplot2::geom_jitter(): plots jittered scatterplot\n\nggbeeswarm::geom_beeswarm(): plots beeswarm plot\n\nggplot2::scale_x_discrete(), ggplot2::scale_y_discrete(): adjusts discrete scale properties (e.g., limits, ticks)\n\nggplot2::scale_x_continuous(), ggplot2::scale_y_continuous(): adjusts continuous scale properties (e.g., limits, ticks)\n\nggplot2::lims(), ggplot2::xlim(), ggplot2::ylim(): adjusts axis limits\n\nggplot2::facet_wrap(), ggplot2::facet_grid(): creates facets based on discrete variables\nAdorning plots\n\n\nggplot2::labs(), ggplot2::xlab(), ggplot2::ylab(): replaces axis labels\n\nggplot2::annotate(): annotates plot with text, segments, rectangles, etc.\n\nggplot2::geom_text(): plots text as aesthetic property\n\nggplot2::geom_hline(), ggplot2::geom_vline(): plots horizontal and vertical reference lines\n\nggplot2::stat_ellipse(): plots ellipse around data\nTables\n\n\nknitr::kable(): creates table from data frame\n\nkableExtra::kable_styling(): styles table\n\nkableExtra::pack_rows(), kableExtra::add_header_above(): adds grouping variables to rows or columns\n\nkableExtra::footnote(): adds table note\n\nkableExtra::landscape(): rotates table to landscape orientation\n\npapaja::apa_table(): formats data frame to APA style table\n\npapaja::apa_print(): formats statistics to APA style"
  },
  {
    "objectID": "resources.html#flashcards",
    "href": "resources.html#flashcards",
    "title": "Resources",
    "section": "Flashcards",
    "text": "Flashcards\nFlashcards can be a useful way to help learning functions and their descriptions. I created a package called {flashr} that builds decks of HTML flashcards. You’re welcome to build your own decks of flashcards by installing the package and following the instructions for building decks. Or, you can use existing decks built for the course or for each of the chapters of R for Data Science (1st edition).\n\nDPaViR flashcards\n\nIntroduction (terms first) (definitions first)\nCoding and workflows (terms first) (definitions first)\nData types (terms first) (definitions first)\nData structures (terms first) (definitions first)\nImporting data (terms first) (definitions first)\nValidating data (terms first) (definitions first)\nCleaning columns (terms first) (definitions first)\nWrangling rows (terms first) (definitions first)\nTidy data (terms first) (definitions first)\nMerging data (terms first) (definitions first)\nNumbers (terms first) (definitions first)\nStrings (terms first) (definitions first)\nFactors (terms first) (definitions first)\nDates and times (terms first) (definitions first)\nIteration (terms first) (definitions first)  \n\n\nR4DS flashcards\n\nCh. 1 Introduction\nCh. 3 Data visualization\nCh. 5 Data transformation\nCh. 7 Exploratory data analysis\nCh. 8 Workflow: projects\nCh. 10 Tibbles\nCh. 11 Data import\nCh. 12 Tidy data\nCh. 13 Relational data\nCh. 14 Strings\nCh. 15 Factors\nCh. 16 Dates and times\nCh. 18 Pipes\nCh. 20 Vectors\nCh. 21 Iteration\nCh. 23 Model basics\nCh. 25 Many models\nCh. 27 R Markdown\nCh. 28 Graphics for communication\nCh. 29 R Markdown formats\nCh. 30 R Markdown workflow"
  },
  {
    "objectID": "resources.html#miscellaneous",
    "href": "resources.html#miscellaneous",
    "title": "Resources",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\nCheatsheets\nTidyverse style\nPsyTeachR books"
  },
  {
    "objectID": "slides/00_getting_started.html#what-is-r",
    "href": "slides/00_getting_started.html#what-is-r",
    "title": "Getting started with R",
    "section": "What is R?",
    "text": "What is R?\nR is a statistical programming language."
  },
  {
    "objectID": "slides/00_getting_started.html#what-is-r-1",
    "href": "slides/00_getting_started.html#what-is-r-1",
    "title": "Getting started with R",
    "section": "What is R?",
    "text": "What is R?\nR is a statistical programming language.\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/00_getting_started.html#what-is-r-2",
    "href": "slides/00_getting_started.html#what-is-r-2",
    "title": "Getting started with R",
    "section": "What is R?",
    "text": "What is R?\nR is a statistical programming language.\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/00_getting_started.html#what-is-r-3",
    "href": "slides/00_getting_started.html#what-is-r-3",
    "title": "Getting started with R",
    "section": "What is R?",
    "text": "What is R?\nR is a statistical programming language.\n\nSource: Twitter"
  },
  {
    "objectID": "slides/00_getting_started.html#what-is-r-4",
    "href": "slides/00_getting_started.html#what-is-r-4",
    "title": "Getting started with R",
    "section": "What is R?",
    "text": "What is R?\nR is a statistical programming language.\nIt allows you to flexibly\n\nwrangle\nanalyze\nvisualize your data\ncreate reproducible documents"
  },
  {
    "objectID": "slides/00_getting_started.html#conventions",
    "href": "slides/00_getting_started.html#conventions",
    "title": "Getting started with R",
    "section": "Conventions",
    "text": "Conventions\n\nAll code is in monospace font peach text\nR functions end with parentheses: function()\nDirectory names end with slash: home/\nPackage names are surrounded by curly braces: tidyverse\nKeyboard buttons separate keys with a plus: Ctrl+S\nThese are parentheses (), brackets [], and braces {}\nLinks are in light blue text"
  },
  {
    "objectID": "slides/00_getting_started.html#getting-started",
    "href": "slides/00_getting_started.html#getting-started",
    "title": "Getting started with R",
    "section": "Getting started",
    "text": "Getting started\nInstalling R\nDownload at https://r-project.org.\nFor Windows, also install Rtools"
  },
  {
    "objectID": "slides/00_getting_started.html#getting-started-1",
    "href": "slides/00_getting_started.html#getting-started-1",
    "title": "Getting started with R",
    "section": "Getting started",
    "text": "Getting started\nInstalling RStudio\nRStudio is an Integrated Development Environment (IDE). Download from Posit"
  },
  {
    "objectID": "slides/00_getting_started.html#getting-started-2",
    "href": "slides/00_getting_started.html#getting-started-2",
    "title": "Getting started with R",
    "section": "Getting started",
    "text": "Getting started\nInteracting with R\nUsing the R console"
  },
  {
    "objectID": "slides/00_getting_started.html#packages",
    "href": "slides/00_getting_started.html#packages",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nPackages are collections of function and data sets"
  },
  {
    "objectID": "slides/00_getting_started.html#packages-1",
    "href": "slides/00_getting_started.html#packages-1",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nBase R is a core set of packages for all R installations.\n\nSource: A ModernDive into R and the Tidyverse\n\n\n\n\n\n\nNote\n\n\nUser-contributed packages can be found on the Comprehensive R Archive Network or CRAN.\n\n\n\n\nBase R is the core, default software needed to run R maintained by the R Development Team. It includes a few core packages that underly much of R.\nBut other people can contribute packages, or collections of data and functions.\nThe official repository for R packages is the Comprehensive R Archive Network or CRAN. There are more than 19,000 packages on CRAN!\nPackages can also be stored at other locations such as GitHub, especially during development."
  },
  {
    "objectID": "slides/00_getting_started.html#packages-2",
    "href": "slides/00_getting_started.html#packages-2",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nInstalling\nIn the console type\ninstall.packages(\"&lt;package_name&gt;\") where &lt;package_name&gt; is the name of the package."
  },
  {
    "objectID": "slides/00_getting_started.html#packages-3",
    "href": "slides/00_getting_started.html#packages-3",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nInstalling\nTry installing the {palmerpenguins} package.\n\ninstall.packages(\"palmerpenguins\")\n\n\nYou can install multiple packages simultaneously by wrapping them with c(). For example,\n\ninstall.packages(c(\"remotes\", \"here\"))"
  },
  {
    "objectID": "slides/00_getting_started.html#packages-4",
    "href": "slides/00_getting_started.html#packages-4",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nLoading packages\n\n\nSource: Preceptor’s Primer for Bayesian Data Science"
  },
  {
    "objectID": "slides/00_getting_started.html#packages-5",
    "href": "slides/00_getting_started.html#packages-5",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nLoading packages\nLoad the {here} package:\n\nlibrary(\"here\")\n\n\n\n\n\n\n\n\nNote\n\n\nEvery time you close your R session, you’ll have to reload the packages you were using.\n\n\n\n\nInstalling packages just means that you have copies of them on your computer. You have to load them for R to have access to their functionality. To load packages, use the library() function.\nNow, all of the functions in the here package are available for us to use."
  },
  {
    "objectID": "slides/00_getting_started.html#packages-6",
    "href": "slides/00_getting_started.html#packages-6",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nUsing\nLet’s view the penguins data set from the palmerpenguins package.\nTry this:\n\npenguins\n\n\nYou should receive Error: object 'penguins' not found. Why did you receive this error?\n\nOnce you load a package, you have access to all of its functions for that R session. But if it is not loaded, you won’t have access."
  },
  {
    "objectID": "slides/00_getting_started.html#packages-7",
    "href": "slides/00_getting_started.html#packages-7",
    "title": "Getting started with R",
    "section": "Packages",
    "text": "Packages\nBut you can either load the palmerpenguins package, or use this trick to call a specific function from a specific package.\n\npalmerpenguins::penguins"
  },
  {
    "objectID": "slides/00_getting_started.html#tidyverse",
    "href": "slides/00_getting_started.html#tidyverse",
    "title": "Getting started with R",
    "section": "tidyverse",
    "text": "tidyverse"
  },
  {
    "objectID": "slides/00_getting_started.html#core-tidyverse-packages",
    "href": "slides/00_getting_started.html#core-tidyverse-packages",
    "title": "Getting started with R",
    "section": "Core tidyverse packages",
    "text": "Core tidyverse packages\n\nggplot2, for data visualisation\ndplyr, for data manipulation\ntidyr, for data tidying\nreadr, for data import\npurrr, for functional programming\ntibble, for tibbles, a version of data frames\nstringr, for strings\nforcats, for factors\nlubridate, for dates"
  },
  {
    "objectID": "slides/00_getting_started.html#homework",
    "href": "slides/00_getting_started.html#homework",
    "title": "Getting started with R",
    "section": "Homework",
    "text": "Homework\n\n\nBefore the first class period\n\nInstall R from https://r-project.org\nInstall RStudio from https://rstudio.com\nInstall tidyverse package\nComplete course introduction form\nRead the syllabus\nRead readings in syllabus schedule\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/02_rstudio.html#review-mental-model-of-r",
    "href": "slides/02_rstudio.html#review-mental-model-of-r",
    "title": "Working in RStudio",
    "section": "Review: Mental model of R",
    "text": "Review: Mental model of R"
  },
  {
    "objectID": "slides/02_rstudio.html#tour-of-rstudio",
    "href": "slides/02_rstudio.html#tour-of-rstudio",
    "title": "Working in RStudio",
    "section": "Tour of RStudio",
    "text": "Tour of RStudio"
  },
  {
    "objectID": "slides/02_rstudio.html#mental-model-of-rstudio",
    "href": "slides/02_rstudio.html#mental-model-of-rstudio",
    "title": "Working in RStudio",
    "section": "Mental model of RStudio",
    "text": "Mental model of RStudio"
  },
  {
    "objectID": "slides/02_rstudio.html#keyboard-shortcuts",
    "href": "slides/02_rstudio.html#keyboard-shortcuts",
    "title": "Working in RStudio",
    "section": "Keyboard shortcuts",
    "text": "Keyboard shortcuts\nHere are some of my favorite things!\nTools &gt; Keyboard Shortcuts Help or Alt/Opt+Shift+K\n\n\n\n\n\n\n\nFunction\nKeyboard shortcut\n\n\n\n\nRun current line\nCtrl/Cmd+Enter/Return\n\n\nSource entire script\nCtrl/Cmd+Shift+S\n\n\nInsert assignment operator\nAlt/Opt+-\n\n\nInsert pipe\nCtrl/Cmd+Shift+M\n\n\nComment lines\nCtrl/Cmd+Shift+C"
  },
  {
    "objectID": "slides/02_rstudio.html#options",
    "href": "slides/02_rstudio.html#options",
    "title": "Working in RStudio",
    "section": "Options",
    "text": "Options\n\nTurn off restore workspace\nTurn off save history\nTurn on soft wrap\nTurn on rainbow parentheses\nChange your theme"
  },
  {
    "objectID": "slides/02_rstudio.html#installing-packages",
    "href": "slides/02_rstudio.html#installing-packages",
    "title": "Working in RStudio",
    "section": "Installing packages",
    "text": "Installing packages"
  },
  {
    "objectID": "slides/02_rstudio.html#getting-help",
    "href": "slides/02_rstudio.html#getting-help",
    "title": "Working in RStudio",
    "section": "Getting help",
    "text": "Getting help\nOnline forums\n\nRStudio Community–RStudio-specific forum (e.g., tidyverse)\nStack Overflow–Coding-related questions\nCross Validated–Statistics questions (not R-specific)\n\nOnline portals/books\n\nCheatsheets\nTidyverse\nRStudio books"
  },
  {
    "objectID": "slides/02_rstudio.html#tips",
    "href": "slides/02_rstudio.html#tips",
    "title": "Working in RStudio",
    "section": "Tips",
    "text": "Tips\n\nLearn to use keyboard shortcuts\nYou can remap keyboard shortcuts (I’ve remapped Insert assignment operator to Ctrl/Cmd+Shift+,)\nRestart R often"
  },
  {
    "objectID": "slides/02_rstudio.html#lets-explore",
    "href": "slides/02_rstudio.html#lets-explore",
    "title": "Working in RStudio",
    "section": "Let’s explore!",
    "text": "Let’s explore!\nWorking in RStudio"
  },
  {
    "objectID": "slides/02_rstudio.html#mental-model-of-rstudio-1",
    "href": "slides/02_rstudio.html#mental-model-of-rstudio-1",
    "title": "Working in RStudio",
    "section": "Mental model of RStudio",
    "text": "Mental model of RStudio"
  },
  {
    "objectID": "slides/04_workflows.html#review-mental-model-of-coding",
    "href": "slides/04_workflows.html#review-mental-model-of-coding",
    "title": "Workflows",
    "section": "Review: Mental model of coding",
    "text": "Review: Mental model of coding"
  },
  {
    "objectID": "slides/04_workflows.html#mental-model-of-file-directories",
    "href": "slides/04_workflows.html#mental-model-of-file-directories",
    "title": "Workflows",
    "section": "Mental model of file directories",
    "text": "Mental model of file directories"
  },
  {
    "objectID": "slides/04_workflows.html#file-system",
    "href": "slides/04_workflows.html#file-system",
    "title": "Workflows",
    "section": "File system",
    "text": "File system\nStructure of directories and files stored on your computer\n\n\n/media/jstevens/data/jstevens/OneDrive/active_sync/teach/psyc_971--data_science_visualization_in_r/dpavir_2025/slides\n├── 00_getting_started.html\n├── 00_getting_started.qmd\n├── 01_introduction.html\n├── 01_introduction.qmd\n├── 01_introduction_files\n│   └── libs\n│       ├── clipboard\n│       │   └── clipboard.min.js\n│       ├── quarto-html\n│       │   ├── light-border.css\n│       │   ├── popper.min.js\n│       │   ├── quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css\n│       │   ├── tabby.min.js\n│       │   ├── tippy.css\n│       │   └── tippy.umd.min.js\n│       └── revealjs\n│           ├── dist\n│           │   ├── reset.css\n│           │   ├── reveal.css\n│           │   ├── reveal.esm.js\n│           │   ├── reveal.esm.js.map\n│           │   ├── reveal.js\n│           │   ├── reveal.js.map\n│           │   └── theme\n│           │       ├── fonts\n│           │       │   ├── league-gothic\n│           │       │   │   ├── LICENSE\n│           │       │   │   ├── league-gothic.css\n│           │       │   │   ├── league-gothic.eot\n│           │       │   │   ├── league-gothic.ttf\n│           │       │   │   └── league-gothic.woff\n│           │       │   └── source-sans-pro\n│           │       │       ├── LICENSE\n│           │       │       ├── source-sans-pro-italic.eot\n│           │       │       ├── source-sans-pro-italic.ttf\n│           │       │       ├── source-sans-pro-italic.woff\n│           │       │       ├── source-sans-pro-regular.eot\n│           │       │       ├── source-sans-pro-regular.ttf\n│           │       │       ├── source-sans-pro-regular.woff\n│           │       │       ├── source-sans-pro-semibold.eot\n│           │       │       ├── source-sans-pro-semibold.ttf\n│           │       │       ├── source-sans-pro-semibold.woff\n│           │       │       ├── source-sans-pro-semibolditalic.eot\n│           │       │       ├── source-sans-pro-semibolditalic.ttf\n│           │       │       ├── source-sans-pro-semibolditalic.woff\n│           │       │       └── source-sans-pro.css\n│           │       └── quarto-a2f7aa52291835777371ae19798055b6.css\n│           └── plugin\n│               ├── highlight\n│               │   ├── highlight.esm.js\n│               │   ├── highlight.js\n│               │   ├── monokai.css\n│               │   ├── plugin.js\n│               │   └── zenburn.css\n│               ├── markdown\n│               │   ├── markdown.esm.js\n│               │   ├── markdown.js\n│               │   └── plugin.js\n│               ├── math\n│               │   ├── katex.js\n│               │   ├── math.esm.js\n│               │   ├── math.js\n│               │   ├── mathjax2.js\n│               │   ├── mathjax3.js\n│               │   └── plugin.js\n│               ├── notes\n│               │   ├── notes.esm.js\n│               │   ├── notes.js\n│               │   ├── plugin.js\n│               │   └── speaker-view.html\n│               ├── pdf-export\n│               │   ├── pdfexport.js\n│               │   └── plugin.yml\n│               ├── quarto-line-highlight\n│               │   ├── line-highlight.css\n│               │   ├── line-highlight.js\n│               │   └── plugin.yml\n│               ├── quarto-support\n│               │   ├── footer.css\n│               │   ├── plugin.yml\n│               │   └── support.js\n│               ├── reveal-menu\n│               │   ├── menu.css\n│               │   ├── menu.js\n│               │   ├── quarto-menu.css\n│               │   └── quarto-menu.js\n│               ├── search\n│               │   ├── plugin.js\n│               │   ├── search.esm.js\n│               │   └── search.js\n│               └── zoom\n│                   ├── plugin.js\n│                   ├── zoom.esm.js\n│                   └── zoom.js\n├── 02_rstudio.html\n├── 02_rstudio.qmd\n├── 03_coding.html\n├── 03_coding.qmd\n├── 03_coding_files\n│   └── libs\n│       ├── clipboard\n│       │   └── clipboard.min.js\n│       ├── quarto-html\n│       │   ├── light-border.css\n│       │   ├── popper.min.js\n│       │   ├── quarto-syntax-highlighting-dark-e25cc82807363e79c52e96bc8b7855f1.css\n│       │   ├── tabby.min.js\n│       │   ├── tippy.css\n│       │   └── tippy.umd.min.js\n│       └── revealjs\n│           ├── dist\n│           │   ├── reset.css\n│           │   ├── reveal.css\n│           │   ├── reveal.esm.js\n│           │   ├── reveal.esm.js.map\n│           │   ├── reveal.js\n│           │   ├── reveal.js.map\n│           │   └── theme\n│           │       ├── fonts\n│           │       │   ├── league-gothic\n│           │       │   │   ├── LICENSE\n│           │       │   │   ├── league-gothic.css\n│           │       │   │   ├── league-gothic.eot\n│           │       │   │   ├── league-gothic.ttf\n│           │       │   │   └── league-gothic.woff\n│           │       │   └── source-sans-pro\n│           │       │       ├── LICENSE\n│           │       │       ├── source-sans-pro-italic.eot\n│           │       │       ├── source-sans-pro-italic.ttf\n│           │       │       ├── source-sans-pro-italic.woff\n│           │       │       ├── source-sans-pro-regular.eot\n│           │       │       ├── source-sans-pro-regular.ttf\n│           │       │       ├── source-sans-pro-regular.woff\n│           │       │       ├── source-sans-pro-semibold.eot\n│           │       │       ├── source-sans-pro-semibold.ttf\n│           │       │       ├── source-sans-pro-semibold.woff\n│           │       │       ├── source-sans-pro-semibolditalic.eot\n│           │       │       ├── source-sans-pro-semibolditalic.ttf\n│           │       │       ├── source-sans-pro-semibolditalic.woff\n│           │       │       └── source-sans-pro.css\n│           │       └── quarto-a72b68f23337d6c747b4277c226ad139.css\n│           └── plugin\n│               ├── highlight\n│               │   ├── highlight.esm.js\n│               │   ├── highlight.js\n│               │   ├── monokai.css\n│               │   ├── plugin.js\n│               │   └── zenburn.css\n│               ├── markdown\n│               │   ├── markdown.esm.js\n│               │   ├── markdown.js\n│               │   └── plugin.js\n│               ├── math\n│               │   ├── katex.js\n│               │   ├── math.esm.js\n│               │   ├── math.js\n│               │   ├── mathjax2.js\n│               │   ├── mathjax3.js\n│               │   └── plugin.js\n│               ├── notes\n│               │   ├── notes.esm.js\n│               │   ├── notes.js\n│               │   ├── plugin.js\n│               │   └── speaker-view.html\n│               ├── pdf-export\n│               │   ├── pdfexport.js\n│               │   └── plugin.yml\n│               ├── quarto-line-highlight\n│               │   ├── line-highlight.css\n│               │   ├── line-highlight.js\n│               │   └── plugin.yml\n│               ├── quarto-support\n│               │   ├── footer.css\n│               │   ├── plugin.yml\n│               │   └── support.js\n│               ├── reveal-menu\n│               │   ├── menu.css\n│               │   ├── menu.js\n│               │   ├── plugin.yml\n│               │   ├── quarto-menu.css\n│               │   └── quarto-menu.js\n│               ├── search\n│               │   ├── plugin.js\n│               │   ├── search.esm.js\n│               │   └── search.js\n│               └── zoom\n│                   ├── plugin.js\n│                   ├── zoom.esm.js\n│                   └── zoom.js\n├── 04_workflows.qmd\n├── 04_workflows.rmarkdown\n├── 05_rmarkdown.qmd\n├── 05_rmarkdown_files\n│   ├── figure-revealjs\n│   │   ├── unnamed-chunk-1-1.png\n│   │   ├── unnamed-chunk-2-1.png\n│   │   └── unnamed-chunk-3-1.png\n│   └── libs\n│       ├── clipboard\n│       │   └── clipboard.min.js\n│       ├── quarto-html\n│       │   ├── popper.min.js\n│       │   ├── quarto-html.min.css\n│       │   ├── quarto-syntax-highlighting-dark.css\n│       │   ├── tabby.min.js\n│       │   ├── tippy.css\n│       │   └── tippy.umd.min.js\n│       └── revealjs\n│           ├── dist\n│           │   ├── reset.css\n│           │   ├── reveal.css\n│           │   ├── reveal.esm.js\n│           │   ├── reveal.esm.js.map\n│           │   ├── reveal.js\n│           │   ├── reveal.js.map\n│           │   └── theme\n│           │       ├── fonts\n│           │       │   ├── league-gothic\n│           │       │   │   ├── LICENSE\n│           │       │   │   ├── league-gothic.css\n│           │       │   │   ├── league-gothic.eot\n│           │       │   │   ├── league-gothic.ttf\n│           │       │   │   └── league-gothic.woff\n│           │       │   └── source-sans-pro\n│           │       │       ├── LICENSE\n│           │       │       ├── source-sans-pro-italic.eot\n│           │       │       ├── source-sans-pro-italic.ttf\n│           │       │       ├── source-sans-pro-italic.woff\n│           │       │       ├── source-sans-pro-regular.eot\n│           │       │       ├── source-sans-pro-regular.ttf\n│           │       │       ├── source-sans-pro-regular.woff\n│           │       │       ├── source-sans-pro-semibold.eot\n│           │       │       ├── source-sans-pro-semibold.ttf\n│           │       │       ├── source-sans-pro-semibold.woff\n│           │       │       ├── source-sans-pro-semibolditalic.eot\n│           │       │       ├── source-sans-pro-semibolditalic.ttf\n│           │       │       ├── source-sans-pro-semibolditalic.woff\n│           │       │       └── source-sans-pro.css\n│           │       └── quarto.css\n│           └── plugin\n│               ├── highlight\n│               │   ├── highlight.esm.js\n│               │   ├── highlight.js\n│               │   ├── monokai.css\n│               │   ├── plugin.js\n│               │   └── zenburn.css\n│               ├── markdown\n│               │   ├── markdown.esm.js\n│               │   ├── markdown.js\n│               │   └── plugin.js\n│               ├── math\n│               │   ├── katex.js\n│               │   ├── math.esm.js\n│               │   ├── math.js\n│               │   ├── mathjax2.js\n│               │   ├── mathjax3.js\n│               │   └── plugin.js\n│               ├── notes\n│               │   ├── notes.esm.js\n│               │   ├── notes.js\n│               │   ├── plugin.js\n│               │   └── speaker-view.html\n│               ├── pdf-export\n│               │   ├── pdfexport.js\n│               │   └── plugin.yml\n│               ├── quarto-line-highlight\n│               │   ├── line-highlight.css\n│               │   ├── line-highlight.js\n│               │   └── plugin.yml\n│               ├── quarto-support\n│               │   ├── footer.css\n│               │   ├── plugin.yml\n│               │   └── support.js\n│               ├── reveal-menu\n│               │   ├── menu.css\n│               │   ├── menu.js\n│               │   ├── plugin.yml\n│               │   ├── quarto-menu.css\n│               │   └── quarto-menu.js\n│               ├── search\n│               │   ├── plugin.js\n│               │   ├── search.esm.js\n│               │   └── search.js\n│               └── zoom\n│                   ├── plugin.js\n│                   ├── zoom.esm.js\n│                   └── zoom.js\n├── 06_datatypes.qmd\n├── 07_datastructures.qmd\n├── 08_importing.qmd\n├── 09_validating.qmd\n├── 10_selecting.qmd\n├── 11_mutating.html\n├── 11_mutating.qmd\n├── 11_mutating_files\n│   └── libs\n│       ├── clipboard\n│       │   └── clipboard.min.js\n│       ├── quarto-html\n│       │   ├── light-border.css\n│       │   ├── popper.min.js\n│       │   ├── quarto-syntax-highlighting-dark-e25cc82807363e79c52e96bc8b7855f1.css\n│       │   ├── tabby.min.js\n│       │   ├── tippy.css\n│       │   └── tippy.umd.min.js\n│       └── revealjs\n│           ├── dist\n│           │   ├── reset.css\n│           │   ├── reveal.css\n│           │   ├── reveal.esm.js\n│           │   ├── reveal.esm.js.map\n│           │   ├── reveal.js\n│           │   ├── reveal.js.map\n│           │   └── theme\n│           │       ├── fonts\n│           │       │   ├── league-gothic\n│           │       │   │   ├── LICENSE\n│           │       │   │   ├── league-gothic.css\n│           │       │   │   ├── league-gothic.eot\n│           │       │   │   ├── league-gothic.ttf\n│           │       │   │   └── league-gothic.woff\n│           │       │   └── source-sans-pro\n│           │       │       ├── LICENSE\n│           │       │       ├── source-sans-pro-italic.eot\n│           │       │       ├── source-sans-pro-italic.ttf\n│           │       │       ├── source-sans-pro-italic.woff\n│           │       │       ├── source-sans-pro-regular.eot\n│           │       │       ├── source-sans-pro-regular.ttf\n│           │       │       ├── source-sans-pro-regular.woff\n│           │       │       ├── source-sans-pro-semibold.eot\n│           │       │       ├── source-sans-pro-semibold.ttf\n│           │       │       ├── source-sans-pro-semibold.woff\n│           │       │       ├── source-sans-pro-semibolditalic.eot\n│           │       │       ├── source-sans-pro-semibolditalic.ttf\n│           │       │       ├── source-sans-pro-semibolditalic.woff\n│           │       │       └── source-sans-pro.css\n│           │       └── quarto-a72b68f23337d6c747b4277c226ad139.css\n│           └── plugin\n│               ├── highlight\n│               │   ├── highlight.esm.js\n│               │   ├── highlight.js\n│               │   ├── monokai.css\n│               │   ├── plugin.js\n│               │   └── zenburn.css\n│               ├── markdown\n│               │   ├── markdown.esm.js\n│               │   ├── markdown.js\n│               │   └── plugin.js\n│               ├── math\n│               │   ├── katex.js\n│               │   ├── math.esm.js\n│               │   ├── math.js\n│               │   ├── mathjax2.js\n│               │   ├── mathjax3.js\n│               │   └── plugin.js\n│               ├── notes\n│               │   ├── notes.esm.js\n│               │   ├── notes.js\n│               │   ├── plugin.js\n│               │   └── speaker-view.html\n│               ├── pdf-export\n│               │   ├── pdfexport.js\n│               │   └── plugin.yml\n│               ├── quarto-line-highlight\n│               │   ├── line-highlight.css\n│               │   ├── line-highlight.js\n│               │   └── plugin.yml\n│               ├── quarto-support\n│               │   ├── footer.css\n│               │   ├── plugin.yml\n│               │   └── support.js\n│               ├── reveal-menu\n│               │   ├── menu.css\n│               │   ├── menu.js\n│               │   ├── plugin.yml\n│               │   ├── quarto-menu.css\n│               │   └── quarto-menu.js\n│               ├── search\n│               │   ├── plugin.js\n│               │   ├── search.esm.js\n│               │   └── search.js\n│               └── zoom\n│                   ├── plugin.js\n│                   ├── zoom.esm.js\n│                   └── zoom.js\n├── 12_piping.qmd\n├── 13_filtering.qmd\n├── 14_summarizing.qmd\n├── 15_pivoting.qmd\n├── 16_separating.qmd\n├── 17_mergingcolumns.qmd\n├── 18_mergingrows.qmd\n├── 19_numbers.qmd\n├── 20_strings.qmd\n├── 21_patterns.qmd\n├── 22_factors.qmd\n├── 23_dates.qmd\n├── 24_functions.qmd\n├── 25_iteration.qmd\n├── 26_grammar1.qmd\n├── 27_grammar2.qmd\n├── 28_themes.R\n├── 28_themes.qmd\n├── 29_color.qmd\n├── 29_color_files\n│   ├── figure-html\n│   │   ├── unnamed-chunk-1-1.png\n│   │   └── unnamed-chunk-2-1.png\n│   └── libs\n│       ├── clipboard\n│       │   └── clipboard.min.js\n│       ├── quarto-html\n│       │   ├── popper.min.js\n│       │   ├── quarto-html.min.css\n│       │   ├── quarto-syntax-highlighting-dark.css\n│       │   ├── tabby.min.js\n│       │   ├── tippy.css\n│       │   └── tippy.umd.min.js\n│       └── revealjs\n│           ├── dist\n│           │   ├── reset.css\n│           │   ├── reveal.css\n│           │   ├── reveal.esm.js\n│           │   ├── reveal.esm.js.map\n│           │   ├── reveal.js\n│           │   ├── reveal.js.map\n│           │   └── theme\n│           │       ├── fonts\n│           │       │   ├── league-gothic\n│           │       │   │   ├── LICENSE\n│           │       │   │   ├── league-gothic.css\n│           │       │   │   ├── league-gothic.eot\n│           │       │   │   ├── league-gothic.ttf\n│           │       │   │   └── league-gothic.woff\n│           │       │   └── source-sans-pro\n│           │       │       ├── LICENSE\n│           │       │       ├── source-sans-pro-italic.eot\n│           │       │       ├── source-sans-pro-italic.ttf\n│           │       │       ├── source-sans-pro-italic.woff\n│           │       │       ├── source-sans-pro-regular.eot\n│           │       │       ├── source-sans-pro-regular.ttf\n│           │       │       ├── source-sans-pro-regular.woff\n│           │       │       ├── source-sans-pro-semibold.eot\n│           │       │       ├── source-sans-pro-semibold.ttf\n│           │       │       ├── source-sans-pro-semibold.woff\n│           │       │       ├── source-sans-pro-semibolditalic.eot\n│           │       │       ├── source-sans-pro-semibolditalic.ttf\n│           │       │       ├── source-sans-pro-semibolditalic.woff\n│           │       │       └── source-sans-pro.css\n│           │       └── quarto.css\n│           └── plugin\n│               ├── highlight\n│               │   ├── highlight.esm.js\n│               │   ├── highlight.js\n│               │   ├── monokai.css\n│               │   ├── plugin.js\n│               │   └── zenburn.css\n│               ├── markdown\n│               │   ├── markdown.esm.js\n│               │   ├── markdown.js\n│               │   └── plugin.js\n│               ├── math\n│               │   ├── katex.js\n│               │   ├── math.esm.js\n│               │   ├── math.js\n│               │   ├── mathjax2.js\n│               │   ├── mathjax3.js\n│               │   └── plugin.js\n│               ├── notes\n│               │   ├── notes.esm.js\n│               │   ├── notes.js\n│               │   ├── plugin.js\n│               │   └── speaker-view.html\n│               ├── pdf-export\n│               │   ├── pdfexport.js\n│               │   └── plugin.yml\n│               ├── quarto-line-highlight\n│               │   ├── line-highlight.css\n│               │   ├── line-highlight.js\n│               │   └── plugin.yml\n│               ├── quarto-support\n│               │   ├── footer.css\n│               │   ├── plugin.yml\n│               │   └── support.js\n│               ├── reveal-menu\n│               │   ├── menu.css\n│               │   ├── menu.js\n│               │   ├── plugin.yml\n│               │   ├── quarto-menu.css\n│               │   └── quarto-menu.js\n│               ├── search\n│               │   ├── plugin.js\n│               │   ├── search.esm.js\n│               │   └── search.js\n│               └── zoom\n│                   ├── plugin.js\n│                   ├── zoom.esm.js\n│                   └── zoom.js\n├── 30_histograms.R\n├── 30_histograms_answers.R\n├── 31_boxplots.R\n├── 31_boxplots_answers.R\n├── 32_barcharts.R\n├── 32_barcharts_answers.R\n├── 33_associations.R\n├── 33_associations_answers.R\n├── 34_timeseries.R\n├── 34_timeseries_answers.R\n├── 35_categories.R\n├── 35_categories_answers.R\n├── 36_axes.R\n├── 36_axes_answers.R\n├── 37_annotating.R\n├── 37_annotating_answers.R\n├── 39_tables.Rmd\n├── 39_tables.pdf\n├── 39_tables.tex\n├── 40_publications.qmd\n├── 41_advrmarkdown.qmd\n├── 42_quarto.qmd\n├── 43_statistics.R\n├── _freeze\n│   ├── 00_getting_started\n│   │   └── libs\n│   │       ├── clipboard\n│   │       │   └── clipboard.min.js\n│   │       ├── quarto-html\n│   │       │   ├── light-border.css\n│   │       │   ├── popper.min.js\n│   │       │   ├── quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css\n│   │       │   ├── tabby.min.js\n│   │       │   ├── tippy.css\n│   │       │   └── tippy.umd.min.js\n│   │       └── revealjs\n│   │           ├── dist\n│   │           │   ├── reset.css\n│   │           │   ├── reveal.css\n│   │           │   ├── reveal.esm.js\n│   │           │   ├── reveal.esm.js.map\n│   │           │   ├── reveal.js\n│   │           │   ├── reveal.js.map\n│   │           │   └── theme\n│   │           │       ├── fonts\n│   │           │       │   ├── league-gothic\n│   │           │       │   │   ├── LICENSE\n│   │           │       │   │   ├── league-gothic.css\n│   │           │       │   │   ├── league-gothic.eot\n│   │           │       │   │   ├── league-gothic.ttf\n│   │           │       │   │   └── league-gothic.woff\n│   │           │       │   └── source-sans-pro\n│   │           │       │       ├── LICENSE\n│   │           │       │       ├── source-sans-pro-italic.eot\n│   │           │       │       ├── source-sans-pro-italic.ttf\n│   │           │       │       ├── source-sans-pro-italic.woff\n│   │           │       │       ├── source-sans-pro-regular.eot\n│   │           │       │       ├── source-sans-pro-regular.ttf\n│   │           │       │       ├── source-sans-pro-regular.woff\n│   │           │       │       ├── source-sans-pro-semibold.eot\n│   │           │       │       ├── source-sans-pro-semibold.ttf\n│   │           │       │       ├── source-sans-pro-semibold.woff\n│   │           │       │       ├── source-sans-pro-semibolditalic.eot\n│   │           │       │       ├── source-sans-pro-semibolditalic.ttf\n│   │           │       │       ├── source-sans-pro-semibolditalic.woff\n│   │           │       │       └── source-sans-pro.css\n│   │           │       └── quarto-a2f7aa52291835777371ae19798055b6.css\n│   │           └── plugin\n│   │               ├── highlight\n│   │               │   ├── highlight.esm.js\n│   │               │   ├── highlight.js\n│   │               │   ├── monokai.css\n│   │               │   ├── plugin.js\n│   │               │   └── zenburn.css\n│   │               ├── markdown\n│   │               │   ├── markdown.esm.js\n│   │               │   ├── markdown.js\n│   │               │   └── plugin.js\n│   │               ├── math\n│   │               │   ├── katex.js\n│   │               │   ├── math.esm.js\n│   │               │   ├── math.js\n│   │               │   ├── mathjax2.js\n│   │               │   ├── mathjax3.js\n│   │               │   └── plugin.js\n│   │               ├── notes\n│   │               │   ├── notes.esm.js\n│   │               │   ├── notes.js\n│   │               │   ├── plugin.js\n│   │               │   └── speaker-view.html\n│   │               ├── pdf-export\n│   │               │   ├── pdfexport.js\n│   │               │   └── plugin.yml\n│   │               ├── quarto-line-highlight\n│   │               │   ├── line-highlight.css\n│   │               │   ├── line-highlight.js\n│   │               │   └── plugin.yml\n│   │               ├── quarto-support\n│   │               │   ├── footer.css\n│   │               │   ├── plugin.yml\n│   │               │   └── support.js\n│   │               ├── reveal-menu\n│   │               │   ├── menu.css\n│   │               │   ├── menu.js\n│   │               │   ├── plugin.yml\n│   │               │   ├── quarto-menu.css\n│   │               │   └── quarto-menu.js\n│   │               ├── search\n│   │               │   ├── plugin.js\n│   │               │   ├── search.esm.js\n│   │               │   └── search.js\n│   │               └── zoom\n│   │                   ├── plugin.js\n│   │                   ├── zoom.esm.js\n│   │                   └── zoom.js\n│   ├── 04_workflows\n│   │   ├── execute-results\n│   │   │   └── html.json\n│   │   └── libs\n│   │       ├── clipboard\n│   │       │   └── clipboard.min.js\n│   │       ├── quarto-html\n│   │       │   ├── light-border.css\n│   │       │   ├── popper.min.js\n│   │       │   ├── quarto-html.min.css\n│   │       │   ├── quarto-syntax-highlighting-dark.css\n│   │       │   ├── tabby.min.js\n│   │       │   ├── tippy.css\n│   │       │   └── tippy.umd.min.js\n│   │       └── revealjs\n│   │           ├── dist\n│   │           │   ├── reset.css\n│   │           │   ├── reveal.css\n│   │           │   ├── reveal.esm.js\n│   │           │   ├── reveal.esm.js.map\n│   │           │   ├── reveal.js\n│   │           │   ├── reveal.js.map\n│   │           │   └── theme\n│   │           │       ├── fonts\n│   │           │       │   ├── league-gothic\n│   │           │       │   │   ├── LICENSE\n│   │           │       │   │   ├── league-gothic.css\n│   │           │       │   │   ├── league-gothic.eot\n│   │           │       │   │   ├── league-gothic.ttf\n│   │           │       │   │   └── league-gothic.woff\n│   │           │       │   └── source-sans-pro\n│   │           │       │       ├── LICENSE\n│   │           │       │       ├── source-sans-pro-italic.eot\n│   │           │       │       ├── source-sans-pro-italic.ttf\n│   │           │       │       ├── source-sans-pro-italic.woff\n│   │           │       │       ├── source-sans-pro-regular.eot\n│   │           │       │       ├── source-sans-pro-regular.ttf\n│   │           │       │       ├── source-sans-pro-regular.woff\n│   │           │       │       ├── source-sans-pro-semibold.eot\n│   │           │       │       ├── source-sans-pro-semibold.ttf\n│   │           │       │       ├── source-sans-pro-semibold.woff\n│   │           │       │       ├── source-sans-pro-semibolditalic.eot\n│   │           │       │       ├── source-sans-pro-semibolditalic.ttf\n│   │           │       │       ├── source-sans-pro-semibolditalic.woff\n│   │           │       │       └── source-sans-pro.css\n│   │           │       └── quarto.css\n│   │           └── plugin\n│   │               ├── highlight\n│   │               │   ├── highlight.esm.js\n│   │               │   ├── highlight.js\n│   │               │   ├── monokai.css\n│   │               │   ├── plugin.js\n│   │               │   └── zenburn.css\n│   │               ├── markdown\n│   │               │   ├── markdown.esm.js\n│   │               │   ├── markdown.js\n│   │               │   └── plugin.js\n│   │               ├── math\n│   │               │   ├── katex.js\n│   │               │   ├── math.esm.js\n│   │               │   ├── math.js\n│   │               │   ├── mathjax2.js\n│   │               │   ├── mathjax3.js\n│   │               │   └── plugin.js\n│   │               ├── notes\n│   │               │   ├── notes.esm.js\n│   │               │   ├── notes.js\n│   │               │   ├── plugin.js\n│   │               │   └── speaker-view.html\n│   │               ├── pdf-export\n│   │               │   ├── pdfexport.js\n│   │               │   └── plugin.yml\n│   │               ├── quarto-line-highlight\n│   │               │   ├── line-highlight.css\n│   │               │   ├── line-highlight.js\n│   │               │   └── plugin.yml\n│   │               ├── quarto-support\n│   │               │   ├── footer.css\n│   │               │   ├── plugin.yml\n│   │               │   └── support.js\n│   │               ├── reveal-menu\n│   │               │   ├── menu.css\n│   │               │   ├── menu.js\n│   │               │   ├── plugin.yml\n│   │               │   ├── quarto-menu.css\n│   │               │   └── quarto-menu.js\n│   │               ├── search\n│   │               │   ├── plugin.js\n│   │               │   ├── search.esm.js\n│   │               │   └── search.js\n│   │               └── zoom\n│   │                   ├── plugin.js\n│   │                   ├── zoom.esm.js\n│   │                   └── zoom.js\n│   └── 11_mutating\n│       └── execute-results\n│           └── html.json\n├── _quarto.yml\n└── custom.scss"
  },
  {
    "objectID": "slides/04_workflows.html#file-managers",
    "href": "slides/04_workflows.html#file-managers",
    "title": "Workflows",
    "section": "File managers",
    "text": "File managers\n\nApps/GUIs to interact with file system\n\nWindows File Explorer\nMacOS Finder"
  },
  {
    "objectID": "slides/04_workflows.html#file-managers-1",
    "href": "slides/04_workflows.html#file-managers-1",
    "title": "Workflows",
    "section": "File managers",
    "text": "File managers\n\nRStudio"
  },
  {
    "objectID": "slides/04_workflows.html#terminals",
    "href": "slides/04_workflows.html#terminals",
    "title": "Workflows",
    "section": "Terminals",
    "text": "Terminals\n\nInteract with file system through prompt/command line\nIf not familiar with terminal, read primer for Windows or MacOS"
  },
  {
    "objectID": "slides/04_workflows.html#mental-model-of-file-directories-1",
    "href": "slides/04_workflows.html#mental-model-of-file-directories-1",
    "title": "Workflows",
    "section": "Mental model of file directories",
    "text": "Mental model of file directories"
  },
  {
    "objectID": "slides/04_workflows.html#paths-1",
    "href": "slides/04_workflows.html#paths-1",
    "title": "Workflows",
    "section": "Paths",
    "text": "Paths\nConvert tree structure to character string\n\n\n\nexercises/01_introduction/rsconnect/documents/01_introduction.Rmd/shinapps.io/jeffreyrstevens/01_introduction.dcf"
  },
  {
    "objectID": "slides/04_workflows.html#absolute-paths",
    "href": "slides/04_workflows.html#absolute-paths",
    "title": "Workflows",
    "section": "Absolute paths",
    "text": "Absolute paths\nFrom root directory\n\n\nStarts with drive letter or /\n\nWindows: C:\\users\\jeff\\Documents\\projects\\dpavir_2023\\R\\\nLinux and MacOS: /home/jeff/projects/dpavir_2023/R/"
  },
  {
    "objectID": "slides/04_workflows.html#relative-paths",
    "href": "slides/04_workflows.html#relative-paths",
    "title": "Workflows",
    "section": "Relative paths",
    "text": "Relative paths\nFrom current directory\n\n\nStarts with first subdirectory name\n\nIf in projects/, relative path to R/ is dpavir_2023/R\n\n\n\n\n\n\nUse relative paths!\nWhy?"
  },
  {
    "objectID": "slides/04_workflows.html#changing-directories",
    "href": "slides/04_workflows.html#changing-directories",
    "title": "Workflows",
    "section": "Changing directories",
    "text": "Changing directories\nChange directories with cd\n\n\n/home/jeff/projects/dpavir_2023/\n\n\n\nTo move from dpavir_2023/ to rsconnect/, type cd exercises/01_introduction/rsconnect/"
  },
  {
    "objectID": "slides/04_workflows.html#go-backwards",
    "href": "slides/04_workflows.html#go-backwards",
    "title": "Workflows",
    "section": "Go backwards",
    "text": "Go backwards\nMove backwards with cd ..\n\n\n\nOne set of .. for each directory going backwards\nTo move from rsconnect/ to 01_introduction/,  type cd ..\nTo move from 01_introduction/ to code/,  type cd ../../code/"
  },
  {
    "objectID": "slides/04_workflows.html#lets-try-it",
    "href": "slides/04_workflows.html#lets-try-it",
    "title": "Workflows",
    "section": "Let’s try it!",
    "text": "Let’s try it!\n\n\nGo to Files in RStudio\nAdd folder named test and a subfolder named R.\nGo to Terminal.\nType ls or dir.\nHow do we go to test/?\nHow do we go back?\nHow do we go to test/R/?\nHow do we go back up to test/?"
  },
  {
    "objectID": "slides/04_workflows.html#mental-model-of-file-directories-2",
    "href": "slides/04_workflows.html#mental-model-of-file-directories-2",
    "title": "Workflows",
    "section": "Mental model of file directories",
    "text": "Mental model of file directories"
  },
  {
    "objectID": "slides/04_workflows.html#project-directory-structure",
    "href": "slides/04_workflows.html#project-directory-structure",
    "title": "Workflows",
    "section": "Project directory structure",
    "text": "Project directory structure\n\n\n\n\n\n\n\n\n\nBuild a consistent directory structure\nWhy?\nConsistency for you\nAdapt structure to your needs or lab requirements\nConsistency for the lab\nMake a template directory"
  },
  {
    "objectID": "slides/04_workflows.html#working-directories",
    "href": "slides/04_workflows.html#working-directories",
    "title": "Workflows",
    "section": "Working directories",
    "text": "Working directories\nBase directory for R session\n\n\n\nView your working directory\n\nConsole: getwd()\n\nRStudio: top of Console\n\n\n\n\n\n\nWhat is your working directory?"
  },
  {
    "objectID": "slides/04_workflows.html#rstudio-projects",
    "href": "slides/04_workflows.html#rstudio-projects",
    "title": "Workflows",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nConvenient system to:\n\nSet working directory\nOpen files you had open before closing RStudio\nFocus on relative paths\nEnable version control\n\nUse them! Always!"
  },
  {
    "objectID": "slides/04_workflows.html#rstudio-projects-1",
    "href": "slides/04_workflows.html#rstudio-projects-1",
    "title": "Workflows",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nLet’s create an RStudio Project for this course"
  },
  {
    "objectID": "slides/04_workflows.html#rstudio-projects-2",
    "href": "slides/04_workflows.html#rstudio-projects-2",
    "title": "Workflows",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nCreate an RStudio Project in the existing test/ directory\n\n\n\nCreate your typical project structure\nUse the terminal to change directories in your project"
  },
  {
    "objectID": "slides/04_workflows.html#project-working-directories",
    "href": "slides/04_workflows.html#project-working-directories",
    "title": "Workflows",
    "section": "Project working directories",
    "text": "Project working directories\n{here}: The package that sets your working directory to the RStudio Project root directory\n\nread_csv(here(\"data/a.csv\"))\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/04_workflows.html#mental-model-of-file-directories-3",
    "href": "slides/04_workflows.html#mental-model-of-file-directories-3",
    "title": "Workflows",
    "section": "Mental model of file directories",
    "text": "Mental model of file directories"
  },
  {
    "objectID": "slides/06_datatypes.html#mental-model-of-literate-programming",
    "href": "slides/06_datatypes.html#mental-model-of-literate-programming",
    "title": "Data types",
    "section": "Mental model of literate programming",
    "text": "Mental model of literate programming"
  },
  {
    "objectID": "slides/06_datatypes.html#data-types-1",
    "href": "slides/06_datatypes.html#data-types-1",
    "title": "Data types",
    "section": "Data types",
    "text": "Data types\nFormats of individual elements\n\nDouble\nInteger\nCharacter\nLogical\n\nCheck data types with typeof()"
  },
  {
    "objectID": "slides/06_datatypes.html#mental-model-of-data-types",
    "href": "slides/06_datatypes.html#mental-model-of-data-types",
    "title": "Data types",
    "section": "Mental model of data types",
    "text": "Mental model of data types"
  },
  {
    "objectID": "slides/06_datatypes.html#numeric-data",
    "href": "slides/06_datatypes.html#numeric-data",
    "title": "Data types",
    "section": "Numeric data",
    "text": "Numeric data\nDoubles\nFloating-point numbers with decimals\n\n# assign value 7.2 to object a\n(a &lt;- 7.2) # remember, wrapping in parentheses prints to console\n\n[1] 7.2\n\n\n\n\ntypeof(a)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/06_datatypes.html#numeric-data-1",
    "href": "slides/06_datatypes.html#numeric-data-1",
    "title": "Data types",
    "section": "Numeric data",
    "text": "Numeric data\nIntegers\nNumbers without decimals\n\n(b &lt;- 7)\n\n[1] 7\n\n\n\n\ntypeof(b)\n\n[1] \"double\"\n\n\n\n\n\n\n\n\nDoubles can have 0 as decimal"
  },
  {
    "objectID": "slides/06_datatypes.html#numeric-data-2",
    "href": "slides/06_datatypes.html#numeric-data-2",
    "title": "Data types",
    "section": "Numeric data",
    "text": "Numeric data\nIntegers\nNumbers without decimals (specified with L)\n\n(c &lt;- 7L)\n\n[1] 7\n\n\n\n\ntypeof(c)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/06_datatypes.html#character-data",
    "href": "slides/06_datatypes.html#character-data",
    "title": "Data types",
    "section": "Character data",
    "text": "Character data\nMust be surrounded by \"\"\n\n\n\n(d &lt;- \"Hello, world\")\n\n[1] \"Hello, world\"\n\n(e &lt;- \"7\")\n\n[1] \"7\"\n\n\n\n\n\ntypeof(e)\n\n[1] \"character\""
  },
  {
    "objectID": "slides/06_datatypes.html#lets-explore",
    "href": "slides/06_datatypes.html#lets-explore",
    "title": "Data types",
    "section": "Let’s explore!",
    "text": "Let’s explore!\n\n\nType b, c, and e into the console separately. What do you see?\nAdd b + c.\nAdd b + e."
  },
  {
    "objectID": "slides/06_datatypes.html#logical",
    "href": "slides/06_datatypes.html#logical",
    "title": "Data types",
    "section": "Logical",
    "text": "Logical\nTests whether conditional statement is TRUE or FALSE (notice always all upper case)\nLogical operators: &gt;, &gt;=, &lt;, &lt;=, ==, !=, %in%\n\n\n\na\n\n[1] 7.2\n\na &gt; 5\n\n[1] TRUE\n\n\n\n\n\nd\n\n[1] \"Hello, world\"\n\n(mytest &lt;- d == \"Good-bye, world\")\n\n[1] FALSE\n\n\n\n\n\ntypeof(mytest)\n\n[1] \"logical\""
  },
  {
    "objectID": "slides/06_datatypes.html#logical-1",
    "href": "slides/06_datatypes.html#logical-1",
    "title": "Data types",
    "section": "Logical",
    "text": "Logical\nThe logical operator for equals is ==\n\n\n\n\n\n\n\nNote\n\n\nWe use\n\n\n== for logical equals\n\n&lt;- for assigning objects\n\n= for assigning function argument values to argument names"
  },
  {
    "objectID": "slides/06_datatypes.html#logical-2",
    "href": "slides/06_datatypes.html#logical-2",
    "title": "Data types",
    "section": "Logical",
    "text": "Logical\n\n%in% operator: “is contained in”\n\n\n(subjects &lt;- c(\"01\", \"02\", \"03\", \"04\", \"05\"))\n\n[1] \"01\" \"02\" \"03\" \"04\" \"05\"\n\n\n\n\n\n\"03\" %in% subjects\n\n[1] TRUE\n\n\n\n\n\n\"06\" %in% subjects\n\n[1] FALSE\n\n\n\n\nTest “is NOT contained in” with ! before test string\n\n!\"06\" %in% subjects\n\n[1] TRUE"
  },
  {
    "objectID": "slides/06_datatypes.html#augmented-data-types",
    "href": "slides/06_datatypes.html#augmented-data-types",
    "title": "Data types",
    "section": "Augmented data types",
    "text": "Augmented data types\nCore data types with special attributes\n\nFactors\nDates"
  },
  {
    "objectID": "slides/06_datatypes.html#factors",
    "href": "slides/06_datatypes.html#factors",
    "title": "Data types",
    "section": "Factors",
    "text": "Factors\nAugmented integers with ‘levels’\n\n\n(i &lt;- factor(\"married\", levels = c(\"single\", \"married\", \"widowed\")))\n\n[1] married\nLevels: single married widowed\n\n\n\n\n\ntypeof(i)\n\n[1] \"integer\"\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nUse class() to view augmented data type\n\nclass(i)\n\n[1] \"factor\""
  },
  {
    "objectID": "slides/06_datatypes.html#dates",
    "href": "slides/06_datatypes.html#dates",
    "title": "Data types",
    "section": "Dates",
    "text": "Dates\nAugmented numerics based on number of days since 1970-01-01\n\n\n(j &lt;- as.Date(\"1970-01-01\"))\n\n[1] \"1970-01-01\"\n\ntypeof(j)\n\n[1] \"double\"\n\nclass(j)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nNote\n\n\nMake sure to wrap dates in \"\""
  },
  {
    "objectID": "slides/06_datatypes.html#dates-1",
    "href": "slides/06_datatypes.html#dates-1",
    "title": "Data types",
    "section": "Dates",
    "text": "Dates\nYou can do math on dates\n\n\n(k &lt;- as.Date(\"2023-02-03\"))\n\n[1] \"2023-02-03\"\n\nk-j\n\nTime difference of 19391 days"
  },
  {
    "objectID": "slides/06_datatypes.html#check-data-types",
    "href": "slides/06_datatypes.html#check-data-types",
    "title": "Data types",
    "section": "Check data types",
    "text": "Check data types\n\nCheck with typeof()/class()\n\n\n\n\nCheck in RStudio\n\n\n\n\nUse is.&lt;type&gt;() functions: is.logical(), is.numeric(), is.character()\n\n\n\nis.character(7)\n\n[1] FALSE\n\nis.character(\"7\")\n\n[1] TRUE"
  },
  {
    "objectID": "slides/06_datatypes.html#converting-between-data-types-coercion",
    "href": "slides/06_datatypes.html#converting-between-data-types-coercion",
    "title": "Data types",
    "section": "Converting between data types (coercion)",
    "text": "Converting between data types (coercion)\n\nUse as.&lt;type&gt;() functions:\nas.logical(), as.numeric(), as.character()\n\n\n\ne\n\n[1] \"7\"\n\ntypeof(e)\n\n[1] \"character\"\n\n(l &lt;- as.numeric(e))\n\n[1] 7\n\ntypeof(l)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/06_datatypes.html#converting-between-data-types-coercion-1",
    "href": "slides/06_datatypes.html#converting-between-data-types-coercion-1",
    "title": "Data types",
    "section": "Converting between data types (coercion)",
    "text": "Converting between data types (coercion)\n\n(m &lt;- \"TRUE\")\n\n[1] \"TRUE\"\n\ntypeof(m)\n\n[1] \"character\"\n\n(n &lt;- as.logical(m))\n\n[1] TRUE\n\ntypeof(n)\n\n[1] \"logical\""
  },
  {
    "objectID": "slides/06_datatypes.html#converting-between-data-types-coercion-2",
    "href": "slides/06_datatypes.html#converting-between-data-types-coercion-2",
    "title": "Data types",
    "section": "Converting between data types (coercion)",
    "text": "Converting between data types (coercion)\nFactors to numerics is tricky\n\n(o &lt;- factor(0, levels = c(\"1\", \"0\")))\n\n[1] 0\nLevels: 1 0\n\nas.numeric(o)\n\n[1] 2\n\n\n\nFirst coerce to character\n\nas.character(o)\n\n[1] \"0\"\n\nas.numeric(as.character(o))\n\n[1] 0"
  },
  {
    "objectID": "slides/06_datatypes.html#special-values",
    "href": "slides/06_datatypes.html#special-values",
    "title": "Data types",
    "section": "Special values",
    "text": "Special values\n\nNA represents missing values\n\nEach data type has its own type of NA\nCheck with is.na()\n\n\n\nNaN means “not a number” (undefined)\n\n0 / 0 = NaN\n\n\n\n\nInf and -Inf represent infinity and negative infinity\n\n1 / 0 = Inf\n-1 / 0 = -Inf"
  },
  {
    "objectID": "slides/06_datatypes.html#mental-model-of-data-types-1",
    "href": "slides/06_datatypes.html#mental-model-of-data-types-1",
    "title": "Data types",
    "section": "Mental model of data types",
    "text": "Mental model of data types"
  },
  {
    "objectID": "slides/06_datatypes.html#lets-code",
    "href": "slides/06_datatypes.html#lets-code",
    "title": "Data types",
    "section": "Let’s code!",
    "text": "Let’s code!\nData types coding [Rmd]"
  },
  {
    "objectID": "slides/08_importing.html#mental-model-of-data-in-r",
    "href": "slides/08_importing.html#mental-model-of-data-in-r",
    "title": "Importing data",
    "section": "Mental model of data in R",
    "text": "Mental model of data in R"
  },
  {
    "objectID": "slides/08_importing.html#mental-model-of-data-analysis",
    "href": "slides/08_importing.html#mental-model-of-data-analysis",
    "title": "Importing data",
    "section": "Mental model of data analysis",
    "text": "Mental model of data analysis"
  },
  {
    "objectID": "slides/08_importing.html#mental-model-of-importing-data",
    "href": "slides/08_importing.html#mental-model-of-importing-data",
    "title": "Importing data",
    "section": "Mental model of importing data",
    "text": "Mental model of importing data"
  },
  {
    "objectID": "slides/08_importing.html#file-types",
    "href": "slides/08_importing.html#file-types",
    "title": "Importing data",
    "section": "File types",
    "text": "File types\n\n\nExcel (.xls/.xlsx): Binary matrix file with formatting, formulas, multiple sheets\nComma-separated values (.csv): Plain text matrix file without formatting, etc. (also TSV)\nOther program-specific files: SPSS, SAS, etc.\nText files (.txt): Plain text file of raw text\nStart saving CSVs and convert other formats to CSVs"
  },
  {
    "objectID": "slides/08_importing.html#dog-data",
    "href": "slides/08_importing.html#dog-data",
    "title": "Importing data",
    "section": "Dog data",
    "text": "Dog data\n\n\nDownload data for dog breed popularity.\nCreate data/ directory in your dpavir2023 course directory.\nSave dog_breed_popularity.csv into the data/ directory.\nView file in RStudio file manager"
  },
  {
    "objectID": "slides/08_importing.html#base-r-data-import",
    "href": "slides/08_importing.html#base-r-data-import",
    "title": "Importing data",
    "section": "Base R data import",
    "text": "Base R data import\nread.csv()\n\nWrapper around read.table()\n\n\n\nDefaults\n\nHeader row (turn off with header = FALSE)\nComma separated (change with sep=\";\" or use read.csv2())\nOutputs data frame"
  },
  {
    "objectID": "slides/08_importing.html#base-r-data-import-1",
    "href": "slides/08_importing.html#base-r-data-import-1",
    "title": "Importing data",
    "section": "Base R data import",
    "text": "Base R data import\nread.csv()\nUsage:\nread.csv(file = \"path/to/file.csv\")\n\nlibrary(here)\nmydf &lt;- read.csv(here(\"data/dog_breed_popularity.csv\"))"
  },
  {
    "objectID": "slides/08_importing.html#tidyverse-data-import",
    "href": "slides/08_importing.html#tidyverse-data-import",
    "title": "Importing data",
    "section": "{tidyverse} data import",
    "text": "{tidyverse} data import\n{readr}\nreadr::read_csv()\n\n\n\nControl column names with col_names (including renaming)\nControl column types with col_types\nControl missing values with na and quoted_na\nCan skip rows before reading data with skip or cut off with n_max\nOutputs tibble"
  },
  {
    "objectID": "slides/08_importing.html#tidyverse-data-import-1",
    "href": "slides/08_importing.html#tidyverse-data-import-1",
    "title": "Importing data",
    "section": "{tidyverse} data import",
    "text": "{tidyverse} data import\nreadr::read_csv()\nUsage:\nread_csv(file = \"path/to/file.csv\")\n\nlibrary(readr)\nmydf2 &lt;- read_csv(here(\"data/dog_breed_popularity.csv\"))"
  },
  {
    "objectID": "slides/08_importing.html#importing-from-urls",
    "href": "slides/08_importing.html#importing-from-urls",
    "title": "Importing data",
    "section": "Importing from URLs",
    "text": "Importing from URLs\nBoth read.csv() and read_csv() import CSV files available online by using the URL as the path.\nhttps://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv\n\nmydf3 &lt;- read.csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv\")\nmydf4 &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv\")"
  },
  {
    "objectID": "slides/08_importing.html#exporting-csvs",
    "href": "slides/08_importing.html#exporting-csvs",
    "title": "Importing data",
    "section": "Exporting CSVs",
    "text": "Exporting CSVs\nwrite.csv()\n\nCharacter/factor columns in quotes with quote = TRUE\nRemove row/column names with row.names = FALSE or col.names = FALSE\n\n\nreadr::write_csv()\n\nCharacters are only quoted if they contain a comma, quote, or new line"
  },
  {
    "objectID": "slides/08_importing.html#exporting-csvs-1",
    "href": "slides/08_importing.html#exporting-csvs-1",
    "title": "Importing data",
    "section": "Exporting CSVs",
    "text": "Exporting CSVs\nUsage\nwrite.csv(df, file = \"path/to/file.csv\")\nwrite_csv(df, file = \"path/to/file.csv\")\n\nwrite.csv(mydf, here(\"data/newdata.csv\"))\nwrite_csv(mydf, here(\"data/newdata2.csv\"))"
  },
  {
    "objectID": "slides/08_importing.html#excel-data",
    "href": "slides/08_importing.html#excel-data",
    "title": "Importing data",
    "section": "Excel data",
    "text": "Excel data\nImport Excel data with {readxl}\n\n\n\n\nFunctions: read_xls(), read_xlsx(), read_excel()\nSpecify sheets with sheets argument\nSpecify subset of cells with range argument\nLike read_csv(), has col_names, col_types, na, skip, n_max"
  },
  {
    "objectID": "slides/08_importing.html#excel-data-1",
    "href": "slides/08_importing.html#excel-data-1",
    "title": "Importing data",
    "section": "Excel data",
    "text": "Excel data\nImport Excel data with {readxl}\n\nUsage:\nread_excel(path = \"path/to/file.csv\")*\n\n\nlibrary(readxl)\nmydf5 &lt;- read_excel(here(\"data/dog_breed_data.xlsx\"), sheet = \"Sheet2\")\n\n\n\n\n*Currently, read_excel() cannot download from URLs. So first download https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_data.xlsx and save it in the data/ directory."
  },
  {
    "objectID": "slides/08_importing.html#other-stats-packages",
    "href": "slides/08_importing.html#other-stats-packages",
    "title": "Importing data",
    "section": "Other stats packages",
    "text": "Other stats packages\nImport SPSS, SAS, & Stata data with {haven}\n\n\n\nSPSS\nhaven::read_sav(\"mtcars.sav\")\nSAS\nhaven::read_sas(\"mtcars.sas7bdat\")\nStata\nhaven::read_dta(\"mtcars.dta\")"
  },
  {
    "objectID": "slides/08_importing.html#qualtrics-data",
    "href": "slides/08_importing.html#qualtrics-data",
    "title": "Importing data",
    "section": "Qualtrics data",
    "text": "Qualtrics data\nImport Qualtrics data directly with {qualtRics}\n\n\n\nRegister your Qualtrics credentials with qualtRics::qualtrics_api_credentials()*\nGet survey ID by viewing qualtRics::all_surveys()\nImport data with qualtRics::fetch_survey()\nNever have to download Qualtrics data again!\n\n\n\n\n*Be cautious with using API credentials! I’m not responsible for the security of packages that I describe."
  },
  {
    "objectID": "slides/08_importing.html#qualtrics-data-1",
    "href": "slides/08_importing.html#qualtrics-data-1",
    "title": "Importing data",
    "section": "Qualtrics data",
    "text": "Qualtrics data\nImport Qualtrics data directly with {qualtRics}\n\n\nDownload choice text by default or numeric values with label = FALSE\nSet time zone with time_zone = \"America/Chicago\"\nTurn off sublabels with add_var_labels = FALSE"
  },
  {
    "objectID": "slides/08_importing.html#qualtrics-data-2",
    "href": "slides/08_importing.html#qualtrics-data-2",
    "title": "Importing data",
    "section": "Qualtrics data",
    "text": "Qualtrics data\nUsage\n\nmydf6 &lt;- qualtRics::fetch_survey(\"SV_xxxxxxxxxxxxx\", save_dir = \"data\", label = FALSE, convert = FALSE, \n             force_request = TRUE, time_zone = \"America/Chicago\")"
  },
  {
    "objectID": "slides/08_importing.html#cloud-storage",
    "href": "slides/08_importing.html#cloud-storage",
    "title": "Importing data",
    "section": "Cloud storage",
    "text": "Cloud storage\nImport data directly from cloud storage\n\nOneDrive {Microsoft365R}*\nGoogle sheets {googlesheets4}*\nBox {boxr}*\n\n\n\n\n*Be cautious with using API credentials! I’m not responsible for the security of packages that I describe."
  },
  {
    "objectID": "slides/08_importing.html#mental-model-of-importing-data-1",
    "href": "slides/08_importing.html#mental-model-of-importing-data-1",
    "title": "Importing data",
    "section": "Mental model of importing data",
    "text": "Mental model of importing data"
  },
  {
    "objectID": "slides/08_importing.html#lets-code",
    "href": "slides/08_importing.html#lets-code",
    "title": "Importing data",
    "section": "Let’s code!",
    "text": "Let’s code!\nImporting data [Rmd]"
  },
  {
    "objectID": "slides/10_selecting.html#mental-model-of-data-analysis",
    "href": "slides/10_selecting.html#mental-model-of-data-analysis",
    "title": "Selecting columns",
    "section": "Mental model of data analysis",
    "text": "Mental model of data analysis"
  },
  {
    "objectID": "slides/10_selecting.html#data-wrangling",
    "href": "slides/10_selecting.html#data-wrangling",
    "title": "Selecting columns",
    "section": "Data wrangling",
    "text": "Data wrangling\n{dplyr}\n\n\n\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/10_selecting.html#data-wrangling-1",
    "href": "slides/10_selecting.html#data-wrangling-1",
    "title": "Selecting columns",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nlibrary(dplyr)"
  },
  {
    "objectID": "slides/10_selecting.html#mental-model-of-selecting-columns",
    "href": "slides/10_selecting.html#mental-model-of-selecting-columns",
    "title": "Selecting columns",
    "section": "Mental model of selecting columns",
    "text": "Mental model of selecting columns"
  },
  {
    "objectID": "slides/10_selecting.html#data-set",
    "href": "slides/10_selecting.html#data-set",
    "title": "Selecting columns",
    "section": "Data set",
    "text": "Data set\n\nlibrary(nycflights13)\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…"
  },
  {
    "objectID": "slides/10_selecting.html#selecting-columns-1",
    "href": "slides/10_selecting.html#selecting-columns-1",
    "title": "Selecting columns",
    "section": "Selecting columns",
    "text": "Selecting columns\nselect()"
  },
  {
    "objectID": "slides/10_selecting.html#selecting-columns-2",
    "href": "slides/10_selecting.html#selecting-columns-2",
    "title": "Selecting columns",
    "section": "Selecting columns",
    "text": "Selecting columns\n\nselect() by inclusion\n\nselect(flights, year, month, day, sched_dep_time, sched_arr_time)\n\n# A tibble: 336,776 × 5\n    year month   day sched_dep_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1            515            819\n 2  2013     1     1            529            830\n 3  2013     1     1            540            850\n 4  2013     1     1            545           1022\n 5  2013     1     1            600            837\n 6  2013     1     1            558            728\n 7  2013     1     1            600            854\n 8  2013     1     1            600            723\n 9  2013     1     1            600            846\n10  2013     1     1            600            745\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/10_selecting.html#selecting-columns-3",
    "href": "slides/10_selecting.html#selecting-columns-3",
    "title": "Selecting columns",
    "section": "Selecting columns",
    "text": "Selecting columns\n\nselect() by exclusion\n\nselect(flights, -dep_time, -dep_delay, -arr_time, -arr_delay, -carrier, -flight, -tailnum,\n       -origin, -dest, -air_time, -distance, -hour, -minute, -time_hour)\n\n# A tibble: 336,776 × 5\n    year month   day sched_dep_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1            515            819\n 2  2013     1     1            529            830\n 3  2013     1     1            540            850\n 4  2013     1     1            545           1022\n 5  2013     1     1            600            837\n 6  2013     1     1            558            728\n 7  2013     1     1            600            854\n 8  2013     1     1            600            723\n 9  2013     1     1            600            846\n10  2013     1     1            600            745\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/10_selecting.html#helper-functions",
    "href": "slides/10_selecting.html#helper-functions",
    "title": "Selecting columns",
    "section": "Helper functions",
    "text": "Helper functions\nCollections of functions to facilitate selecting columns\n\n\n\n\n\n\nWarning\n\n\nThese helper functions only apply inside {dplyr} or other tidyverse functions that use select()."
  },
  {
    "objectID": "slides/10_selecting.html#helper-functions-1",
    "href": "slides/10_selecting.html#helper-functions-1",
    "title": "Selecting columns",
    "section": "Helper functions",
    "text": "Helper functions\nSelect consecutive columns with :\n\n\nselect(flights, year:day, hour, time_hour)\n\n# A tibble: 336,776 × 5\n    year month   day  hour time_hour          \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dttm&gt;             \n 1  2013     1     1     5 2013-01-01 05:00:00\n 2  2013     1     1     5 2013-01-01 05:00:00\n 3  2013     1     1     5 2013-01-01 05:00:00\n 4  2013     1     1     5 2013-01-01 05:00:00\n 5  2013     1     1     6 2013-01-01 06:00:00\n 6  2013     1     1     5 2013-01-01 05:00:00\n 7  2013     1     1     6 2013-01-01 06:00:00\n 8  2013     1     1     6 2013-01-01 06:00:00\n 9  2013     1     1     6 2013-01-01 06:00:00\n10  2013     1     1     6 2013-01-01 06:00:00\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/10_selecting.html#helper-functions-2",
    "href": "slides/10_selecting.html#helper-functions-2",
    "title": "Selecting columns",
    "section": "Helper functions",
    "text": "Helper functions\nSelect everything else with everything()\n\n\nselect(flights, time_hour, air_time, everything())\n\n# A tibble: 336,776 × 19\n   time_hour           air_time  year month   day dep_time sched_dep_time\n   &lt;dttm&gt;                 &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n 7 2013-01-01 06:00:00      158  2013     1     1      555            600\n 8 2013-01-01 06:00:00       53  2013     1     1      557            600\n 9 2013-01-01 06:00:00      140  2013     1     1      557            600\n10 2013-01-01 06:00:00      138  2013     1     1      558            600\n# ℹ 336,766 more rows\n# ℹ 12 more variables: dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;,\n#   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;"
  },
  {
    "objectID": "slides/10_selecting.html#helper-functions-3",
    "href": "slides/10_selecting.html#helper-functions-3",
    "title": "Selecting columns",
    "section": "Helper functions",
    "text": "Helper functions\nSelect columns containing specific text with contains()\n\n\nselect(flights, contains(\"_time\"))\n\n# A tibble: 336,776 × 5\n   dep_time sched_dep_time arr_time sched_arr_time air_time\n      &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;dbl&gt;\n 1      517            515      830            819      227\n 2      533            529      850            830      227\n 3      542            540      923            850      160\n 4      544            545     1004           1022      183\n 5      554            600      812            837      116\n 6      554            558      740            728      150\n 7      555            600      913            854      158\n 8      557            600      709            723       53\n 9      557            600      838            846      140\n10      558            600      753            745      138\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/10_selecting.html#helper-functions-4",
    "href": "slides/10_selecting.html#helper-functions-4",
    "title": "Selecting columns",
    "section": "Helper functions",
    "text": "Helper functions\nSelect columns starting or ending with text with starts_with() or ends_with()\n\n\nselect(flights, starts_with(\"dep_\"))\n\n# A tibble: 336,776 × 2\n   dep_time dep_delay\n      &lt;int&gt;     &lt;dbl&gt;\n 1      517         2\n 2      533         4\n 3      542         2\n 4      544        -1\n 5      554        -6\n 6      554        -4\n 7      555        -5\n 8      557        -3\n 9      557        -3\n10      558        -2\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/10_selecting.html#move-with-select",
    "href": "slides/10_selecting.html#move-with-select",
    "title": "Selecting columns",
    "section": "Move with select()\n",
    "text": "Move with select()"
  },
  {
    "objectID": "slides/10_selecting.html#move-with-select-1",
    "href": "slides/10_selecting.html#move-with-select-1",
    "title": "Selecting columns",
    "section": "Move with select()\n",
    "text": "Move with select()\n\n\nselect(flights, carrier, flight, year:day)\n\n# A tibble: 336,776 × 5\n   carrier flight  year month   day\n   &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 UA        1545  2013     1     1\n 2 UA        1714  2013     1     1\n 3 AA        1141  2013     1     1\n 4 B6         725  2013     1     1\n 5 DL         461  2013     1     1\n 6 UA        1696  2013     1     1\n 7 B6         507  2013     1     1\n 8 EV        5708  2013     1     1\n 9 B6          79  2013     1     1\n10 AA         301  2013     1     1\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/10_selecting.html#move-with-relocate",
    "href": "slides/10_selecting.html#move-with-relocate",
    "title": "Selecting columns",
    "section": "Move with relocate()\n",
    "text": "Move with relocate()"
  },
  {
    "objectID": "slides/10_selecting.html#move-with-relocate-1",
    "href": "slides/10_selecting.html#move-with-relocate-1",
    "title": "Selecting columns",
    "section": "Move with relocate()\n",
    "text": "Move with relocate()\n\n\nrelocate(flights, carrier, flight, .before = year)\n\n# A tibble: 336,776 × 19\n   carrier flight  year month   day dep_time sched_dep_time dep_delay arr_time\n   &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1 UA        1545  2013     1     1      517            515         2      830\n 2 UA        1714  2013     1     1      533            529         4      850\n 3 AA        1141  2013     1     1      542            540         2      923\n 4 B6         725  2013     1     1      544            545        -1     1004\n 5 DL         461  2013     1     1      554            600        -6      812\n 6 UA        1696  2013     1     1      554            558        -4      740\n 7 B6         507  2013     1     1      555            600        -5      913\n 8 EV        5708  2013     1     1      557            600        -3      709\n 9 B6          79  2013     1     1      557            600        -3      838\n10 AA         301  2013     1     1      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 10 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, tailnum &lt;chr&gt;,\n#   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/10_selecting.html#rename-with-select",
    "href": "slides/10_selecting.html#rename-with-select",
    "title": "Selecting columns",
    "section": "Rename with select()\n",
    "text": "Rename with select()\n\n\nselect(flights, airline = carrier, flight_num = flight, everything())\n\n# A tibble: 336,776 × 19\n   airline flight_num  year month   day dep_time sched_dep_time dep_delay\n   &lt;chr&gt;        &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1 UA            1545  2013     1     1      517            515         2\n 2 UA            1714  2013     1     1      533            529         4\n 3 AA            1141  2013     1     1      542            540         2\n 4 B6             725  2013     1     1      544            545        -1\n 5 DL             461  2013     1     1      554            600        -6\n 6 UA            1696  2013     1     1      554            558        -4\n 7 B6             507  2013     1     1      555            600        -5\n 8 EV            5708  2013     1     1      557            600        -3\n 9 B6              79  2013     1     1      557            600        -3\n10 AA             301  2013     1     1      558            600        -2\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/10_selecting.html#rename-with-rename",
    "href": "slides/10_selecting.html#rename-with-rename",
    "title": "Selecting columns",
    "section": "Rename with rename()\n",
    "text": "Rename with rename()"
  },
  {
    "objectID": "slides/10_selecting.html#rename-with-rename-1",
    "href": "slides/10_selecting.html#rename-with-rename-1",
    "title": "Selecting columns",
    "section": "Rename with rename()\n",
    "text": "Rename with rename()\n\n\nrename(flights, departure = dep_time, arrival = arr_time)\n\n# A tibble: 336,776 × 19\n    year month   day departure sched_dep_time dep_delay arrival sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;   &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1       517            515         2     830            819\n 2  2013     1     1       533            529         4     850            830\n 3  2013     1     1       542            540         2     923            850\n 4  2013     1     1       544            545        -1    1004           1022\n 5  2013     1     1       554            600        -6     812            837\n 6  2013     1     1       554            558        -4     740            728\n 7  2013     1     1       555            600        -5     913            854\n 8  2013     1     1       557            600        -3     709            723\n 9  2013     1     1       557            600        -3     838            846\n10  2013     1     1       558            600        -2     753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/10_selecting.html#mental-model-of-selecting-columns-1",
    "href": "slides/10_selecting.html#mental-model-of-selecting-columns-1",
    "title": "Selecting columns",
    "section": "Mental model of selecting columns",
    "text": "Mental model of selecting columns"
  },
  {
    "objectID": "slides/10_selecting.html#lets-code",
    "href": "slides/10_selecting.html#lets-code",
    "title": "Selecting columns",
    "section": "Let’s code!",
    "text": "Let’s code!\nSelecting data [Rmd]"
  },
  {
    "objectID": "slides/12_piping.html#data-wrangling",
    "href": "slides/12_piping.html#data-wrangling",
    "title": "Piping",
    "section": "Data wrangling",
    "text": "Data wrangling"
  },
  {
    "objectID": "slides/12_piping.html#set-up",
    "href": "slides/12_piping.html#set-up",
    "title": "Piping",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(dplyr)\nlibrary(nycflights13)\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…"
  },
  {
    "objectID": "slides/12_piping.html#base-r-pipelines",
    "href": "slides/12_piping.html#base-r-pipelines",
    "title": "Piping",
    "section": "Base R pipelines",
    "text": "Base R pipelines\n\nmyflights &lt;- flights[c(\"year\", \"month\", \"day\", \"air_time\", \"distance\", \n                       \"hour\", \"minute\")]\nmyflights$month &lt;- as.character(myflights$month)\nmyflights$month &lt;- ifelse(myflights$month &lt; 10, \n                          paste0(\"0\", myflights$month), myflights$month)\nmyflights$day &lt;- ifelse(myflights$day &lt; 10, \n                        paste0(\"0\", myflights$day), myflights$day)\nmyflights$date &lt;- paste(myflights$year, myflights$month, myflights$day, \n                        sep = \"-\")\nmyflights$speed &lt;- myflights$distance / myflights$air_time * 60\nmyflights &lt;- myflights[c(\"year\", \"month\", \"day\", \"date\", \"air_time\", \n                         \"distance\", \"speed\", \"hour\", \"minute\")]\n\n\nWhat do you like and dislike about this pipeline?"
  },
  {
    "objectID": "slides/12_piping.html#tidyverse-pipelines",
    "href": "slides/12_piping.html#tidyverse-pipelines",
    "title": "Piping",
    "section": "tidyverse pipelines",
    "text": "tidyverse pipelines\n\nmyflights2 &lt;- flights |&gt; \n  select(year:day, air_time, distance, hour, minute) |&gt; \n  mutate(month = as.character(month),\n         month = if_else(month &lt; 10, paste0(\"0\", month), as.character(month)),\n         day = if_else(day &lt; 10, paste0(\"0\", day), as.character(day)),\n         date = paste(year, month, day, sep = \"-\"),\n         speed = distance / air_time * 60) |&gt; \n  select(year:day, date, air_time, distance, speed, everything())\n\n\nWhat do you like and dislike about this pipeline?"
  },
  {
    "objectID": "slides/12_piping.html#tidyverse-pipelines-1",
    "href": "slides/12_piping.html#tidyverse-pipelines-1",
    "title": "Piping",
    "section": "tidyverse pipelines",
    "text": "tidyverse pipelines\n\nmyflights3 &lt;- flights |&gt; \n  select(year:day, air_time, distance, hour, minute) |&gt; \n  mutate(month = as.character(month),\n         month = if_else(month &lt; 10, paste0(\"0\", month), as.character(month)),\n         day = if_else(day &lt; 10, paste0(\"0\", day), as.character(day)),\n         date = paste(year, month, day, sep = \"-\"),\n         .after = day) |&gt; \n  mutate(speed = distance / air_time * 60,\n         .after = distance)\n\n\nWhat do you like and dislike about this pipeline?"
  },
  {
    "objectID": "slides/12_piping.html#pipeline-comparison",
    "href": "slides/12_piping.html#pipeline-comparison",
    "title": "Piping",
    "section": "Pipeline comparison",
    "text": "Pipeline comparison\n\nidentical(myflights, myflights2)\n\n[1] TRUE\n\nidentical(myflights, myflights3)\n\n[1] TRUE\n\nidentical(myflights2, myflights3)\n\n[1] TRUE\n\n\n\nCharacter counts\n\n\n\n\nPipeline\nCharacters\n\n\n\nmyflights\n566\n\n\nmyflights2\n423\n\n\nmyflights3\n406"
  },
  {
    "objectID": "slides/12_piping.html#pipes",
    "href": "slides/12_piping.html#pipes",
    "title": "Piping",
    "section": "Pipes",
    "text": "Pipes\n\nBase R pipe |&gt;\n\nadded in R 4.1.0 but key functionality started in 4.2.0\nworks following most base R and tidyverse functions\n\n\n\n\n\ntidyverse pipe %&gt;%\n\nfrom {magrittr} package\nworks following tidyverse verbs\n\n\n\n\n\n\nHadley Wickham recommends using the base R pipe |&gt;, so we’ll use that here."
  },
  {
    "objectID": "slides/12_piping.html#piping-basics",
    "href": "slides/12_piping.html#piping-basics",
    "title": "Piping",
    "section": "Piping basics",
    "text": "Piping basics\nStart with the data object…\n\nflights |&gt; \n  select(year:dep_delay, origin) |&gt; # include these columns\n  select(-sched_dep_time) # exclude this column\n\n\nOr use data object as the first argument…\n\nselect(flights, year:dep_delay, origin) |&gt; # include these columns\n  select(-sched_dep_time) # exclude this column\n\n\n\nBut don’t use data object after first pipe\n\nselect(flights, year:dep_delay, origin) |&gt; # include these columns\n  select(flights, -sched_dep_time) # exclude this column\n\nError in `select()`:\n! Can't subset columns with `flights`.\n✖ `flights` must be numeric or character, not a &lt;tbl_df/tbl/data.frame&gt; object."
  },
  {
    "objectID": "slides/12_piping.html#piping-basics-1",
    "href": "slides/12_piping.html#piping-basics-1",
    "title": "Piping",
    "section": "Piping basics",
    "text": "Piping basics\nLike any object, assigning it does not output to console\n\nmyflights &lt;- flights |&gt; \n  select(year:dep_delay, origin) |&gt;\n  select(-sched_dep_time)\n\n\nBut omitting assignment does\n\nflights |&gt; \n  select(year:dep_delay, origin) |&gt;\n  select(-sched_dep_time)\n\n# A tibble: 336,776 × 6\n    year month   day dep_time dep_delay origin\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt; \n 1  2013     1     1      517         2 EWR   \n 2  2013     1     1      533         4 LGA   \n 3  2013     1     1      542         2 JFK   \n 4  2013     1     1      544        -1 JFK   \n 5  2013     1     1      554        -6 LGA   \n 6  2013     1     1      554        -4 EWR   \n 7  2013     1     1      555        -5 EWR   \n 8  2013     1     1      557        -3 LGA   \n 9  2013     1     1      557        -3 JFK   \n10  2013     1     1      558        -2 LGA   \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/12_piping.html#piping-basics-2",
    "href": "slides/12_piping.html#piping-basics-2",
    "title": "Piping",
    "section": "Piping basics",
    "text": "Piping basics\nAs does wrapping assignment in parentheses\n\n(myflights &lt;- flights |&gt; \n  select(year:dep_delay, origin) |&gt;\n  select(-sched_dep_time))\n\n# A tibble: 336,776 × 6\n    year month   day dep_time dep_delay origin\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt; \n 1  2013     1     1      517         2 EWR   \n 2  2013     1     1      533         4 LGA   \n 3  2013     1     1      542         2 JFK   \n 4  2013     1     1      544        -1 JFK   \n 5  2013     1     1      554        -6 LGA   \n 6  2013     1     1      554        -4 EWR   \n 7  2013     1     1      555        -5 EWR   \n 8  2013     1     1      557        -3 LGA   \n 9  2013     1     1      557        -3 JFK   \n10  2013     1     1      558        -2 LGA   \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/12_piping.html#advanced-piping",
    "href": "slides/12_piping.html#advanced-piping",
    "title": "Piping",
    "section": "Advanced piping",
    "text": "Advanced piping\n\nSometimes, non-tidyverse functions don’t take the data object as the first argument\nThis requires a “placeholder” signaling where the data object goes\n\n\n\nThe placeholder for the |&gt; pipe is _\nThe placeholder for the %&gt;% pipe is ."
  },
  {
    "objectID": "slides/12_piping.html#advanced-piping-1",
    "href": "slides/12_piping.html#advanced-piping-1",
    "title": "Piping",
    "section": "Advanced piping",
    "text": "Advanced piping\nBase R pipe\n\nmtcars |&gt; \n  select(mpg, cyl) |&gt; \n  lm(mpg ~ cyl)\n\n\nError in as.data.frame.default(data) : \n  cannot coerce class ‘\"formula\"’ to a data.frame\n\n\n\nmtcars |&gt; \n  select(mpg, cyl) |&gt; \n  lm(mpg ~ cyl, data = _)\n\n\nCall:\nlm(formula = mpg ~ cyl, data = select(mtcars, mpg, cyl))\n\nCoefficients:\n(Intercept)          cyl  \n     37.885       -2.876  \n\n\n\nYou must specify the argument name to use placeholder"
  },
  {
    "objectID": "slides/12_piping.html#advanced-piping-2",
    "href": "slides/12_piping.html#advanced-piping-2",
    "title": "Piping",
    "section": "Advanced piping",
    "text": "Advanced piping\ntidyverse pipe\n\nmtcars %&gt;% \n  select(mpg, cyl) %&gt;% \n  lm(mpg ~ cyl, data = .)\n\n\nCall:\nlm(formula = mpg ~ cyl, data = .)\n\nCoefficients:\n(Intercept)          cyl  \n     37.885       -2.876"
  },
  {
    "objectID": "slides/12_piping.html#lets-code",
    "href": "slides/12_piping.html#lets-code",
    "title": "Piping",
    "section": "Let’s code!",
    "text": "Let’s code!\nPiping [Rmd]"
  },
  {
    "objectID": "slides/14_summarizing.html#the-problem",
    "href": "slides/14_summarizing.html#the-problem",
    "title": "Summarizing rows",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets? What needs to happen to create data2 from data1?\n\n\n\ndata1\n\n   cond id       date   response\n1     3  1 2022-02-09 0.46708414\n2     2  2 2022-01-25 0.85341699\n3     1  3 2022-01-17 0.27674132\n4     2  4 2022-02-12 0.75481575\n5     3  5 2022-02-18 0.62293253\n6     2  6 2022-01-10 0.23421642\n7     1  7 2022-01-16 0.95526940\n8     3  8 2022-01-01 0.97477158\n9     2  9 2022-01-11 0.20675449\n10    1 10 2022-02-19 0.31482096\n11    3 11 2022-02-28 0.09298274\n12    2 12 2022-01-20 0.65438036\n\n\n\n\ndata2\n\n# A tibble: 3 × 4\n   cond cond_n cond_mean cond_sd\n  &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     1      3     0.516   0.381\n2     2      5     0.541   0.301\n3     3      4     0.539   0.366"
  },
  {
    "objectID": "slides/14_summarizing.html#data-wrangling",
    "href": "slides/14_summarizing.html#data-wrangling",
    "title": "Summarizing rows",
    "section": "Data wrangling",
    "text": "Data wrangling"
  },
  {
    "objectID": "slides/14_summarizing.html#set-up",
    "href": "slides/14_summarizing.html#set-up",
    "title": "Summarizing rows",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(dplyr)\nlibrary(nycflights13)\n(flights2 &lt;- select(flights, year:dep_delay, carrier))\n\n# A tibble: 336,776 × 7\n    year month   day dep_time sched_dep_time dep_delay carrier\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013     1     1      517            515         2 UA     \n 2  2013     1     1      533            529         4 UA     \n 3  2013     1     1      542            540         2 AA     \n 4  2013     1     1      544            545        -1 B6     \n 5  2013     1     1      554            600        -6 DL     \n 6  2013     1     1      554            558        -4 UA     \n 7  2013     1     1      555            600        -5 B6     \n 8  2013     1     1      557            600        -3 EV     \n 9  2013     1     1      557            600        -3 B6     \n10  2013     1     1      558            600        -2 AA     \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#count",
    "href": "slides/14_summarizing.html#count",
    "title": "Summarizing rows",
    "section": "count()",
    "text": "count()\n\nflights2 |&gt; \n  count(carrier)\n\n# A tibble: 16 × 2\n   carrier     n\n   &lt;chr&gt;   &lt;int&gt;\n 1 9E      18460\n 2 AA      32729\n 3 AS        714\n 4 B6      54635\n 5 DL      48110\n 6 EV      54173\n 7 F9        685\n 8 FL       3260\n 9 HA        342\n10 MQ      26397\n11 OO         32\n12 UA      58665\n13 US      20536\n14 VX       5162\n15 WN      12275\n16 YV        601"
  },
  {
    "objectID": "slides/14_summarizing.html#count-1",
    "href": "slides/14_summarizing.html#count-1",
    "title": "Summarizing rows",
    "section": "count()",
    "text": "count()\n\nflights2 |&gt; \n  count(carrier, month)\n\n# A tibble: 185 × 3\n   carrier month     n\n   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n 1 9E          1  1573\n 2 9E          2  1459\n 3 9E          3  1627\n 4 9E          4  1511\n 5 9E          5  1462\n 6 9E          6  1437\n 7 9E          7  1494\n 8 9E          8  1456\n 9 9E          9  1540\n10 9E         10  1673\n# ℹ 175 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#summarise",
    "href": "slides/14_summarizing.html#summarise",
    "title": "Summarizing rows",
    "section": "summarise()",
    "text": "summarise()"
  },
  {
    "objectID": "slides/14_summarizing.html#summarise-1",
    "href": "slides/14_summarizing.html#summarise-1",
    "title": "Summarizing rows",
    "section": "summarise()",
    "text": "summarise()\n\nflights2 |&gt; \n  summarise(n())\n\n# A tibble: 1 × 1\n   `n()`\n   &lt;int&gt;\n1 336776"
  },
  {
    "objectID": "slides/14_summarizing.html#summary-functions",
    "href": "slides/14_summarizing.html#summary-functions",
    "title": "Summarizing rows",
    "section": "Summary functions",
    "text": "Summary functions\n\nn()\nmean()\nmedian()\nmin()\nmax()\nsd()"
  },
  {
    "objectID": "slides/14_summarizing.html#summarise-2",
    "href": "slides/14_summarizing.html#summarise-2",
    "title": "Summarizing rows",
    "section": "summarise()",
    "text": "summarise()\n\nflights2 |&gt; \n  summarise(mean_dep_delay = mean(dep_delay), \n            sd_dep_delay = sd(dep_delay),\n            n_dep_delay = n())\n\n# A tibble: 1 × 3\n  mean_dep_delay sd_dep_delay n_dep_delay\n           &lt;dbl&gt;        &lt;dbl&gt;       &lt;int&gt;\n1             NA           NA      336776\n\n\nWhy does this return NA?\n\n\nflights2 |&gt; \n  summarise(mean_dep_delay = mean(dep_delay, na.rm = TRUE),\n          sd_dep_delay = sd(dep_delay, na.rm = TRUE),\n          n_dep_delay = n())\n\n# A tibble: 1 × 3\n  mean_dep_delay sd_dep_delay n_dep_delay\n           &lt;dbl&gt;        &lt;dbl&gt;       &lt;int&gt;\n1           12.6         40.2      336776"
  },
  {
    "objectID": "slides/14_summarizing.html#summarizing-multiple-columns",
    "href": "slides/14_summarizing.html#summarizing-multiple-columns",
    "title": "Summarizing rows",
    "section": "Summarizing multiple columns",
    "text": "Summarizing multiple columns\nHow do we apply a function across multiple columns?\n\nsummarise() + across()\n\nflights2 |&gt; \n  summarise(across(contains(\"_time\"), mean))\n\n# A tibble: 1 × 2\n  dep_time sched_dep_time\n     &lt;dbl&gt;          &lt;dbl&gt;\n1       NA          1344.\n\n\n\n\n\nflights2 |&gt; \n  summarise(across(contains(\"_time\"), ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 2\n  dep_time sched_dep_time\n     &lt;dbl&gt;          &lt;dbl&gt;\n1    1349.          1344."
  },
  {
    "objectID": "slides/14_summarizing.html#summarizing-multiple-columns-1",
    "href": "slides/14_summarizing.html#summarizing-multiple-columns-1",
    "title": "Summarizing rows",
    "section": "Summarizing multiple columns",
    "text": "Summarizing multiple columns\nsummarise() + across()\nMultiple functions (add list())\n\nflights2 |&gt; \n  summarise(across(contains(\"_time\"), # for all columns containing \"_time\"\n                   list(mean = ~ mean(.x, na.rm = TRUE), # calculate the mean\n                        sd = ~ sd(.x, na.rm = TRUE)))) # and standard deviation\n\n# A tibble: 1 × 4\n  dep_time_mean dep_time_sd sched_dep_time_mean sched_dep_time_sd\n          &lt;dbl&gt;       &lt;dbl&gt;               &lt;dbl&gt;             &lt;dbl&gt;\n1         1349.        488.               1344.              467."
  },
  {
    "objectID": "slides/14_summarizing.html#group_by",
    "href": "slides/14_summarizing.html#group_by",
    "title": "Summarizing rows",
    "section": "group_by()",
    "text": "group_by()\n\nflights2 |&gt; \n  group_by(month)\n\n# A tibble: 336,776 × 7\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay carrier\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013     1     1      517            515         2 UA     \n 2  2013     1     1      533            529         4 UA     \n 3  2013     1     1      542            540         2 AA     \n 4  2013     1     1      544            545        -1 B6     \n 5  2013     1     1      554            600        -6 DL     \n 6  2013     1     1      554            558        -4 UA     \n 7  2013     1     1      555            600        -5 B6     \n 8  2013     1     1      557            600        -3 EV     \n 9  2013     1     1      557            600        -3 B6     \n10  2013     1     1      558            600        -2 AA     \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#group_by-1",
    "href": "slides/14_summarizing.html#group_by-1",
    "title": "Summarizing rows",
    "section": "group_by()",
    "text": "group_by()\nRemove groups with ungroup()\n\nflights2 |&gt; \n  group_by(month) |&gt; \n  ungroup()\n\n# A tibble: 336,776 × 7\n    year month   day dep_time sched_dep_time dep_delay carrier\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013     1     1      517            515         2 UA     \n 2  2013     1     1      533            529         4 UA     \n 3  2013     1     1      542            540         2 AA     \n 4  2013     1     1      544            545        -1 B6     \n 5  2013     1     1      554            600        -6 DL     \n 6  2013     1     1      554            558        -4 UA     \n 7  2013     1     1      555            600        -5 B6     \n 8  2013     1     1      557            600        -3 EV     \n 9  2013     1     1      557            600        -3 B6     \n10  2013     1     1      558            600        -2 AA     \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#summarizing-groups-of-data",
    "href": "slides/14_summarizing.html#summarizing-groups-of-data",
    "title": "Summarizing rows",
    "section": "Summarizing groups of data",
    "text": "Summarizing groups of data\ngroup_by() + summarise()\n\nflights2 |&gt; \n  group_by(carrier) |&gt; \n  summarise(carrier_n = n(),\n            mean_carrier_delay = mean(dep_delay, na.rm = TRUE), \n            sd_carrier_delay = sd(dep_delay, na.rm = TRUE))\n\n# A tibble: 16 × 4\n   carrier carrier_n mean_carrier_delay sd_carrier_delay\n   &lt;chr&gt;       &lt;int&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n 1 9E          18460              16.7              45.9\n 2 AA          32729               8.59             37.4\n 3 AS            714               5.80             31.4\n 4 B6          54635              13.0              38.5\n 5 DL          48110               9.26             39.7\n 6 EV          54173              20.0              46.6\n 7 F9            685              20.2              58.4\n 8 FL           3260              18.7              52.7\n 9 HA            342               4.90             74.1\n10 MQ          26397              10.6              39.2\n11 OO             32              12.6              43.1\n12 UA          58665              12.1              35.7\n13 US          20536               3.78             28.1\n14 VX           5162              12.9              44.8\n15 WN          12275              17.7              43.3\n16 YV            601              19.0              49.2"
  },
  {
    "objectID": "slides/14_summarizing.html#summarizing-multiple-groups",
    "href": "slides/14_summarizing.html#summarizing-multiple-groups",
    "title": "Summarizing rows",
    "section": "Summarizing multiple groups",
    "text": "Summarizing multiple groups\ngroup_by() + summarise()\n\nflights2 |&gt; \n  group_by(carrier, month) |&gt; \n  summarise(carrier_n = n(),\n            mean_carrier_delay = mean(dep_delay, na.rm = TRUE), \n            sd_carrier_delay = sd(dep_delay, na.rm = TRUE))\n\n# A tibble: 185 × 5\n# Groups:   carrier [16]\n   carrier month carrier_n mean_carrier_delay sd_carrier_delay\n   &lt;chr&gt;   &lt;int&gt;     &lt;int&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n 1 9E          1      1573              16.9              47.6\n 2 9E          2      1459              16.5              50.5\n 3 9E          3      1627              13.4              43.0\n 4 9E          4      1511              13.6              43.8\n 5 9E          5      1462              22.7              50.6\n 6 9E          6      1437              29.0              55.4\n 7 9E          7      1494              31.4              60.4\n 8 9E          8      1456              17.3              42.8\n 9 9E          9      1540               7.75             34.3\n10 9E         10      1673               9.33             33.8\n# ℹ 175 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#summarizing-groups-for-multiple-columns",
    "href": "slides/14_summarizing.html#summarizing-groups-for-multiple-columns",
    "title": "Summarizing rows",
    "section": "Summarizing groups for multiple columns",
    "text": "Summarizing groups for multiple columns\ngroup_by() + summarise() + across()\n\nflights2 |&gt; \n  group_by(carrier) |&gt; # separately for each carrier\n  summarise(across(contains(\"_time\"), # for all columns containing \"_time\"\n                   list(mean = ~ mean(.x, na.rm = TRUE), # calculate the mean\n                        sd = ~ sd(.x, na.rm = TRUE)))) # and standard deviation\n\n# A tibble: 16 × 5\n   carrier dep_time_mean dep_time_sd sched_dep_time_mean sched_dep_time_sd\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;               &lt;dbl&gt;             &lt;dbl&gt;\n 1 9E              1487.       450.                1472.             430. \n 2 AA              1297.       458.                1290.             442. \n 3 AS              1295.       566.                1285.             552. \n 4 B6              1381.       555.                1397.             525. \n 5 DL              1351.       463.                1346.             445. \n 6 EV              1369.       497.                1354.             471. \n 7 F9              1438.       405.                1408.             376. \n 8 FL              1387.       480.                1372.             446. \n 9 HA               949.        53.6                974.              41.7\n10 MQ              1393.       442.                1387.             428. \n11 OO              1725.       163.                1731.             162. \n12 UA              1327.       484.                1313.             467. \n13 US              1231.       456.                1246.             447. \n14 VX              1280.       460.                1265.             435. \n15 WN              1281.       468.                1260.             440. \n16 YV              1601.       245.                1575.             223."
  },
  {
    "objectID": "slides/14_summarizing.html#solving-the-problem",
    "href": "slides/14_summarizing.html#solving-the-problem",
    "title": "Summarizing rows",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code turns data1 into data2?\n\n\n\ndata1\n\n   cond id       date   response\n1     3  1 2022-02-09 0.46708414\n2     2  2 2022-01-25 0.85341699\n3     1  3 2022-01-17 0.27674132\n4     2  4 2022-02-12 0.75481575\n5     3  5 2022-02-18 0.62293253\n6     2  6 2022-01-10 0.23421642\n7     1  7 2022-01-16 0.95526940\n8     3  8 2022-01-01 0.97477158\n9     2  9 2022-01-11 0.20675449\n10    1 10 2022-02-19 0.31482096\n11    3 11 2022-02-28 0.09298274\n12    2 12 2022-01-20 0.65438036\n\n\n\n\ndata2\n\n# A tibble: 3 × 4\n   cond cond_n cond_mean cond_sd\n  &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     1      3     0.516   0.381\n2     2      5     0.541   0.301\n3     3      4     0.539   0.366"
  },
  {
    "objectID": "slides/14_summarizing.html#slicing-rows",
    "href": "slides/14_summarizing.html#slicing-rows",
    "title": "Summarizing rows",
    "section": "Slicing rows",
    "text": "Slicing rows\nWhat if you want to grab a subset of rows per group?\ndplyr::slice_() functions\n\n\nslice_head() first row(s) from each group\n\nslice_tail() last row(s) in each group\n\nslice_min() row(s) with smallest value in column x\n\nslice_max() row(s) with largest value in column x\n\nslice_sample() random row(s)"
  },
  {
    "objectID": "slides/14_summarizing.html#slicing-rows-1",
    "href": "slides/14_summarizing.html#slicing-rows-1",
    "title": "Summarizing rows",
    "section": "Slicing rows",
    "text": "Slicing rows\nLet’s say we want the first flight for each carrier on 2022-02-22.\n\nflights2 |&gt; \n  filter(month == 2 & day == 22 & dep_time &gt; 10)\n\n# A tibble: 938 × 7\n    year month   day dep_time sched_dep_time dep_delay carrier\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013     2    22      455            500        -5 US     \n 2  2013     2    22      512            515        -3 UA     \n 3  2013     2    22      530            530         0 UA     \n 4  2013     2    22      536            545        -9 B6     \n 5  2013     2    22      539            540        -1 AA     \n 6  2013     2    22      551            600        -9 B6     \n 7  2013     2    22      553            600        -7 DL     \n 8  2013     2    22      553            600        -7 EV     \n 9  2013     2    22      553            600        -7 B6     \n10  2013     2    22      553            600        -7 US     \n# ℹ 928 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#slicing-rows-2",
    "href": "slides/14_summarizing.html#slicing-rows-2",
    "title": "Summarizing rows",
    "section": "Slicing rows",
    "text": "Slicing rows\nLet’s say we want the first flight for each carrier on 2022-02-22.\n\nflights2 |&gt; \n  filter(month == 2 & day == 22 & dep_time &gt; 10) |&gt; \n  group_by(carrier) |&gt; \n  slice_min(dep_time)\n\n# A tibble: 15 × 7\n# Groups:   carrier [15]\n    year month   day dep_time sched_dep_time dep_delay carrier\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013     2    22      558            605        -7 9E     \n 2  2013     2    22      539            540        -1 AA     \n 3  2013     2    22      731            725         6 AS     \n 4  2013     2    22      536            545        -9 B6     \n 5  2013     2    22      553            600        -7 DL     \n 6  2013     2    22      553            600        -7 EV     \n 7  2013     2    22      827            830        -3 F9     \n 8  2013     2    22      602            600         2 FL     \n 9  2013     2    22      857            900        -3 HA     \n10  2013     2    22      553            600        -7 MQ     \n11  2013     2    22      512            515        -3 UA     \n12  2013     2    22      455            500        -5 US     \n13  2013     2    22      702            705        -3 VX     \n14  2013     2    22      601            600         1 WN     \n15  2013     2    22     1601           1606        -5 YV"
  },
  {
    "objectID": "slides/14_summarizing.html#slicing-rows-3",
    "href": "slides/14_summarizing.html#slicing-rows-3",
    "title": "Summarizing rows",
    "section": "Slicing rows",
    "text": "Slicing rows\nWhat if we want the three most delayed flight for each carrier on 2022-02-22.\n\nflights2 |&gt; \n  filter(month == 2 & day == 22 & dep_time &gt; 10) |&gt; \n  group_by(carrier) |&gt; \n  slice_max(dep_delay, n = 3) |&gt; \n  arrange(carrier, dep_delay)\n\n# A tibble: 43 × 7\n# Groups:   carrier [15]\n    year month   day dep_time sched_dep_time dep_delay carrier\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013     2    22     1723           1540       103 9E     \n 2  2013     2    22     2301           1945       196 9E     \n 3  2013     2    22     2010           1550       260 9E     \n 4  2013     2    22     2134           2015        79 AA     \n 5  2013     2    22     2240           2045       115 AA     \n 6  2013     2    22     2000           1700       180 AA     \n 7  2013     2    22     1811           1815        -4 AS     \n 8  2013     2    22      731            725         6 AS     \n 9  2013     2    22     1955           1805       110 B6     \n10  2013     2    22     1829           1600       149 B6     \n# ℹ 33 more rows"
  },
  {
    "objectID": "slides/14_summarizing.html#dplyr-verbs",
    "href": "slides/14_summarizing.html#dplyr-verbs",
    "title": "Summarizing rows",
    "section": "{dplyr} verbs",
    "text": "{dplyr} verbs\n\n\n\nselect()\nrename()\nrelocate()\nmutate()\nif_else()\ncase_when()\nrowwise()\nacross()\n\n\n\n\nfilter()\nif_any()\ndrop_na()\narrange()\ndesc()\n\n\n\n\n\nsummarise()\n\ncount(), n()\n\ngroup_by()\nslice_()"
  },
  {
    "objectID": "slides/14_summarizing.html#solving-the-problem-1",
    "href": "slides/14_summarizing.html#solving-the-problem-1",
    "title": "Summarizing rows",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code turns data1 into data3?\n\n\n\ndata1\n\n   cond id       date   response\n1     3  1 2022-02-09 0.46708414\n2     2  2 2022-01-25 0.85341699\n3     1  3 2022-01-17 0.27674132\n4     2  4 2022-02-12 0.75481575\n5     3  5 2022-02-18 0.62293253\n6     2  6 2022-01-10 0.23421642\n7     1  7 2022-01-16 0.95526940\n8     3  8 2022-01-01 0.97477158\n9     2  9 2022-01-11 0.20675449\n10    1 10 2022-02-19 0.31482096\n11    3 11 2022-02-28 0.09298274\n12    2 12 2022-01-20 0.65438036\n\n\n\n\ndata3\n\n# A tibble: 2 × 2\n  condition   earliest_date\n  &lt;chr&gt;       &lt;date&gt;       \n1 Condition 2 2022-01-10   \n2 Condition 3 2022-01-01"
  },
  {
    "objectID": "slides/14_summarizing.html#lets-code",
    "href": "slides/14_summarizing.html#lets-code",
    "title": "Summarizing rows",
    "section": "Let’s code!",
    "text": "Let’s code!\nSummarizing rows [Rmd]"
  },
  {
    "objectID": "slides/16_separating.html#the-problem",
    "href": "slides/16_separating.html#the-problem",
    "title": "Separating and uniting data",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat needs to happen to create data2 from data1?\n\n\n\ndata1\n\n# A tibble: 11 × 4\n      id cond1 cond2 date      \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;date&gt;    \n 1     1     1 A     2022-02-11\n 2     1     2 A     2022-02-20\n 3     1     3 A     2022-02-02\n 4     2     1 B     2022-01-18\n 5     2     3 B     2022-02-14\n 6     3     1 A     2022-01-09\n 7     3     2 A     2022-01-25\n 8     3     3 A     2022-02-03\n 9     4     1 B     2022-01-17\n10     4     2 B     2022-01-28\n11     4     3 B     2022-01-27\n\n\n\n\ndata2\n\n# A tibble: 12 × 5\n      id condition year  month day  \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1     1 1A        2022  02    11   \n 2     1 2A        2022  02    20   \n 3     1 3A        2022  02    02   \n 4     2 1B        2022  01    18   \n 5     2 2B        &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 6     2 3B        2022  02    14   \n 7     3 1A        2022  01    09   \n 8     3 2A        2022  01    25   \n 9     3 3A        2022  02    03   \n10     4 1B        2022  01    17   \n11     4 2B        2022  01    28   \n12     4 3B        2022  01    27"
  },
  {
    "objectID": "slides/16_separating.html#mental-model-of-tidy-data",
    "href": "slides/16_separating.html#mental-model-of-tidy-data",
    "title": "Separating and uniting data",
    "section": "Mental model of tidy data",
    "text": "Mental model of tidy data\n\n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell"
  },
  {
    "objectID": "slides/16_separating.html#separating-data-1",
    "href": "slides/16_separating.html#separating-data-1",
    "title": "Separating and uniting data",
    "section": "Separating data",
    "text": "Separating data\n\n\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n\nWhy is table3 not tidy?"
  },
  {
    "objectID": "slides/16_separating.html#separating-data-2",
    "href": "slides/16_separating.html#separating-data-2",
    "title": "Separating and uniting data",
    "section": "Separating data",
    "text": "Separating data\n\nseparate(table3, rate, into = c(\"cases\", \"population\"))\n\n# A tibble: 6 × 4\n  country      year cases  population\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\nseparate(table3, rate, into = c(\"cases\", \"population\"), convert = TRUE)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583"
  },
  {
    "objectID": "slides/16_separating.html#separating-data-3",
    "href": "slides/16_separating.html#separating-data-3",
    "title": "Separating and uniting data",
    "section": "Separating data",
    "text": "Separating data\n\nseparate(table3, year, into = c(\"century\", \"year2\"), sep = 2)\n\n# A tibble: 6 × 4\n  country     century year2 rate             \n  &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 19      99    745/19987071     \n2 Afghanistan 20      00    2666/20595360    \n3 Brazil      19      99    37737/172006362  \n4 Brazil      20      00    80488/174504898  \n5 China       19      99    212258/1272915272\n6 China       20      00    213766/1280428583\n\n\n\n\nseparate(table3, year, into = c(\"century\", \"year2\"), sep = 2, remove = FALSE)\n\n# A tibble: 6 × 5\n  country      year century year2 rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan  1999 19      99    745/19987071     \n2 Afghanistan  2000 20      00    2666/20595360    \n3 Brazil       1999 19      99    37737/172006362  \n4 Brazil       2000 20      00    80488/174504898  \n5 China        1999 19      99    212258/1272915272\n6 China        2000 20      00    213766/1280428583"
  },
  {
    "objectID": "slides/16_separating.html#separating-data-4",
    "href": "slides/16_separating.html#separating-data-4",
    "title": "Separating and uniting data",
    "section": "Separating data",
    "text": "Separating data\n\n\n\n\n\n\nWarning\n\n\nThe separate() function is being superseded by separate_wider_delim() and separate_wider_position() for the two use cases described before. But these are both listed as experimental, so we’re sticking with separate().\n\n\n\n\nseparate(table3, rate, into = c(\"cases\", \"population\"), sep = \"/\")\n\n==\n\nseparate_wider_delim(table3, rate, names = c(\"cases\", \"population\"), delim = \"/\")"
  },
  {
    "objectID": "slides/16_separating.html#separating-data-5",
    "href": "slides/16_separating.html#separating-data-5",
    "title": "Separating and uniting data",
    "section": "Separating data",
    "text": "Separating data\n\n\n\n\n\n\nWarning\n\n\nThe separate() function is being superseded by separate_wider_delim() and separate_wider_position() for the two use cases described before. But these are both listed as experimental, so we’re sticking with separate().\n\n\n\nseparate(table3, year, into = c(\"century\", \"year2\"), sep = 2)\n\n==\n\nseparate_wider_position(table3, year, widths = c(century = 2, year2 = 2))"
  },
  {
    "objectID": "slides/16_separating.html#uniting-data-1",
    "href": "slides/16_separating.html#uniting-data-1",
    "title": "Separating and uniting data",
    "section": "Uniting data",
    "text": "Uniting data\n\n\n\n\ntable5\n\n# A tibble: 6 × 4\n  country     century year  rate             \n  &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 19      99    745/19987071     \n2 Afghanistan 20      00    2666/20595360    \n3 Brazil      19      99    37737/172006362  \n4 Brazil      20      00    80488/174504898  \n5 China       19      99    212258/1272915272\n6 China       20      00    213766/1280428583\n\n\n\n\nWhy is table5 not tidy?"
  },
  {
    "objectID": "slides/16_separating.html#uniting-data-2",
    "href": "slides/16_separating.html#uniting-data-2",
    "title": "Separating and uniting data",
    "section": "Uniting data",
    "text": "Uniting data\n\nunite(table5, new, century:year)\n\n# A tibble: 6 × 3\n  country     new   rate             \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 19_99 745/19987071     \n2 Afghanistan 20_00 2666/20595360    \n3 Brazil      19_99 37737/172006362  \n4 Brazil      20_00 80488/174504898  \n5 China       19_99 212258/1272915272\n6 China       20_00 213766/1280428583\n\n\n\n\nunite(table5, new, century:year, sep = \"\")\n\n# A tibble: 6 × 3\n  country     new   rate             \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 1999  745/19987071     \n2 Afghanistan 2000  2666/20595360    \n3 Brazil      1999  37737/172006362  \n4 Brazil      2000  80488/174504898  \n5 China       1999  212258/1272915272\n6 China       2000  213766/1280428583"
  },
  {
    "objectID": "slides/16_separating.html#uniting-data-3",
    "href": "slides/16_separating.html#uniting-data-3",
    "title": "Separating and uniting data",
    "section": "Uniting data",
    "text": "Uniting data\n\nunite(table5, new, century:year, sep = \"\", remove = FALSE)\n\n# A tibble: 6 × 5\n  country     new   century year  rate             \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 1999  19      99    745/19987071     \n2 Afghanistan 2000  20      00    2666/20595360    \n3 Brazil      1999  19      99    37737/172006362  \n4 Brazil      2000  20      00    80488/174504898  \n5 China       1999  19      99    212258/1272915272\n6 China       2000  20      00    213766/1280428583"
  },
  {
    "objectID": "slides/16_separating.html#coalescing-data",
    "href": "slides/16_separating.html#coalescing-data",
    "title": "Separating and uniting data",
    "section": "Coalescing data",
    "text": "Coalescing data\n\ncoal_data\n\n# A tibble: 4 × 3\n    a_1   a_2   a_3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    NA    NA\n2    NA     4    NA\n3    NA    NA     7\n4    NA    NA    NA\n\n\n\n\ncoal_data %&gt;% # note the use of magrittr pipe!\n  mutate(a_all = coalesce(!!! select(., contains(\"a_\"))))\n\n# A tibble: 4 × 4\n    a_1   a_2   a_3 a_all\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    NA    NA     1\n2    NA     4    NA     4\n3    NA    NA     7     7\n4    NA    NA    NA    NA"
  },
  {
    "objectID": "slides/16_separating.html#missing-data",
    "href": "slides/16_separating.html#missing-data",
    "title": "Separating and uniting data",
    "section": "Missing data",
    "text": "Missing data\n\n\n\nstocks\n\n# A tibble: 7 × 3\n   year   qtr return\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2015     1   1.88\n2  2015     2   0.59\n3  2015     3   0.35\n4  2015     4  NA   \n5  2016     2   0.92\n6  2016     3   0.17\n7  2016     4   2.66\n\n\n\nExplicitly missing (Q4 2015 is NA)\nImplicitly missing (Q1 2016 absent)\n\n\n\n\nstocks |&gt; \n  complete(year, qtr)\n\n# A tibble: 8 × 3\n   year   qtr return\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2015     1   1.88\n2  2015     2   0.59\n3  2015     3   0.35\n4  2015     4  NA   \n5  2016     1  NA   \n6  2016     2   0.92\n7  2016     3   0.17\n8  2016     4   2.66\n\n\n\n\n\n\n\n\n\n\n\nImportant for factorial designs and for data validation"
  },
  {
    "objectID": "slides/16_separating.html#combinations-of-factors",
    "href": "slides/16_separating.html#combinations-of-factors",
    "title": "Separating and uniting data",
    "section": "Combinations of factors",
    "text": "Combinations of factors\n\n\n\nfruits\n\n# A tibble: 6 × 4\n  type    year size  weights\n  &lt;chr&gt;  &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n1 apple   2010 XS       4.22\n2 orange  2010 S        4.31\n3 apple   2012 M        5.47\n4 orange  2010 S        3.65\n5 orange  2010 S        4.51\n6 orange  2012 M        5.55\n\n\n\n\n\nfruits |&gt; expand(type, size)\n\n# A tibble: 8 × 2\n  type   size \n  &lt;chr&gt;  &lt;fct&gt;\n1 apple  XS   \n2 apple  S    \n3 apple  M    \n4 apple  L    \n5 orange XS   \n6 orange S    \n7 orange M    \n8 orange L    \n\n\nreturn all possible combinations"
  },
  {
    "objectID": "slides/16_separating.html#combinations-of-factors-1",
    "href": "slides/16_separating.html#combinations-of-factors-1",
    "title": "Separating and uniting data",
    "section": "Combinations of factors",
    "text": "Combinations of factors\n\n\n\nfruits\n\n# A tibble: 6 × 4\n  type    year size  weights\n  &lt;chr&gt;  &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n1 apple   2010 XS       4.22\n2 orange  2010 S        4.31\n3 apple   2012 M        5.47\n4 orange  2010 S        3.65\n5 orange  2010 S        4.51\n6 orange  2012 M        5.55\n\n\n\n\n\nfruits |&gt; expand(nesting(type, size))\n\n# A tibble: 4 × 2\n  type   size \n  &lt;chr&gt;  &lt;fct&gt;\n1 apple  XS   \n2 apple  M    \n3 orange S    \n4 orange M    \n\n\nreturn all existing combinations"
  },
  {
    "objectID": "slides/16_separating.html#filling-data",
    "href": "slides/16_separating.html#filling-data",
    "title": "Separating and uniting data",
    "section": "Filling data",
    "text": "Filling data\n\n\n\n\ntreatment\n\n# A tibble: 4 × 3\n  person           treatment response\n  &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;\n1 Derrick Whitmore         1        7\n2 &lt;NA&gt;                     2       10\n3 &lt;NA&gt;                     3        9\n4 Katherine Burke          1        4\n\n\n\n\n\n\ntreatment |&gt; \n  fill(person)\n\n# A tibble: 4 × 3\n  person           treatment response\n  &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;\n1 Derrick Whitmore         1        7\n2 Derrick Whitmore         2       10\n3 Derrick Whitmore         3        9\n4 Katherine Burke          1        4"
  },
  {
    "objectID": "slides/16_separating.html#solving-the-problem",
    "href": "slides/16_separating.html#solving-the-problem",
    "title": "Separating and uniting data",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code turns data1 into data2?\n\n\n\ndata1\n\n# A tibble: 11 × 4\n      id cond1 cond2 date      \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;date&gt;    \n 1     1     1 A     2022-02-11\n 2     1     2 A     2022-02-20\n 3     1     3 A     2022-02-02\n 4     2     1 B     2022-01-18\n 5     2     3 B     2022-02-14\n 6     3     1 A     2022-01-09\n 7     3     2 A     2022-01-25\n 8     3     3 A     2022-02-03\n 9     4     1 B     2022-01-17\n10     4     2 B     2022-01-28\n11     4     3 B     2022-01-27\n\n\n\n\ndata2\n\n# A tibble: 12 × 5\n      id condition year  month day  \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1     1 1A        2022  02    11   \n 2     1 2A        2022  02    20   \n 3     1 3A        2022  02    02   \n 4     2 1B        2022  01    18   \n 5     2 2B        &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 6     2 3B        2022  02    14   \n 7     3 1A        2022  01    09   \n 8     3 2A        2022  01    25   \n 9     3 3A        2022  02    03   \n10     4 1B        2022  01    17   \n11     4 2B        2022  01    28   \n12     4 3B        2022  01    27"
  },
  {
    "objectID": "slides/16_separating.html#lets-code",
    "href": "slides/16_separating.html#lets-code",
    "title": "Separating and uniting data",
    "section": "Let’s code!",
    "text": "Let’s code!\nSeparating data [Rmd]"
  },
  {
    "objectID": "slides/18_mergingrows.html#the-problem",
    "href": "slides/18_mergingrows.html#the-problem",
    "title": "Merging rows",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat is needed to create data3 from data1 and data2?\n\n\n\ndata1\n\n# A tibble: 12 × 2\n      id  resp\n   &lt;int&gt; &lt;dbl&gt;\n 1     1 0.473\n 2     2 0.346\n 3     3 0.786\n 4     4 0.121\n 5     5 0.910\n 6     6 0.888\n 7     7 0.370\n 8     8 0.133\n 9     9 0.520\n10    10 0.188\n11    11 0.608\n12    12 0.190\n\n\n\n\ndata2\n\n# A tibble: 12 × 2\n      id  cond\n   &lt;int&gt; &lt;int&gt;\n 1     1     1\n 2     2     2\n 3     3     3\n 4     4     1\n 5     5     2\n 6     6     3\n 7     7     1\n 8     8     2\n 9     9     3\n10    10     1\n11    11     2\n12    12     3\n\n\n\n\ndata3\n\n# A tibble: 4 × 2\n     id  resp\n  &lt;int&gt; &lt;dbl&gt;\n1     1 0.473\n2     4 0.121\n3     7 0.370\n4    10 0.188"
  },
  {
    "objectID": "slides/18_mergingrows.html#set-up",
    "href": "slides/18_mergingrows.html#set-up",
    "title": "Merging rows",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(dplyr)\nlibrary(nycflights13)\n(flights2 &lt;- select(flights, year:dep_time, carrier, tailnum))\n\n# A tibble: 336,776 × 6\n    year month   day dep_time carrier tailnum\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013     1     1      517 UA      N14228 \n 2  2013     1     1      533 UA      N24211 \n 3  2013     1     1      542 AA      N619AA \n 4  2013     1     1      544 B6      N804JB \n 5  2013     1     1      554 DL      N668DN \n 6  2013     1     1      554 UA      N39463 \n 7  2013     1     1      555 B6      N516JB \n 8  2013     1     1      557 EV      N829AS \n 9  2013     1     1      557 B6      N593JB \n10  2013     1     1      558 AA      N3ALAA \n# ℹ 336,766 more rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#set-up-1",
    "href": "slides/18_mergingrows.html#set-up-1",
    "title": "Merging rows",
    "section": "Set-up",
    "text": "Set-up\n\nset.seed(1)\n(airlines2 &lt;- slice_sample(airlines, prop = 0.5))\n\n# A tibble: 8 × 2\n  carrier name                  \n  &lt;chr&gt;   &lt;chr&gt;                 \n1 HA      Hawaiian Airlines Inc.\n2 B6      JetBlue Airways       \n3 F9      Frontier Airlines Inc.\n4 9E      Endeavor Air Inc.     \n5 AA      American Airlines Inc.\n6 VX      Virgin America        \n7 UA      United Air Lines Inc. \n8 AS      Alaska Airlines Inc.  \n\n(airlines3 &lt;- rename(airlines2, airline = carrier))\n\n# A tibble: 8 × 2\n  airline name                  \n  &lt;chr&gt;   &lt;chr&gt;                 \n1 HA      Hawaiian Airlines Inc.\n2 B6      JetBlue Airways       \n3 F9      Frontier Airlines Inc.\n4 9E      Endeavor Air Inc.     \n5 AA      American Airlines Inc.\n6 VX      Virgin America        \n7 UA      United Air Lines Inc. \n8 AS      Alaska Airlines Inc."
  },
  {
    "objectID": "slides/18_mergingrows.html#joining-with-dplyr",
    "href": "slides/18_mergingrows.html#joining-with-dplyr",
    "title": "Merging rows",
    "section": "Joining with {dplyr}",
    "text": "Joining with {dplyr}\n\nlibrary(dplyr)\n\n\n\n\n\n\n\n\n\n\nSource: Garrick Aden-Buie"
  },
  {
    "objectID": "slides/18_mergingrows.html#filtering-joins-1",
    "href": "slides/18_mergingrows.html#filtering-joins-1",
    "title": "Merging rows",
    "section": "Filtering joins",
    "text": "Filtering joins\nAffect rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#semi-joins",
    "href": "slides/18_mergingrows.html#semi-joins",
    "title": "Merging rows",
    "section": "Semi joins",
    "text": "Semi joins\nKeep only matching observations\n\n\n\nWhen is this useful?"
  },
  {
    "objectID": "slides/18_mergingrows.html#semi-joins-1",
    "href": "slides/18_mergingrows.html#semi-joins-1",
    "title": "Merging rows",
    "section": "Semi joins",
    "text": "Semi joins\n\n\n\n\nx\n\n# A tibble: 3 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n    key val_y\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 y1   \n2     2 y2   \n3     4 y3   \n\n\n\n\nsemi_join(x, y, by = \"key\")\n\n# A tibble: 2 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2"
  },
  {
    "objectID": "slides/18_mergingrows.html#semi-joins-2",
    "href": "slides/18_mergingrows.html#semi-joins-2",
    "title": "Merging rows",
    "section": "Semi joins",
    "text": "Semi joins\n\nairlines2\n\n# A tibble: 8 × 2\n  carrier name                  \n  &lt;chr&gt;   &lt;chr&gt;                 \n1 HA      Hawaiian Airlines Inc.\n2 B6      JetBlue Airways       \n3 F9      Frontier Airlines Inc.\n4 9E      Endeavor Air Inc.     \n5 AA      American Airlines Inc.\n6 VX      Virgin America        \n7 UA      United Air Lines Inc. \n8 AS      Alaska Airlines Inc."
  },
  {
    "objectID": "slides/18_mergingrows.html#semi-joins-3",
    "href": "slides/18_mergingrows.html#semi-joins-3",
    "title": "Merging rows",
    "section": "Semi joins",
    "text": "Semi joins\n\nflights2 |&gt;\n  semi_join(airlines2, by = \"carrier\")\n\n# A tibble: 171,392 × 6\n    year month   day dep_time carrier tailnum\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013     1     1      517 UA      N14228 \n 2  2013     1     1      533 UA      N24211 \n 3  2013     1     1      542 AA      N619AA \n 4  2013     1     1      544 B6      N804JB \n 5  2013     1     1      554 UA      N39463 \n 6  2013     1     1      555 B6      N516JB \n 7  2013     1     1      557 B6      N593JB \n 8  2013     1     1      558 AA      N3ALAA \n 9  2013     1     1      558 B6      N793JB \n10  2013     1     1      558 B6      N657JB \n# ℹ 171,382 more rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#anti-joins",
    "href": "slides/18_mergingrows.html#anti-joins",
    "title": "Merging rows",
    "section": "Anti joins",
    "text": "Anti joins\nKeep only non-matching observations\n\n\n\nWhen is this useful?"
  },
  {
    "objectID": "slides/18_mergingrows.html#anti-joins-1",
    "href": "slides/18_mergingrows.html#anti-joins-1",
    "title": "Merging rows",
    "section": "Anti joins",
    "text": "Anti joins\n\n\n\n\nx\n\n# A tibble: 3 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n    key val_y\n  &lt;dbl&gt; &lt;chr&gt;\n1     1 y1   \n2     2 y2   \n3     4 y3   \n\n\n\n\nanti_join(x, y, by = \"key\")\n\n# A tibble: 1 × 2\n    key val_x\n  &lt;dbl&gt; &lt;chr&gt;\n1     3 x3"
  },
  {
    "objectID": "slides/18_mergingrows.html#anti-joins-2",
    "href": "slides/18_mergingrows.html#anti-joins-2",
    "title": "Merging rows",
    "section": "Anti joins",
    "text": "Anti joins\n\nflights2 |&gt;\n  anti_join(airlines2, by = \"carrier\")\n\n# A tibble: 165,384 × 6\n    year month   day dep_time carrier tailnum\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013     1     1      554 DL      N668DN \n 2  2013     1     1      557 EV      N829AS \n 3  2013     1     1      600 MQ      N542MQ \n 4  2013     1     1      602 DL      N971DL \n 5  2013     1     1      602 MQ      N730MQ \n 6  2013     1     1      606 DL      N3739P \n 7  2013     1     1      608 MQ      N9EAMQ \n 8  2013     1     1      615 DL      N326NB \n 9  2013     1     1      622 US      N807AW \n10  2013     1     1      624 EV      N11107 \n# ℹ 165,374 more rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#joining-with-different-key-names",
    "href": "slides/18_mergingrows.html#joining-with-different-key-names",
    "title": "Merging rows",
    "section": "Joining with different key names",
    "text": "Joining with different key names\n\n\n\n\nflights2\n\n# A tibble: 336,776 × 6\n    year month   day dep_time carrier tailnum\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013     1     1      517 UA      N14228 \n 2  2013     1     1      533 UA      N24211 \n 3  2013     1     1      542 AA      N619AA \n 4  2013     1     1      544 B6      N804JB \n 5  2013     1     1      554 DL      N668DN \n 6  2013     1     1      554 UA      N39463 \n 7  2013     1     1      555 B6      N516JB \n 8  2013     1     1      557 EV      N829AS \n 9  2013     1     1      557 B6      N593JB \n10  2013     1     1      558 AA      N3ALAA \n# ℹ 336,766 more rows\n\n\n\n\n\n\nairlines3\n\n# A tibble: 8 × 2\n  airline name                  \n  &lt;chr&gt;   &lt;chr&gt;                 \n1 HA      Hawaiian Airlines Inc.\n2 B6      JetBlue Airways       \n3 F9      Frontier Airlines Inc.\n4 9E      Endeavor Air Inc.     \n5 AA      American Airlines Inc.\n6 VX      Virgin America        \n7 UA      United Air Lines Inc. \n8 AS      Alaska Airlines Inc."
  },
  {
    "objectID": "slides/18_mergingrows.html#joining-with-different-key-names-1",
    "href": "slides/18_mergingrows.html#joining-with-different-key-names-1",
    "title": "Merging rows",
    "section": "Joining with different key names",
    "text": "Joining with different key names\n\nflights2 |&gt;\n  anti_join(airlines3, by = join_by(carrier == airline))\n\n# A tibble: 165,384 × 6\n    year month   day dep_time carrier tailnum\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013     1     1      554 DL      N668DN \n 2  2013     1     1      557 EV      N829AS \n 3  2013     1     1      600 MQ      N542MQ \n 4  2013     1     1      602 DL      N971DL \n 5  2013     1     1      602 MQ      N730MQ \n 6  2013     1     1      606 DL      N3739P \n 7  2013     1     1      608 MQ      N9EAMQ \n 8  2013     1     1      615 DL      N326NB \n 9  2013     1     1      622 US      N807AW \n10  2013     1     1      624 EV      N11107 \n# ℹ 165,374 more rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#adding-rows",
    "href": "slides/18_mergingrows.html#adding-rows",
    "title": "Merging rows",
    "section": "Adding rows",
    "text": "Adding rows\ntibble::add_row()\n\n\n\n(df &lt;- tibble(x = 1:3, y = 3:1))\n\n# A tibble: 3 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     3\n2     2     2\n3     3     1\n\n\n\ndf %&gt;% add_row(x = 4, y = 0)\n\n# A tibble: 4 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     3\n2     2     2\n3     3     1\n4     4     0\n\n\n\n\n\ndf %&gt;% add_row(x = 4, y = 0, \n               .before = 2)\n\n# A tibble: 4 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     3\n2     4     0\n3     2     2\n4     3     1\n\n\n\ndf %&gt;% add_row(x = 4:5, y = 0:-1)\n\n# A tibble: 5 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     3\n2     2     2\n3     3     1\n4     4     0\n5     5    -1"
  },
  {
    "objectID": "slides/18_mergingrows.html#add-rows",
    "href": "slides/18_mergingrows.html#add-rows",
    "title": "Merging rows",
    "section": "Add rows",
    "text": "Add rows\ndplyr::bind_rows()\n\n\n\n(df2 &lt;- tibble(x = 4:5, y = 5:4))\n\n# A tibble: 2 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     4     5\n2     5     4\n\n\n\nbind_rows(df, df2)\n\n# A tibble: 5 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     3\n2     2     2\n3     3     1\n4     4     5\n5     5     4\n\n\n\n\n\n(df3 &lt;- tibble(x = 6:7, y = 7:6, \n              z = c(\"A\", \"B\")))\n\n# A tibble: 2 × 3\n      x     y z    \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1     6     7 A    \n2     7     6 B    \n\n\n\nbind_rows(df, df3)\n\n# A tibble: 5 × 3\n      x     y z    \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1     1     3 &lt;NA&gt; \n2     2     2 &lt;NA&gt; \n3     3     1 &lt;NA&gt; \n4     6     7 A    \n5     7     6 B"
  },
  {
    "objectID": "slides/18_mergingrows.html#add-columns",
    "href": "slides/18_mergingrows.html#add-columns",
    "title": "Merging rows",
    "section": "Add columns",
    "text": "Add columns\ndplyr::bind_cols()\n\n\n\n(df4 &lt;- tibble(z = c(\"A\", \"B\" , \"C\"), \n              zz = c(\"Z\", \"Y\", \"X\")))\n\n# A tibble: 3 × 2\n  z     zz   \n  &lt;chr&gt; &lt;chr&gt;\n1 A     Z    \n2 B     Y    \n3 C     X    \n\n\n\nbind_cols(df, df4)\n\n# A tibble: 3 × 4\n      x     y z     zz   \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1     1     3 A     Z    \n2     2     2 B     Y    \n3     3     1 C     X    \n\n\n\n\nbind_cols(df, new_col = df4$z)\n\n# A tibble: 3 × 3\n      x     y new_col\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;  \n1     1     3 A      \n2     2     2 B      \n3     3     1 C      \n\n\n\n\nBut why is this dangerous? What is a better solution?"
  },
  {
    "objectID": "slides/18_mergingrows.html#set-operations-1",
    "href": "slides/18_mergingrows.html#set-operations-1",
    "title": "Merging rows",
    "section": "Set operations",
    "text": "Set operations\nFor finding overlap, differences, and combinations of datasets"
  },
  {
    "objectID": "slides/18_mergingrows.html#intersect",
    "href": "slides/18_mergingrows.html#intersect",
    "title": "Merging rows",
    "section": "Intersect",
    "text": "Intersect\nCommon rows in both x and y, keeping just unique rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#set-difference",
    "href": "slides/18_mergingrows.html#set-difference",
    "title": "Merging rows",
    "section": "Set difference",
    "text": "Set difference\nAll rows from x which are not also rows in y, keeping just unique rows"
  },
  {
    "objectID": "slides/18_mergingrows.html#union",
    "href": "slides/18_mergingrows.html#union",
    "title": "Merging rows",
    "section": "Union",
    "text": "Union\nAll unique rows from x and y"
  },
  {
    "objectID": "slides/18_mergingrows.html#union-all",
    "href": "slides/18_mergingrows.html#union-all",
    "title": "Merging rows",
    "section": "Union all",
    "text": "Union all\nAll rows from x and y, keeping duplicates"
  },
  {
    "objectID": "slides/18_mergingrows.html#sql",
    "href": "slides/18_mergingrows.html#sql",
    "title": "Merging rows",
    "section": "SQL",
    "text": "SQL\nCongratulations—you just learned SQL databases!"
  },
  {
    "objectID": "slides/18_mergingrows.html#solving-the-problem",
    "href": "slides/18_mergingrows.html#solving-the-problem",
    "title": "Merging rows",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code combines data1 and data2 into data3?\n\n\n\ndata1\n\n# A tibble: 12 × 2\n      id  resp\n   &lt;int&gt; &lt;dbl&gt;\n 1     1 0.473\n 2     2 0.346\n 3     3 0.786\n 4     4 0.121\n 5     5 0.910\n 6     6 0.888\n 7     7 0.370\n 8     8 0.133\n 9     9 0.520\n10    10 0.188\n11    11 0.608\n12    12 0.190\n\n\n\n\ndata2\n\n# A tibble: 12 × 2\n      id  cond\n   &lt;int&gt; &lt;int&gt;\n 1     1     1\n 2     2     2\n 3     3     3\n 4     4     1\n 5     5     2\n 6     6     3\n 7     7     1\n 8     8     2\n 9     9     3\n10    10     1\n11    11     2\n12    12     3\n\n\n\n\ndata3\n\n# A tibble: 4 × 2\n     id  resp\n  &lt;int&gt; &lt;dbl&gt;\n1     1 0.473\n2     4 0.121\n3     7 0.370\n4    10 0.188"
  },
  {
    "objectID": "slides/18_mergingrows.html#lets-code",
    "href": "slides/18_mergingrows.html#lets-code",
    "title": "Merging rows",
    "section": "Let’s code!",
    "text": "Let’s code!\nMerging rows [Rmd]"
  },
  {
    "objectID": "slides/20_strings.html#the-problem",
    "href": "slides/20_strings.html#the-problem",
    "title": "Strings",
    "section": "The problem",
    "text": "The problem\nWhat’s different between these data sets?\nWhat is needed to create data2 from data1?\n\n\n\ndata1\n\n# A tibble: 12 × 3\n      id cond  resp \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1     1 cond1 yes  \n 2     2 cond2 no   \n 3     3 cond1 yes  \n 4     4 cond2 yes  \n 5     5 cond1 no   \n 6     6 cond2 yes  \n 7     7 cond1 yes  \n 8     8 cond2 no   \n 9     9 cond1 no   \n10    10 cond2 no   \n11    11 cond1 yes  \n12    12 cond2 yes  \n\n\n\n\ndata2\n\n# A tibble: 12 × 4\n      id cond  resp  output                           \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;glue&gt;                           \n 1     1 1     Yes   1 had condition 1 and said \"Yes\" \n 2     2 2     No    2 had condition 2 and said \"No\"  \n 3     3 1     Yes   3 had condition 1 and said \"Yes\" \n 4     4 2     Yes   4 had condition 2 and said \"Yes\" \n 5     5 1     No    5 had condition 1 and said \"No\"  \n 6     6 2     Yes   6 had condition 2 and said \"Yes\" \n 7     7 1     Yes   7 had condition 1 and said \"Yes\" \n 8     8 2     No    8 had condition 2 and said \"No\"  \n 9     9 1     No    9 had condition 1 and said \"No\"  \n10    10 2     No    10 had condition 2 and said \"No\" \n11    11 1     Yes   11 had condition 1 and said \"Yes\"\n12    12 2     Yes   12 had condition 2 and said \"Yes\""
  },
  {
    "objectID": "slides/20_strings.html#set-up",
    "href": "slides/20_strings.html#set-up",
    "title": "Strings",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/20_strings.html#mental-model",
    "href": "slides/20_strings.html#mental-model",
    "title": "Strings",
    "section": "Mental model",
    "text": "Mental model"
  },
  {
    "objectID": "slides/20_strings.html#useful-character-vectors",
    "href": "slides/20_strings.html#useful-character-vectors",
    "title": "Strings",
    "section": "Useful character vectors",
    "text": "Useful character vectors\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nLETTERS\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nmonth.name\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nmonth.abb\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\""
  },
  {
    "objectID": "slides/20_strings.html#quotes",
    "href": "slides/20_strings.html#quotes",
    "title": "Strings",
    "section": "Quotes",
    "text": "Quotes\nCreate strings with either single quotes or double quotes\n\n(string1 &lt;- \"This is a string\")\n\n[1] \"This is a string\"\n\nwriteLines(string1)\n\nThis is a string\n\n(string2 &lt;- 'So is this.')\n\n[1] \"So is this.\"\n\nwriteLines(string2)\n\nSo is this."
  },
  {
    "objectID": "slides/20_strings.html#quotes-1",
    "href": "slides/20_strings.html#quotes-1",
    "title": "Strings",
    "section": "Quotes",
    "text": "Quotes\nIncluding quotes in strings\n\n(string3 &lt;- 'If I want to include a \"double quote\" inside a string, I use single quotes')\n\n[1] \"If I want to include a \\\"double quote\\\" inside a string, I use single quotes\"\n\nwriteLines(string3)\n\nIf I want to include a \"double quote\" inside a string, I use single quotes\n\n(string4 &lt;- \"And 'vice versa'\")\n\n[1] \"And 'vice versa'\"\n\nwriteLines(string4)\n\nAnd 'vice versa'"
  },
  {
    "objectID": "slides/20_strings.html#escaping-quotes",
    "href": "slides/20_strings.html#escaping-quotes",
    "title": "Strings",
    "section": "Escaping quotes",
    "text": "Escaping quotes\nOr use \\ to “escape” it\n\ndouble_quote &lt;- \"\\\"\"\nwriteLines(double_quote)\n\n\"\n\nsingle_quote &lt;- '\\''\nwriteLines(single_quote)\n\n'"
  },
  {
    "objectID": "slides/20_strings.html#escaping-quotes-1",
    "href": "slides/20_strings.html#escaping-quotes-1",
    "title": "Strings",
    "section": "Escaping quotes",
    "text": "Escaping quotes\nBecause \\ escapes, you can’t just wrap it in quotes\nIf you want an actual backslash printed, you need two \\\\\n\nbackslash &lt;- \"\\\\\"\nwriteLines(backslash)\n\n\\"
  },
  {
    "objectID": "slides/20_strings.html#strings-with-stringr",
    "href": "slides/20_strings.html#strings-with-stringr",
    "title": "Strings",
    "section": "Strings with {stringr}",
    "text": "Strings with {stringr}\n\nlibrary(stringr)\n\n\n\n\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/20_strings.html#string-length",
    "href": "slides/20_strings.html#string-length",
    "title": "Strings",
    "section": "String length",
    "text": "String length\nReturn number of characters in a string with stringr::str_length()\n\n(r4ds_string &lt;- c(\"a\", \"R for data science\", NA))\n\n[1] \"a\"                  \"R for data science\" NA                  \n\nstr_length(r4ds_string)  # nchar() in base R\n\n[1]  1 18 NA\n\n# This differs from length...\nlength(r4ds_string)\n\n[1] 3"
  },
  {
    "objectID": "slides/20_strings.html#extracting-strings",
    "href": "slides/20_strings.html#extracting-strings",
    "title": "Strings",
    "section": "Extracting strings",
    "text": "Extracting strings\nExtract parts of a string based on position with stringr::str_sub()\n\nx &lt;- c(\"apple\", \"banana\", \"pear\")\nstr_sub(x, 1, 3)  # substr() in base R\n\n[1] \"app\" \"ban\" \"pea\"\n\n# Negative numbers count backwards from end\nstr_sub(x, -3, -1)\n\n[1] \"ple\" \"ana\" \"ear\""
  },
  {
    "objectID": "slides/20_strings.html#extracting-strings-1",
    "href": "slides/20_strings.html#extracting-strings-1",
    "title": "Strings",
    "section": "Extracting strings",
    "text": "Extracting strings\nUseful when you don’t have delimiters. But use delimiters!\n\npenguins |&gt;\n  mutate(species = str_sub(species, 1, 1),\n         island = str_sub(island, 1, 3),\n         year = str_sub(year, -2, -1), .keep = \"used\")\n\n# A tibble: 344 × 3\n   species island year \n   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n 1 A       Tor    07   \n 2 A       Tor    07   \n 3 A       Tor    07   \n 4 A       Tor    07   \n 5 A       Tor    07   \n 6 A       Tor    07   \n 7 A       Tor    07   \n 8 A       Tor    07   \n 9 A       Tor    07   \n10 A       Tor    07   \n# ℹ 334 more rows"
  },
  {
    "objectID": "slides/20_strings.html#extracting-strings-2",
    "href": "slides/20_strings.html#extracting-strings-2",
    "title": "Strings",
    "section": "Extracting strings",
    "text": "Extracting strings\nAlso can substitute characters based on position\n\nx\n\n[1] \"apple\"  \"banana\" \"pear\"  \n\nstr_sub(x, 1, 1) &lt;- \"#\"  # replace first character\nx\n\n[1] \"#pple\"  \"#anana\" \"#ear\"  \n\nstr_sub(x, -1, -1) &lt;- \"*\"  # replace last character\nx\n\n[1] \"#ppl*\"  \"#anan*\" \"#ea*\"  \n\nstr_sub(x, 0, 0) &lt;- \"~\"  # add before first character\nx\n\n[1] \"~#ppl*\"  \"~#anan*\" \"~#ea*\""
  },
  {
    "objectID": "slides/20_strings.html#changing-case",
    "href": "slides/20_strings.html#changing-case",
    "title": "Strings",
    "section": "Changing case",
    "text": "Changing case\nControl capitalization with stringr::str_to_lower() and stringr::str_to_upper()\n\n(y &lt;- \"hello, World\")\n\n[1] \"hello, World\"\n\nstr_to_lower(y)  # tolower() in base R\n\n[1] \"hello, world\"\n\nstr_to_upper(y)  # toupper() in base R\n\n[1] \"HELLO, WORLD\""
  },
  {
    "objectID": "slides/20_strings.html#changing-case-1",
    "href": "slides/20_strings.html#changing-case-1",
    "title": "Strings",
    "section": "Changing case",
    "text": "Changing case\nPlus super useful stringr::str_to_title() and stringr::str_to_sentence()\n\nstr_to_title(y)\n\n[1] \"Hello, World\"\n\nstr_to_sentence(y)\n\n[1] \"Hello, world\""
  },
  {
    "objectID": "slides/20_strings.html#changing-case-2",
    "href": "slides/20_strings.html#changing-case-2",
    "title": "Strings",
    "section": "Changing case",
    "text": "Changing case\nUseful for column names\n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\nstr_to_lower(names(iris))\n\n[1] \"sepal.length\" \"sepal.width\"  \"petal.length\" \"petal.width\"  \"species\""
  },
  {
    "objectID": "slides/20_strings.html#changing-case-3",
    "href": "slides/20_strings.html#changing-case-3",
    "title": "Strings",
    "section": "Changing case",
    "text": "Changing case\nOr to change case of column entries\n\npenguins |&gt;\n  mutate(sex_upper = str_to_sentence(sex), .keep = \"used\")\n\n# A tibble: 344 × 2\n   sex    sex_upper\n   &lt;fct&gt;  &lt;chr&gt;    \n 1 male   Male     \n 2 female Female   \n 3 female Female   \n 4 &lt;NA&gt;   &lt;NA&gt;     \n 5 female Female   \n 6 male   Male     \n 7 female Female   \n 8 male   Male     \n 9 &lt;NA&gt;   &lt;NA&gt;     \n10 &lt;NA&gt;   &lt;NA&gt;     \n# ℹ 334 more rows\n\n\nBut notice what happened to data type"
  },
  {
    "objectID": "slides/20_strings.html#combining-strings-1",
    "href": "slides/20_strings.html#combining-strings-1",
    "title": "Strings",
    "section": "Combining strings",
    "text": "Combining strings\nCombine multiple strings into a single string with stringr::str_c():\n\nc(\"x\", \"y\", \"z\")\n\n[1] \"x\" \"y\" \"z\"\n\nstr_c(\"x\", \"y\", \"z\")\n\n[1] \"xyz\"\n\nstr_c(\"x\", \"y\", \"z\", sep = \", \")\n\n[1] \"x, y, z\""
  },
  {
    "objectID": "slides/20_strings.html#collapsing-strings",
    "href": "slides/20_strings.html#collapsing-strings",
    "title": "Strings",
    "section": "Collapsing strings",
    "text": "Collapsing strings\nCollapse a vector of strings into a single string with collapse argument\n\nstr_c(c(\"x\", \"y\", \"z\"), collapse = \", \")\n\n[1] \"x, y, z\"\n\n\n\nHow is this different from using sep argument?\n\nstr_c(\"x\", \"y\", \"z\", sep = \", \")\n\n[1] \"x, y, z\""
  },
  {
    "objectID": "slides/20_strings.html#collapsing-strings-1",
    "href": "slides/20_strings.html#collapsing-strings-1",
    "title": "Strings",
    "section": "Collapsing strings",
    "text": "Collapsing strings\nWhen would this be useful?\n\nstr_c(month.name, collapse = \", \")\n\n[1] \"January, February, March, April, May, June, July, August, September, October, November, December\"\n\nunique(penguins$species)\n\n[1] Adelie    Gentoo    Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\nstr_c(sort(unique(penguins$species)), collapse = \", \")\n\n[1] \"Adelie, Chinstrap, Gentoo\""
  },
  {
    "objectID": "slides/20_strings.html#combining-strings-with-output",
    "href": "slides/20_strings.html#combining-strings-with-output",
    "title": "Strings",
    "section": "Combining strings with output",
    "text": "Combining strings with output\nPasting character vectors with base R paste()\n\nname &lt;- \"Fred\"\nage &lt;- 50\npaste(\"My name is\", name, \", and my age next year is\", age + 1, \".\")\n\n[1] \"My name is Fred , and my age next year is 51 .\"\n\npaste0(\"My name is\", name, \", and my age next year is\", age + 1, \".\")\n\n[1] \"My name isFred, and my age next year is51.\"\n\npaste0(\"My name is \", name, \", and my age next year is \", age + 1, \".\")\n\n[1] \"My name is Fred, and my age next year is 51.\"\n\npaste(\"My name is \", name, \", and my age next year is \", age + 1, \".\", sep = \"\")\n\n[1] \"My name is Fred, and my age next year is 51.\""
  },
  {
    "objectID": "slides/20_strings.html#combining-strings-with-output-1",
    "href": "slides/20_strings.html#combining-strings-with-output-1",
    "title": "Strings",
    "section": "Combining strings with output",
    "text": "Combining strings with output\nGluing character vectors with stringr::str_glue()\n\nstr_glue(\"My name is {name}, and my age next year is {age + 1}.\")\n\nMy name is Fred, and my age next year is 51.\n\nstr_glue(\"My name is {name}, and my age next year is {age + 1}.\", \n         name = \"Jane\", age = 40)\n\nMy name is Jane, and my age next year is 41."
  },
  {
    "objectID": "slides/20_strings.html#combining-strings-with-output-2",
    "href": "slides/20_strings.html#combining-strings-with-output-2",
    "title": "Strings",
    "section": "Combining strings with output",
    "text": "Combining strings with output\nApply to each row of a data frame\n\npenguins |&gt;\n  mutate(full_island = str_glue(\"{island} Island\")) |&gt; \n  arrange(bill_length_mm) |&gt; \n  select(species, island, full_island)\n\n# A tibble: 344 × 3\n   species island    full_island     \n   &lt;fct&gt;   &lt;fct&gt;     &lt;glue&gt;          \n 1 Adelie  Dream     Dream Island    \n 2 Adelie  Dream     Dream Island    \n 3 Adelie  Torgersen Torgersen Island\n 4 Adelie  Dream     Dream Island    \n 5 Adelie  Torgersen Torgersen Island\n 6 Adelie  Torgersen Torgersen Island\n 7 Adelie  Biscoe    Biscoe Island   \n 8 Adelie  Torgersen Torgersen Island\n 9 Adelie  Torgersen Torgersen Island\n10 Adelie  Biscoe    Biscoe Island   \n# ℹ 334 more rows"
  },
  {
    "objectID": "slides/20_strings.html#cheatsheet",
    "href": "slides/20_strings.html#cheatsheet",
    "title": "Strings",
    "section": "Cheatsheet",
    "text": "Cheatsheet"
  },
  {
    "objectID": "slides/20_strings.html#solving-the-problem",
    "href": "slides/20_strings.html#solving-the-problem",
    "title": "Strings",
    "section": "Solving the problem",
    "text": "Solving the problem\n\n\n\ndata1\n\n# A tibble: 12 × 3\n      id cond  resp \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1     1 cond1 yes  \n 2     2 cond2 no   \n 3     3 cond1 yes  \n 4     4 cond2 yes  \n 5     5 cond1 no   \n 6     6 cond2 yes  \n 7     7 cond1 yes  \n 8     8 cond2 no   \n 9     9 cond1 no   \n10    10 cond2 no   \n11    11 cond1 yes  \n12    12 cond2 yes  \n\n\n\n\ndata2\n\n# A tibble: 12 × 4\n      id cond  resp  output                           \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;glue&gt;                           \n 1     1 1     Yes   1 had condition 1 and said \"Yes\" \n 2     2 2     No    2 had condition 2 and said \"No\"  \n 3     3 1     Yes   3 had condition 1 and said \"Yes\" \n 4     4 2     Yes   4 had condition 2 and said \"Yes\" \n 5     5 1     No    5 had condition 1 and said \"No\"  \n 6     6 2     Yes   6 had condition 2 and said \"Yes\" \n 7     7 1     Yes   7 had condition 1 and said \"Yes\" \n 8     8 2     No    8 had condition 2 and said \"No\"  \n 9     9 1     No    9 had condition 1 and said \"No\"  \n10    10 2     No    10 had condition 2 and said \"No\" \n11    11 1     Yes   11 had condition 1 and said \"Yes\"\n12    12 2     Yes   12 had condition 2 and said \"Yes\""
  },
  {
    "objectID": "slides/20_strings.html#lets-code",
    "href": "slides/20_strings.html#lets-code",
    "title": "Strings",
    "section": "Let’s code!",
    "text": "Let’s code!\nStrings [Rmd]"
  },
  {
    "objectID": "slides/22_factors.html#the-problem",
    "href": "slides/22_factors.html#the-problem",
    "title": "Factors",
    "section": "The problem",
    "text": "The problem\nWhat is needed to create data2 from data1?\n\n\n\ndata1\n\n# A tibble: 8 × 2\n  species      n\n  &lt;chr&gt;    &lt;int&gt;\n1 Droid        6\n2 Gungan       3\n3 Human       35\n4 Kaminoan     2\n5 Mirialan     2\n6 Twi'lek      2\n7 Wookiee      2\n8 Zabrak       2\n\n\n\n\ndata2\n\n# A tibble: 4 × 2\n  species     n\n  &lt;fct&gt;   &lt;int&gt;\n1 Human      35\n2 Other      10\n3 Android     6\n4 Gungan      3"
  },
  {
    "objectID": "slides/22_factors.html#factors",
    "href": "slides/22_factors.html#factors",
    "title": "Factors",
    "section": "Factors",
    "text": "Factors\nCategorical variables represented by augmented integers\n\n(x1 &lt;- c(\"Apr\", \"Jun\", \"Oct\", \"Jan\"))\n\n[1] \"Apr\" \"Jun\" \"Oct\" \"Jan\"\n\nmonth.abb\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\n(y1 &lt;- factor(x1))\n\n[1] Apr Jun Oct Jan\nLevels: Apr Jan Jun Oct\n\n\n\n\nclass(y1)\n\n[1] \"factor\"\n\ntypeof(y1)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/22_factors.html#mental-model",
    "href": "slides/22_factors.html#mental-model",
    "title": "Factors",
    "section": "Mental model",
    "text": "Mental model"
  },
  {
    "objectID": "slides/22_factors.html#viewset-factor-levels",
    "href": "slides/22_factors.html#viewset-factor-levels",
    "title": "Factors",
    "section": "View/set factor levels",
    "text": "View/set factor levels\nlevels()\n\ny1\n\n[1] Apr Jun Oct Jan\nLevels: Apr Jan Jun Oct\n\nlevels(y1)\n\n[1] \"Apr\" \"Jan\" \"Jun\" \"Oct\"\n\n\n\n\n(y2 &lt;- factor(x1, levels = month.abb))\n\n[1] Apr Jun Oct Jan\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nlevels(y2)\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\""
  },
  {
    "objectID": "slides/22_factors.html#label-factors",
    "href": "slides/22_factors.html#label-factors",
    "title": "Factors",
    "section": "Label factors",
    "text": "Label factors\nlabels argument\n\n(y3 &lt;- factor(y1, labels = c(\"April\", \"January\", \"June\", \"October\")))\n\n[1] April   June    October January\nLevels: April January June October\n\n\n\n\n\n\n\n\nNote\n\n\nNote you have to label them in the order they appear as levels."
  },
  {
    "objectID": "slides/22_factors.html#factors-with-forcats",
    "href": "slides/22_factors.html#factors-with-forcats",
    "title": "Factors",
    "section": "Factors with {forcats}",
    "text": "Factors with {forcats}\n\nlibrary(forcats)"
  },
  {
    "objectID": "slides/22_factors.html#data-set",
    "href": "slides/22_factors.html#data-set",
    "title": "Factors",
    "section": "Data set",
    "text": "Data set\n\n\ngss_cat\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows"
  },
  {
    "objectID": "slides/22_factors.html#check-level-order",
    "href": "slides/22_factors.html#check-level-order",
    "title": "Factors",
    "section": "Check level order",
    "text": "Check level order\n\nlevels(y1)\n\n[1] \"Apr\" \"Jan\" \"Jun\" \"Oct\"\n\n\n\n\n\n\n\n\nNote\n\n\nBy default, level elements are sorted alphabetically."
  },
  {
    "objectID": "slides/22_factors.html#check-level-order-with-pipes",
    "href": "slides/22_factors.html#check-level-order-with-pipes",
    "title": "Factors",
    "section": "Check level order with pipes",
    "text": "Check level order with pipes\n\nmarital &lt;- gss_cat |&gt;\n  pull(marital)\nmarital |&gt; levels()\n\n[1] \"No answer\"     \"Never married\" \"Separated\"     \"Divorced\"     \n[5] \"Widowed\"       \"Married\"      \n\n\n\n\n\n\n\n\nNote\n\n\nHere, order was determined already."
  },
  {
    "objectID": "slides/22_factors.html#reordering-levels",
    "href": "slides/22_factors.html#reordering-levels",
    "title": "Factors",
    "section": "Reordering levels",
    "text": "Reordering levels\nIn the order present in the data with fct_inorder()\n\nhead(marital, 20)\n\n [1] Never married Divorced      Widowed       Never married Divorced     \n [6] Married       Never married Divorced      Married       Married      \n[11] Married       Married       Married       Married       Divorced     \n[16] Married       Widowed       Never married Married       Married      \nLevels: No answer Never married Separated Divorced Widowed Married\n\n\n\n\nmarital |&gt; fct_inorder() |&gt;\n  levels()\n\n[1] \"Never married\" \"Divorced\"      \"Widowed\"       \"Married\"      \n[5] \"Separated\"     \"No answer\""
  },
  {
    "objectID": "slides/22_factors.html#reordering-levels-1",
    "href": "slides/22_factors.html#reordering-levels-1",
    "title": "Factors",
    "section": "Reordering levels",
    "text": "Reordering levels\nIn the order based on number of observations of each level with fct_infreq()\n\ngss_cat |&gt;\n  count(marital, sort = TRUE)\n\n# A tibble: 6 × 2\n  marital           n\n  &lt;fct&gt;         &lt;int&gt;\n1 Married       10117\n2 Never married  5416\n3 Divorced       3383\n4 Widowed        1807\n5 Separated       743\n6 No answer        17\n\n\n\n\nmarital |&gt; fct_infreq() |&gt;\n  levels()\n\n[1] \"Married\"       \"Never married\" \"Divorced\"      \"Widowed\"      \n[5] \"Separated\"     \"No answer\""
  },
  {
    "objectID": "slides/22_factors.html#reordering-levels-2",
    "href": "slides/22_factors.html#reordering-levels-2",
    "title": "Factors",
    "section": "Reordering levels",
    "text": "Reordering levels\nIn reverse order of factor levels with fct_rev()\n\nlevels(marital)\n\n[1] \"No answer\"     \"Never married\" \"Separated\"     \"Divorced\"     \n[5] \"Widowed\"       \"Married\"      \n\nmarital |&gt; fct_rev() |&gt;\n  levels()\n\n[1] \"Married\"       \"Widowed\"       \"Divorced\"      \"Separated\"    \n[5] \"Never married\" \"No answer\""
  },
  {
    "objectID": "slides/22_factors.html#manually-reorder-factor-levels",
    "href": "slides/22_factors.html#manually-reorder-factor-levels",
    "title": "Factors",
    "section": "Manually reorder factor levels",
    "text": "Manually reorder factor levels\nfct_relevel()\n\n(relig_summary &lt;- gss_cat |&gt;\n    group_by(relig) |&gt;\n    summarise(\n      tvhours = mean(tvhours, na.rm = TRUE),\n      n = n()))\n\n# A tibble: 15 × 3\n   relig                   tvhours     n\n   &lt;fct&gt;                     &lt;dbl&gt; &lt;int&gt;\n 1 No answer                  2.72    93\n 2 Don't know                 4.62    15\n 3 Inter-nondenominational    2.87   109\n 4 Native american            3.46    23\n 5 Christian                  2.79   689\n 6 Orthodox-christian         2.42    95\n 7 Moslem/islam               2.44   104\n 8 Other eastern              1.67    32\n 9 Hinduism                   1.89    71\n10 Buddhism                   2.38   147\n11 Other                      2.73   224\n12 None                       2.71  3523\n13 Jewish                     2.52   388\n14 Catholic                   2.96  5124\n15 Protestant                 3.15 10846"
  },
  {
    "objectID": "slides/22_factors.html#manually-reorder-factor-levels-1",
    "href": "slides/22_factors.html#manually-reorder-factor-levels-1",
    "title": "Factors",
    "section": "Manually reorder factor levels",
    "text": "Manually reorder factor levels\nfct_relevel()\n\nrelig_summary |&gt; ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()"
  },
  {
    "objectID": "slides/22_factors.html#manually-reorder-factor-levels-2",
    "href": "slides/22_factors.html#manually-reorder-factor-levels-2",
    "title": "Factors",
    "section": "Manually reorder factor levels",
    "text": "Manually reorder factor levels\nfct_relevel()\n\nrelig_summary_releveled &lt;- relig_summary |&gt;\n  mutate(relig = fct_relevel(relig, c(\"None\", \"Other\"), after = 2))\nlevels(relig_summary_releveled$relig)\n\n [1] \"No answer\"               \"Don't know\"             \n [3] \"None\"                    \"Other\"                  \n [5] \"Inter-nondenominational\" \"Native american\"        \n [7] \"Christian\"               \"Orthodox-christian\"     \n [9] \"Moslem/islam\"            \"Other eastern\"          \n[11] \"Hinduism\"                \"Buddhism\"               \n[13] \"Jewish\"                  \"Catholic\"               \n[15] \"Protestant\"              \"Not applicable\""
  },
  {
    "objectID": "slides/22_factors.html#manually-reorder-factor-levels-3",
    "href": "slides/22_factors.html#manually-reorder-factor-levels-3",
    "title": "Factors",
    "section": "Manually reorder factor levels",
    "text": "Manually reorder factor levels\nfct_relevel()\n\nrelig_summary_releveled |&gt; ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()"
  },
  {
    "objectID": "slides/22_factors.html#order-factors-by-another-variable",
    "href": "slides/22_factors.html#order-factors-by-another-variable",
    "title": "Factors",
    "section": "Order factors by another variable",
    "text": "Order factors by another variable\nfct_reorder()\n\nrelig_summary |&gt; mutate(relig = fct_reorder(relig, tvhours)) |&gt;\n  ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()"
  },
  {
    "objectID": "slides/22_factors.html#order-factors-by-another-variable-1",
    "href": "slides/22_factors.html#order-factors-by-another-variable-1",
    "title": "Factors",
    "section": "Order factors by another variable",
    "text": "Order factors by another variable\nfct_reorder()\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n  geom_point()"
  },
  {
    "objectID": "slides/22_factors.html#recode-factor-levels",
    "href": "slides/22_factors.html#recode-factor-levels",
    "title": "Factors",
    "section": "Recode factor levels",
    "text": "Recode factor levels\nfct_recode()\n\ngss_cat |&gt;\n  count(partyid)\n\n# A tibble: 10 × 2\n   partyid                n\n   &lt;fct&gt;              &lt;int&gt;\n 1 No answer            154\n 2 Don't know             1\n 3 Other party          393\n 4 Strong republican   2314\n 5 Not str republican  3032\n 6 Ind,near rep        1791\n 7 Independent         4119\n 8 Ind,near dem        2499\n 9 Not str democrat    3690\n10 Strong democrat     3490"
  },
  {
    "objectID": "slides/22_factors.html#recode-factor-levels-1",
    "href": "slides/22_factors.html#recode-factor-levels-1",
    "title": "Factors",
    "section": "Recode factor levels",
    "text": "Recode factor levels\nfct_recode()\n\n\ngss_cat |&gt;\n  mutate(partyid = fct_recode(partyid,\n                              \"Republican, strong\"    = \"Strong republican\",\n                              \"Republican, weak\"      = \"Not str republican\",\n                              \"Independent, near rep\" = \"Ind,near rep\",\n                              \"Independent, near dem\" = \"Ind,near dem\",\n                              \"Democrat, weak\"        = \"Not str democrat\",\n                              \"Democrat, strong\"      = \"Strong democrat\"\n  )) |&gt;\n  count(partyid)\n\n# A tibble: 10 × 2\n   partyid                   n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 No answer               154\n 2 Don't know                1\n 3 Other party             393\n 4 Republican, strong     2314\n 5 Republican, weak       3032\n 6 Independent, near rep  1791\n 7 Independent            4119\n 8 Independent, near dem  2499\n 9 Democrat, weak         3690\n10 Democrat, strong       3490"
  },
  {
    "objectID": "slides/22_factors.html#recode-factor-levels-2",
    "href": "slides/22_factors.html#recode-factor-levels-2",
    "title": "Factors",
    "section": "Recode factor levels",
    "text": "Recode factor levels\nfct_recode()\n\n\ngss_cat |&gt;\n  mutate(partyid = fct_recode(partyid,\n                              \"Independent, near rep\" = \"Ind,near rep\",\n                              \"Independent, near dem\" = \"Ind,near dem\",\n  )) |&gt;\n  count(partyid)\n\n# A tibble: 10 × 2\n   partyid                   n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 No answer               154\n 2 Don't know                1\n 3 Other party             393\n 4 Strong republican      2314\n 5 Not str republican     3032\n 6 Independent, near rep  1791\n 7 Independent            4119\n 8 Independent, near dem  2499\n 9 Not str democrat       3690\n10 Strong democrat        3490"
  },
  {
    "objectID": "slides/22_factors.html#collapse-multiple-levels",
    "href": "slides/22_factors.html#collapse-multiple-levels",
    "title": "Factors",
    "section": "Collapse multiple levels",
    "text": "Collapse multiple levels\nfct_collapse()\n\n\ngss_cat |&gt;\n  mutate(partyid = fct_collapse(partyid,\n                                \"other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n                                \"rep\" = c(\"Strong republican\", \"Not str republican\"),\n                                \"ind\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n                                \"dem\" = c(\"Not str democrat\", \"Strong democrat\")\n  )) |&gt;\n  count(partyid)\n\n# A tibble: 4 × 2\n  partyid     n\n  &lt;fct&gt;   &lt;int&gt;\n1 other     548\n2 rep      5346\n3 ind      8409\n4 dem      7180"
  },
  {
    "objectID": "slides/22_factors.html#combine-factor-levels",
    "href": "slides/22_factors.html#combine-factor-levels",
    "title": "Factors",
    "section": "Combine factor levels",
    "text": "Combine factor levels\nBased on number of groups: fct_lump_n()\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_n(relig, n = 5)) |&gt;\n  count(relig, sort = TRUE)\n\n# A tibble: 6 × 2\n  relig          n\n  &lt;fct&gt;      &lt;int&gt;\n1 Protestant 10846\n2 Catholic    5124\n3 None        3523\n4 Other        913\n5 Christian    689\n6 Jewish       388"
  },
  {
    "objectID": "slides/22_factors.html#combine-factor-levels-1",
    "href": "slides/22_factors.html#combine-factor-levels-1",
    "title": "Factors",
    "section": "Combine factor levels",
    "text": "Combine factor levels\nBased on proportion of total: fct_lump_prop()\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_prop(relig, prop = 0.1, \n                               other_level = \"Something else\")) |&gt;\n  count(relig, sort = TRUE)\n\n# A tibble: 4 × 2\n  relig              n\n  &lt;fct&gt;          &lt;int&gt;\n1 Protestant     10846\n2 Catholic        5124\n3 None            3523\n4 Something else  1990"
  },
  {
    "objectID": "slides/22_factors.html#combine-factor-levels-2",
    "href": "slides/22_factors.html#combine-factor-levels-2",
    "title": "Factors",
    "section": "Combine factor levels",
    "text": "Combine factor levels\nBased on minimum number: fct_lump_min()\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_min(relig, min = 200)) |&gt;\n  count(relig, sort = TRUE)\n\n# A tibble: 6 × 2\n  relig          n\n  &lt;fct&gt;      &lt;int&gt;\n1 Protestant 10846\n2 Catholic    5124\n3 None        3523\n4 Other        913\n5 Christian    689\n6 Jewish       388"
  },
  {
    "objectID": "slides/22_factors.html#solving-the-problem",
    "href": "slides/22_factors.html#solving-the-problem",
    "title": "Factors",
    "section": "Solving the problem",
    "text": "Solving the problem\nWhat code generates data2 from data1?\n\n\n\ndata1\n\n# A tibble: 8 × 2\n  species      n\n  &lt;chr&gt;    &lt;int&gt;\n1 Droid        6\n2 Gungan       3\n3 Human       35\n4 Kaminoan     2\n5 Mirialan     2\n6 Twi'lek      2\n7 Wookiee      2\n8 Zabrak       2\n\n\n\n\ndata2\n\n# A tibble: 4 × 2\n  species     n\n  &lt;fct&gt;   &lt;int&gt;\n1 Human      35\n2 Other      10\n3 Android     6\n4 Gungan      3"
  },
  {
    "objectID": "slides/22_factors.html#lets-code",
    "href": "slides/22_factors.html#lets-code",
    "title": "Factors",
    "section": "Let’s code!",
    "text": "Let’s code!\nFactors [Rmd]"
  },
  {
    "objectID": "slides/24_functions.html#set-up",
    "href": "slides/24_functions.html#set-up",
    "title": "Functions",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/24_functions.html#why-write-your-own-functions",
    "href": "slides/24_functions.html#why-write-your-own-functions",
    "title": "Functions",
    "section": "Why write your own functions?",
    "text": "Why write your own functions?"
  },
  {
    "objectID": "slides/24_functions.html#creating-functions-1",
    "href": "slides/24_functions.html#creating-functions-1",
    "title": "Functions",
    "section": "Creating functions",
    "text": "Creating functions\n\nfunctionname &lt;- function(argument1, argument2) {\n  # Function contents\n}"
  },
  {
    "objectID": "slides/24_functions.html#creating-functions-2",
    "href": "slides/24_functions.html#creating-functions-2",
    "title": "Functions",
    "section": "Creating functions",
    "text": "Creating functions\n\nmymean &lt;- function(x) {\n  sum(x) / length(x)\n}\n\n\n\nmymean(mtcars$mpg)\n\n[1] 20.09062\n\nmean(mtcars$mpg)\n\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#multi-line-functions",
    "href": "slides/24_functions.html#multi-line-functions",
    "title": "Functions",
    "section": "Multi-line functions",
    "text": "Multi-line functions\n\nmymean2 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  mysum_divided &lt;- mysum / length(x)\n}\n\n\n\nmymean2(mtcars$mpg)\n\nWhy no output?\n\n\n\n(mymean_obj &lt;- mymean2(mtcars$mpg))\n\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#returning-output",
    "href": "slides/24_functions.html#returning-output",
    "title": "Functions",
    "section": "Returning output",
    "text": "Returning output\nDon’t assign last step to object\n\nmymean3 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  mysum / length(x)\n}\n\nmymean3(mtcars$mpg)\n\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#returning-output-1",
    "href": "slides/24_functions.html#returning-output-1",
    "title": "Functions",
    "section": "Returning output",
    "text": "Returning output\nOr use return()\n\nmymean4 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  mysum_divided &lt;- mysum / length(x)\n  return(mysum_divided)\n}\n\nmymean4(mtcars$mpg)\n\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#return-multiple-output-values",
    "href": "slides/24_functions.html#return-multiple-output-values",
    "title": "Functions",
    "section": "Return multiple output values",
    "text": "Return multiple output values\nlist()\n\nmymean5 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  mysum_divided &lt;- mysum / length(x)\n  list(sum = mysum, mean = mysum_divided)\n}\n\nmymean5(mtcars$mpg)\n\n$sum\n[1] 642.9\n\n$mean\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#save-intermediate-objects",
    "href": "slides/24_functions.html#save-intermediate-objects",
    "title": "Functions",
    "section": "Save intermediate objects",
    "text": "Save intermediate objects\n\nmymean6 &lt;- function(x) {\n  mysum &lt;&lt;- sum(x)\n  mysum / length(x)\n}\n\nmymean6(mtcars$mpg)\n\n[1] 20.09062\n\n\n\n\n\n\n\n\nNote\n\n\nThis is fine when testing out a function but probably not great practice ‘in production’. Why?"
  },
  {
    "objectID": "slides/24_functions.html#print-messages-to-console",
    "href": "slides/24_functions.html#print-messages-to-console",
    "title": "Functions",
    "section": "Print messages to console",
    "text": "Print messages to console\n\nmymean7 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  print(mysum)\n  mysum / length(x)\n}\n\nmymean7(mtcars$mpg)\n\n[1] 642.9\n\n\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#print-messages-to-console-1",
    "href": "slides/24_functions.html#print-messages-to-console-1",
    "title": "Functions",
    "section": "Print messages to console",
    "text": "Print messages to console\n\nmymean8 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  print(paste0(\"The sum is: \", mysum))\n  mysum / length(x)\n}\n\nmymean8(mtcars$mpg)\n\n[1] \"The sum is: 642.9\"\n\n\n[1] 20.09062"
  },
  {
    "objectID": "slides/24_functions.html#print-messages-to-console-2",
    "href": "slides/24_functions.html#print-messages-to-console-2",
    "title": "Functions",
    "section": "Print messages to console",
    "text": "Print messages to console\n\nmymean9 &lt;- function(x) {\n  mysum &lt;- sum(x)\n  message(paste0(\"The sum is: \", mysum))\n  mysum / length(x)\n}\n\nmymean9(mtcars$mpg)\n\nThe sum is: 642.9\n\n\n[1] 20.09062\n\n\n\n\n\n\n\n\nNote\n\n\nCheck out {cli} package for powerful messaging."
  },
  {
    "objectID": "slides/24_functions.html#arguments-1",
    "href": "slides/24_functions.html#arguments-1",
    "title": "Functions",
    "section": "Arguments",
    "text": "Arguments\n\nmultiplier &lt;- function(x, constant) {\n  x * constant\n}\n\n\n\nmultiplier(x = 7, constant = 3)\n\n[1] 21\n\nmultiplier(x = 1:10, constant = 3)\n\n [1]  3  6  9 12 15 18 21 24 27 30\n\n\n\nmultiplier(x = 1:10)\n\nError in multiplier(x = 1:10) : \nargument \"constant\" is missing, with no default"
  },
  {
    "objectID": "slides/24_functions.html#argument-default-values",
    "href": "slides/24_functions.html#argument-default-values",
    "title": "Functions",
    "section": "Argument default values",
    "text": "Argument default values\n\nmultiplier2 &lt;- function(x, constant = 3) {\n  x * constant\n}\n\n\nmultiplier2(x = 1:10)\n\n [1]  3  6  9 12 15 18 21 24 27 30\n\nmultiplier2(x = 1:10, constant = 5)\n\n [1]  5 10 15 20 25 30 35 40 45 50"
  },
  {
    "objectID": "slides/24_functions.html#lets-write-a-function",
    "href": "slides/24_functions.html#lets-write-a-function",
    "title": "Functions",
    "section": "Let’s write a function!",
    "text": "Let’s write a function!\nHere’s the formula that reverse codes scale values\nValuemax+ Valuemin-Score\nWrite a function that calculates the reversed code score. What arguments do you need?"
  },
  {
    "objectID": "slides/24_functions.html#conditional-execution-1",
    "href": "slides/24_functions.html#conditional-execution-1",
    "title": "Functions",
    "section": "Conditional execution",
    "text": "Conditional execution\n\nhead(penguins[, 1:5])\n\n# A tibble: 6 × 5\n  species island    bill_length_mm bill_depth_mm flipper_length_mm\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181\n2 Adelie  Torgersen           39.5          17.4               186\n3 Adelie  Torgersen           40.3          18                 195\n4 Adelie  Torgersen           NA            NA                  NA\n5 Adelie  Torgersen           36.7          19.3               193\n6 Adelie  Torgersen           39.3          20.6               190\n\n\n\nmymean6(penguins$bill_length_mm)\n\n[1] NA"
  },
  {
    "objectID": "slides/24_functions.html#conditional-execution-2",
    "href": "slides/24_functions.html#conditional-execution-2",
    "title": "Functions",
    "section": "Conditional execution",
    "text": "Conditional execution\n\nhead(penguins[, 1:5])\n\n# A tibble: 6 × 5\n  species island    bill_length_mm bill_depth_mm flipper_length_mm\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181\n2 Adelie  Torgersen           39.5          17.4               186\n3 Adelie  Torgersen           40.3          18                 195\n4 Adelie  Torgersen           NA            NA                  NA\n5 Adelie  Torgersen           36.7          19.3               193\n6 Adelie  Torgersen           39.3          20.6               190\n\n\n\nmymean10 &lt;- function(x) {\n  sum(x, na.rm = TRUE) / sum(!is.na(x))\n}\n\n\nmymean10(penguins$bill_length_mm)\n\n[1] 43.92193"
  },
  {
    "objectID": "slides/24_functions.html#conditional-execution-3",
    "href": "slides/24_functions.html#conditional-execution-3",
    "title": "Functions",
    "section": "Conditional execution",
    "text": "Conditional execution\nBut if you want the user to control whether NA is ignored\n\nmymean11 &lt;- function(x, ignore_na = TRUE) {\n  if (ignore_na) {\n    sum(x, na.rm = TRUE) / sum(!is.na(x))\n  } else {\n    sum(x) / length(x)\n  }\n}\n\n\nmymean11(penguins$bill_length_mm)\n\n[1] 43.92193\n\nmymean11(penguins$bill_length_mm, ignore_na = FALSE)\n\n[1] NA"
  },
  {
    "objectID": "slides/24_functions.html#multiple-conditions",
    "href": "slides/24_functions.html#multiple-conditions",
    "title": "Functions",
    "section": "Multiple conditions",
    "text": "Multiple conditions\nUse else if\n\nage_cutoffs &lt;- function(x) {\n  if(x &lt;= 1.5) {\n    \"puppy\"\n  } else if (x &lt;= 3) {\n    \"adolescent\"\n  } else if (x &lt;= 10) {\n    \"adult\"\n  } else {\n    \"senior\"\n  }\n}\n\n\n\nage_cutoffs(1)\n\n[1] \"puppy\"\n\nage_cutoffs(2)\n\n[1] \"adolescent\"\n\nage_cutoffs(5)\n\n[1] \"adult\""
  },
  {
    "objectID": "slides/24_functions.html#stopping-based-on-conditionals",
    "href": "slides/24_functions.html#stopping-based-on-conditionals",
    "title": "Functions",
    "section": "Stopping based on conditionals",
    "text": "Stopping based on conditionals\n\nage_cutoffs2 &lt;- function(x) {\n  if(x &lt;= 1.5) {\n    \"puppy\"\n  } else if (x &lt;= 3) {\n    \"adolescent\"\n  } else if (x &lt;= 10) {\n    \"adult\"\n  } else if (x &lt;= 20) {\n    \"senior\"\n  } else {\n    stop(\"Age exceeded 20.\")\n  }\n}\n\n\n\nage_cutoffs2(15)\n\n[1] \"senior\"\n\n\n\nage_cutoffs2(22)\n\nError in age_cutoffs2(22) : Age exceeded 20."
  },
  {
    "objectID": "slides/24_functions.html#multiple-conditions-1",
    "href": "slides/24_functions.html#multiple-conditions-1",
    "title": "Functions",
    "section": "Multiple conditions",
    "text": "Multiple conditions\nUse switch()\n\ncentral_tend &lt;- function(x, type) {\n  switch(type,\n         mean = mean(x),\n         median = median(x),\n         trimmed = mean(x, trim = .1))\n}\n\n\n\nvector &lt;- rcauchy(100)\ncentral_tend(x = vector, type = \"mean\")\n\n[1] -0.5667226\n\ncentral_tend(x = vector, type = \"median\")\n\n[1] -0.0404721\n\ncentral_tend(x = vector, type = \"trimmed\")\n\n[1] -0.06394419"
  },
  {
    "objectID": "slides/24_functions.html#creating-functions-in-tidyverse",
    "href": "slides/24_functions.html#creating-functions-in-tidyverse",
    "title": "Functions",
    "section": "Creating functions in tidyverse",
    "text": "Creating functions in tidyverse\n\nmean_species_bill &lt;- function(df) {\n  df |&gt; \n    group_by(species) |&gt; \n    summarise(mean(bill_length_mm, na.rm = TRUE))\n}\n\nmean_species_bill(penguins)\n\n# A tibble: 3 × 2\n  species   `mean(bill_length_mm, na.rm = TRUE)`\n  &lt;fct&gt;                                    &lt;dbl&gt;\n1 Adelie                                    38.8\n2 Chinstrap                                 48.8\n3 Gentoo                                    47.5"
  },
  {
    "objectID": "slides/24_functions.html#creating-functions-in-tidyverse-1",
    "href": "slides/24_functions.html#creating-functions-in-tidyverse-1",
    "title": "Functions",
    "section": "Creating functions in tidyverse",
    "text": "Creating functions in tidyverse\nWhat if we want user to input grouping and response variable?\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarise(mean(mean_var, na.rm = TRUE))\n}\n\n\n\npenguins |&gt; \n  grouped_mean(group_var = species, mean_var = bill_length_mm)\n\nError in `group_by()`:\n! Must group by variables found in `.data`.\n✖ Column `group_var` is not found.\nRun `rlang::last_trace()` to see where the error occurred."
  },
  {
    "objectID": "slides/24_functions.html#embracing",
    "href": "slides/24_functions.html#embracing",
    "title": "Functions",
    "section": "Embracing",
    "text": "Embracing\nEmbrace variables in { }\n\ngrouped_mean2 &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}, na.rm = TRUE))\n}\n\n\npenguins |&gt; \n  grouped_mean2(group_var = species, mean_var = bill_length_mm)\n\n# A tibble: 3 × 2\n  species   `mean(bill_length_mm, na.rm = TRUE)`\n  &lt;fct&gt;                                    &lt;dbl&gt;\n1 Adelie                                    38.8\n2 Chinstrap                                 48.8\n3 Gentoo                                    47.5"
  },
  {
    "objectID": "slides/24_functions.html#lets-code",
    "href": "slides/24_functions.html#lets-code",
    "title": "Functions",
    "section": "Let’s code!",
    "text": "Let’s code!\nFunctions [Rmd]"
  },
  {
    "objectID": "slides/26_grammar1.html#set-up",
    "href": "slides/26_grammar1.html#set-up",
    "title": "Grammar of graphics",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/26_grammar1.html#plotting-with-ggplot2",
    "href": "slides/26_grammar1.html#plotting-with-ggplot2",
    "title": "Grammar of graphics",
    "section": "Plotting with {ggplot2}",
    "text": "Plotting with {ggplot2}\n\nlibrary(ggplot2)\n\n\n\n\n\n\n\n\nSource: Allison Horst"
  },
  {
    "objectID": "slides/26_grammar1.html#grammar-of-graphics",
    "href": "slides/26_grammar1.html#grammar-of-graphics",
    "title": "Grammar of graphics",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics"
  },
  {
    "objectID": "slides/26_grammar1.html#seven-componentslayers-of-ggplots",
    "href": "slides/26_grammar1.html#seven-componentslayers-of-ggplots",
    "title": "Grammar of graphics",
    "section": "Seven components/layers of ggplots",
    "text": "Seven components/layers of ggplots\n\nData\nMappings – maps data to properties of geom\nGeom – represents data\nStat – transforms data\nPosition – control placement of data on coordinate\nFacet – split graph into subplots\nCoordinate – places data in coordinate system"
  },
  {
    "objectID": "slides/26_grammar1.html#seven-componentslayers-of-ggplots-1",
    "href": "slides/26_grammar1.html#seven-componentslayers-of-ggplots-1",
    "title": "Grammar of graphics",
    "section": "Seven components/layers of ggplots",
    "text": "Seven components/layers of ggplots\n\n\nggplot(data = DATA) +\n  GEOM_FUNCTION(\n    mapping = aes(MAPPINGS),\n    stat = STAT,\n    position = POSITION\n  ) +\n  COORDINATE_FUNCTION +\n  FACET_FUNCTION"
  },
  {
    "objectID": "slides/26_grammar1.html#full-specification-of-plot",
    "href": "slides/26_grammar1.html#full-specification-of-plot",
    "title": "Grammar of graphics",
    "section": "Full specification of plot",
    "text": "Full specification of plot\n\nggplot(data = penguins) +\n  geom_point(\n    mapping = aes(x = bill_length_mm, y = bill_depth_mm),\n    stat = \"identity\",\n    position = \"identity\"\n  ) +\n  coord_cartesian() +\n  facet_null()"
  },
  {
    "objectID": "slides/26_grammar1.html#tidy-data",
    "href": "slides/26_grammar1.html#tidy-data",
    "title": "Grammar of graphics",
    "section": "Tidy data",
    "text": "Tidy data\nData should be in tidy format for ggplots\n\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows"
  },
  {
    "objectID": "slides/26_grammar1.html#data-to-ggplot",
    "href": "slides/26_grammar1.html#data-to-ggplot",
    "title": "Grammar of graphics",
    "section": "Data to ggplot",
    "text": "Data to ggplot\nData inside ggplot()\n\nggplot(data = mpg)"
  },
  {
    "objectID": "slides/26_grammar1.html#data-to-ggplot-1",
    "href": "slides/26_grammar1.html#data-to-ggplot-1",
    "title": "Grammar of graphics",
    "section": "Data to ggplot",
    "text": "Data to ggplot\nData piped to ggplot()\n\nmpg |&gt;\n  ggplot()"
  },
  {
    "objectID": "slides/26_grammar1.html#data-to-ggplot-2",
    "href": "slides/26_grammar1.html#data-to-ggplot-2",
    "title": "Grammar of graphics",
    "section": "Data to ggplot",
    "text": "Data to ggplot\nProcess data before plotting\n\nmpg |&gt;\n  filter(class != \"2seater\") |&gt;\n  mutate(class = str_to_sentence(class)) |&gt;\n  ggplot()"
  },
  {
    "objectID": "slides/26_grammar1.html#map-data-to-positions",
    "href": "slides/26_grammar1.html#map-data-to-positions",
    "title": "Grammar of graphics",
    "section": "Map data to positions",
    "text": "Map data to positions\nSpecify columns for x and y\n\n#\nggplot(data = mpg, mapping = aes(x = displ, y = hwy))"
  },
  {
    "objectID": "slides/26_grammar1.html#map-data-to-positions-1",
    "href": "slides/26_grammar1.html#map-data-to-positions-1",
    "title": "Grammar of graphics",
    "section": "Map data to positions",
    "text": "Map data to positions\nEquivalent but not ideal. Why?\n\n#\nggplot(mpg, aes(displ, hwy))"
  },
  {
    "objectID": "slides/26_grammar1.html#map-data-to-positions-2",
    "href": "slides/26_grammar1.html#map-data-to-positions-2",
    "title": "Grammar of graphics",
    "section": "Map data to positions",
    "text": "Map data to positions\nThis is how we’ll do it\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy))"
  },
  {
    "objectID": "slides/26_grammar1.html#geoms",
    "href": "slides/26_grammar1.html#geoms",
    "title": "Grammar of graphics",
    "section": "Geoms",
    "text": "Geoms\nThere are many different ways of representing data on a plot"
  },
  {
    "objectID": "slides/26_grammar1.html#plot-points",
    "href": "slides/26_grammar1.html#plot-points",
    "title": "Grammar of graphics",
    "section": "Plot points",
    "text": "Plot points\nAdd geom_point()\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point()"
  },
  {
    "objectID": "slides/26_grammar1.html#plot-points-1",
    "href": "slides/26_grammar1.html#plot-points-1",
    "title": "Grammar of graphics",
    "section": "Plot points",
    "text": "Plot points\nHow is this different? What are advantages/disadvantages?\n\nmpg |&gt;\n  ggplot() +\n  geom_point(aes(x = displ, y = hwy))"
  },
  {
    "objectID": "slides/26_grammar1.html#plot-smooth-lines",
    "href": "slides/26_grammar1.html#plot-smooth-lines",
    "title": "Grammar of graphics",
    "section": "Plot smooth lines",
    "text": "Plot smooth lines\n\n#\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_smooth()"
  },
  {
    "objectID": "slides/26_grammar1.html#plot-multiple-geoms",
    "href": "slides/26_grammar1.html#plot-multiple-geoms",
    "title": "Grammar of graphics",
    "section": "Plot multiple geoms",
    "text": "Plot multiple geoms\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "slides/26_grammar1.html#order-matters",
    "href": "slides/26_grammar1.html#order-matters",
    "title": "Grammar of graphics",
    "section": "Order matters",
    "text": "Order matters\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_smooth() +\n  geom_point()"
  },
  {
    "objectID": "slides/26_grammar1.html#plot-linear-regression-line",
    "href": "slides/26_grammar1.html#plot-linear-regression-line",
    "title": "Grammar of graphics",
    "section": "Plot linear regression line",
    "text": "Plot linear regression line\n\nmpg |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/26_grammar1.html#plot-boxplots",
    "href": "slides/26_grammar1.html#plot-boxplots",
    "title": "Grammar of graphics",
    "section": "Plot boxplots",
    "text": "Plot boxplots\n\nmpg |&gt;\n  ggplot(aes(x = class, y = displ)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/26_grammar1.html#lets-code",
    "href": "slides/26_grammar1.html#lets-code",
    "title": "Grammar of graphics",
    "section": "Let’s code!",
    "text": "Let’s code!\nGrammar of graphics [Rmd]"
  },
  {
    "objectID": "slides/28_themes.html#edward-tufte",
    "href": "slides/28_themes.html#edward-tufte",
    "title": "Design and themes",
    "section": "Edward Tufte",
    "text": "Edward Tufte"
  },
  {
    "objectID": "slides/28_themes.html#graphical-excellence",
    "href": "slides/28_themes.html#graphical-excellence",
    "title": "Design and themes",
    "section": "Graphical excellence",
    "text": "Graphical excellence\nCommunicating complex ideas with clarity, precision, and efficiency"
  },
  {
    "objectID": "slides/28_themes.html#graphical-excellence-1",
    "href": "slides/28_themes.html#graphical-excellence-1",
    "title": "Design and themes",
    "section": "Graphical excellence",
    "text": "Graphical excellence\nCommunicating complex ideas with clarity, precision, and efficiency\n\nWell-designed presentation of interesting data\nGives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space\nMultivariate\nRequires telling the truth about data"
  },
  {
    "objectID": "slides/28_themes.html#graphical-integrity",
    "href": "slides/28_themes.html#graphical-integrity",
    "title": "Design and themes",
    "section": "Graphical integrity",
    "text": "Graphical integrity\nTell the truth about the data"
  },
  {
    "objectID": "slides/28_themes.html#graphical-integrity-1",
    "href": "slides/28_themes.html#graphical-integrity-1",
    "title": "Design and themes",
    "section": "Graphical integrity",
    "text": "Graphical integrity\nWilke’s Principle of Proportional ink\nThe representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities represented"
  },
  {
    "objectID": "slides/28_themes.html#graphical-integrity-2",
    "href": "slides/28_themes.html#graphical-integrity-2",
    "title": "Design and themes",
    "section": "Graphical integrity",
    "text": "Graphical integrity\nPerceptions of length and area do not match (and we’re bad at judging area)"
  },
  {
    "objectID": "slides/28_themes.html#data-ink-ratio",
    "href": "slides/28_themes.html#data-ink-ratio",
    "title": "Design and themes",
    "section": "Data-ink ratio",
    "text": "Data-ink ratio\nData-ink: the non-erasable core of a graphic, the non-redundant ink arranged in response to variation in the numbers represented\nData-ink ratio: amount of data-ink divided by total ink used to print the graphic"
  },
  {
    "objectID": "slides/28_themes.html#data-ink-ratio-1",
    "href": "slides/28_themes.html#data-ink-ratio-1",
    "title": "Design and themes",
    "section": "Data-ink ratio",
    "text": "Data-ink ratio\n\n\nTukey boxplot\n\n\n\n\n\n\n\n\n\nTufte “box” plot"
  },
  {
    "objectID": "slides/28_themes.html#data-ink-ratio-2",
    "href": "slides/28_themes.html#data-ink-ratio-2",
    "title": "Design and themes",
    "section": "Data-ink ratio",
    "text": "Data-ink ratio\n\nAbove all else show the data\nMaximize the data-ink ratio\nErase non-data-ink\nErase redundant data-ink"
  },
  {
    "objectID": "slides/28_themes.html#chartjunk",
    "href": "slides/28_themes.html#chartjunk",
    "title": "Design and themes",
    "section": "Chartjunk",
    "text": "Chartjunk\nNon-data-ink or redundant data-ink that does not tell the viewer anything new"
  },
  {
    "objectID": "slides/28_themes.html#themes-1",
    "href": "slides/28_themes.html#themes-1",
    "title": "Design and themes",
    "section": "Themes",
    "text": "Themes"
  },
  {
    "objectID": "slides/28_themes.html#set-up",
    "href": "slides/28_themes.html#set-up",
    "title": "Design and themes",
    "section": "Set-up",
    "text": "Set-up\n\nlibrary(tidyverse)\n\nSwitch to R script"
  },
  {
    "objectID": "slides/28_themes.html#lets-code",
    "href": "slides/28_themes.html#lets-code",
    "title": "Design and themes",
    "section": "Let’s code!",
    "text": "Let’s code!\nThemes [Rmd]"
  },
  {
    "objectID": "slides/40_publications.html#templates",
    "href": "slides/40_publications.html#templates",
    "title": "Publications",
    "section": "Templates",
    "text": "Templates\n{rticles}"
  },
  {
    "objectID": "slides/40_publications.html#apa-template",
    "href": "slides/40_publications.html#apa-template",
    "title": "Publications",
    "section": "APA template",
    "text": "APA template\n{papaja}"
  },
  {
    "objectID": "slides/40_publications.html#apa-template-1",
    "href": "slides/40_publications.html#apa-template-1",
    "title": "Publications",
    "section": "APA template",
    "text": "APA template\n{papaja}\n\n\nYAML header\nr_refs() and cite_r()\nAPA 7"
  },
  {
    "objectID": "slides/40_publications.html#quarto-apa-template",
    "href": "slides/40_publications.html#quarto-apa-template",
    "title": "Publications",
    "section": "Quarto APA template",
    "text": "Quarto APA template\n\nqapaja\napaquarto\nHikmah Quarto templates"
  },
  {
    "objectID": "slides/40_publications.html#extracting-statistics-1",
    "href": "slides/40_publications.html#extracting-statistics-1",
    "title": "Publications",
    "section": "Extracting statistics",
    "text": "Extracting statistics\n\napa_print()"
  },
  {
    "objectID": "slides/40_publications.html#run-a-t-test",
    "href": "slides/40_publications.html#run-a-t-test",
    "title": "Publications",
    "section": "Run a t-test",
    "text": "Run a t-test\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n(penguin_ttest &lt;- t.test(formula = bill_length_mm ~ sex, data = penguins))\n\n\n    Welch Two Sample t-test\n\ndata:  bill_length_mm by sex\nt = -6.6725, df = 329.29, p-value = 1.066e-10\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -4.865676 -2.649908\nsample estimates:\nmean in group female   mean in group male \n            42.09697             45.85476"
  },
  {
    "objectID": "slides/40_publications.html#view-structure-of-a-t-test",
    "href": "slides/40_publications.html#view-structure-of-a-t-test",
    "title": "Publications",
    "section": "View structure of a t-test",
    "text": "View structure of a t-test\n\nstr(penguin_ttest)\n\nList of 10\n $ statistic  : Named num -6.67\n  ..- attr(*, \"names\")= chr \"t\"\n $ parameter  : Named num 329\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value    : num 1.07e-10\n $ conf.int   : num [1:2] -4.87 -2.65\n  ..- attr(*, \"conf.level\")= num 0.95\n $ estimate   : Named num [1:2] 42.1 45.9\n  ..- attr(*, \"names\")= chr [1:2] \"mean in group female\" \"mean in group male\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"difference in means between group female and group male\"\n $ stderr     : num 0.563\n $ alternative: chr \"two.sided\"\n $ method     : chr \"Welch Two Sample t-test\"\n $ data.name  : chr \"bill_length_mm by sex\"\n - attr(*, \"class\")= chr \"htest\""
  },
  {
    "objectID": "slides/40_publications.html#extract-information-from-t-test",
    "href": "slides/40_publications.html#extract-information-from-t-test",
    "title": "Publications",
    "section": "Extract information from t-test",
    "text": "Extract information from t-test\n\nlibrary(papaja)\napa_print(penguin_ttest)\n\n$estimate\n[1] \"$\\\\Delta M = -3.76$, 95\\\\% CI $[-4.87, -2.65]$\"\n\n$statistic\n[1] \"$t(329.29) = -6.67$, $p &lt; .001$\"\n\n$full_result\n[1] \"$\\\\Delta M = -3.76$, 95\\\\% CI $[-4.87, -2.65]$, $t(329.29) = -6.67$, $p &lt; .001$\"\n\n$table\nA data.frame with 5 labelled columns:\n\n  estimate       conf.int statistic     df p.value\n1    -3.76 [-4.87, -2.65]     -6.67 329.29  &lt; .001\n\nestimate : $\\\\Delta M$ \nconf.int : 95\\\\% CI \nstatistic: $t$ \ndf       : $\\\\mathit{df}$ \np.value  : $p$ \nattr(,\"class\")\n[1] \"apa_results\" \"list\""
  },
  {
    "objectID": "slides/40_publications.html#extract-information-from-t-test-1",
    "href": "slides/40_publications.html#extract-information-from-t-test-1",
    "title": "Publications",
    "section": "Extract information from t-test",
    "text": "Extract information from t-test\n\napa_print(penguin_ttest)$full_result\n\n[1] \"$\\\\Delta M = -3.76$, 95\\\\% CI $[-4.87, -2.65]$, $t(329.29) = -6.67$, $p &lt; .001$\""
  },
  {
    "objectID": "slides/40_publications.html#insert-statistics-as-inline-code",
    "href": "slides/40_publications.html#insert-statistics-as-inline-code",
    "title": "Publications",
    "section": "Insert statistics as inline code",
    "text": "Insert statistics as inline code\n Male and female penguins differ in their bill length (`r apa_print(penguin_ttest)$full_result`). \n\nMale and female penguins differ in their bill length (\\(\\Delta M = -3.76\\), 95% CI \\([-4.87, -2.65]\\), \\(t(329.29) = -6.67\\), \\(p &lt; .001\\))."
  },
  {
    "objectID": "slides/40_publications.html#apa_print-objects",
    "href": "slides/40_publications.html#apa_print-objects",
    "title": "Publications",
    "section": "\napa_print() objects",
    "text": "apa_print() objects\n\n\n\n\nNon-parametrics (wilcox.test())\nCorrelations (cor.test())\nT-tests (t.test())\nANOVA (aov(), Anova(), afex_aov())\nMANOVA (manova())\nLinear regressions (lm())\nGeneralized linear models (glm())\n\n\n\nMixed models (lmer(), glmer())\nNon-linear models (nlme())\nEstimated marginal means (emm())\nWithin-subjects confidence intervals (wsci())\nBayes factors (from BayesFactor package)"
  },
  {
    "objectID": "slides/40_publications.html#printing-p-values",
    "href": "slides/40_publications.html#printing-p-values",
    "title": "Publications",
    "section": "Printing p-values",
    "text": "Printing p-values\nprintp()\n\nprintp(0.23456)\n\n[1] \".235\"\n\nprintp(0.23456, add_equals = TRUE)\n\n[1] \"= .235\"\n\nprintp(0.000000000000001)\n\n[1] \"&lt; .001\""
  },
  {
    "objectID": "slides/40_publications.html#printing-other-numbers",
    "href": "slides/40_publications.html#printing-other-numbers",
    "title": "Publications",
    "section": "Printing other numbers",
    "text": "Printing other numbers\nprintnum()\n\nprintnum(0.5555555)\n\n[1] \"0.56\"\n\nprintnum(0.5555555, digits = 4)\n\n[1] \"0.5556\"\n\nprintnum(0.5555555, gt1 = FALSE)\n\n[1] \".56\"\n\nprintnum(0.00000000000001)\n\n[1] \"0.00\"\n\nprintnum(0.00000000000001, zero = FALSE)\n\n[1] \"&lt; 0.01\""
  },
  {
    "objectID": "slides/40_publications.html#examples-of-extracting-statistics",
    "href": "slides/40_publications.html#examples-of-extracting-statistics",
    "title": "Publications",
    "section": "Examples of extracting statistics",
    "text": "Examples of extracting statistics\n\nRmd\nPDF"
  },
  {
    "objectID": "slides/40_publications.html#pre-registration-templates",
    "href": "slides/40_publications.html#pre-registration-templates",
    "title": "Publications",
    "section": "Pre-registration templates",
    "text": "Pre-registration templates\n{prereg}\n{preregr}"
  },
  {
    "objectID": "slides/40_publications.html#revision-letter-template",
    "href": "slides/40_publications.html#revision-letter-template",
    "title": "Publications",
    "section": "Revision letter template",
    "text": "Revision letter template\n\n\n\n\n\nFriends don’t let friends copy-paste"
  },
  {
    "objectID": "slides/40_publications.html#dissertations-in-r-markdown",
    "href": "slides/40_publications.html#dissertations-in-r-markdown",
    "title": "Publications",
    "section": "Dissertations in R Markdown",
    "text": "Dissertations in R Markdown"
  },
  {
    "objectID": "slides/40_publications.html#lets-code",
    "href": "slides/40_publications.html#lets-code",
    "title": "Publications",
    "section": "Let’s code!",
    "text": "Let’s code!\nJournal articles [Rmd]"
  },
  {
    "objectID": "slides/42_quarto.html#quarto",
    "href": "slides/42_quarto.html#quarto",
    "title": "Quarto",
    "section": "Quarto",
    "text": "Quarto\nQuarto is an open-source scientific and technical publishing system built on Pandoc"
  },
  {
    "objectID": "code/01_introduction.html",
    "href": "code/01_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Let’s go to R’s console, which is the direct connection to the R engine. In the console, you give R a command, and it returns the output."
  },
  {
    "objectID": "code/01_introduction.html#numerical-operations",
    "href": "code/01_introduction.html#numerical-operations",
    "title": "Introduction",
    "section": "Numerical operations",
    "text": "Numerical operations\nR can be a very fancy calculator. It uses standard mathematical operators for things like addition (+), subtraction (-), multiplication (*), and division (/). Let’s do some calculations by entering numerical operations into the console. How many seconds are there in a year?\n\n# &gt;\n\nOn average, how many days are in each month of a leap year?\n\n# &gt;"
  },
  {
    "objectID": "code/01_introduction.html#text",
    "href": "code/01_introduction.html#text",
    "title": "Introduction",
    "section": "Text",
    "text": "Text\nR also can store, manipulate, and return text. But working with text requires wrapping the characters in quotation marks (either \" or '). Type this out and replace &lt;name&gt; with your name: \"My name is &lt;name&gt;!\".\n\n# &gt;\n\nYou can also apply functions to text. If we want to yell our names, let’s convert the string of characters to upper case with the toupper() function. Put the previous text inside the parentheses of toupper().\n\n# &gt;\n\nPress the up arrow ⬆️ to place previous commands in the console. Navigate to the previous command and change the text a bit."
  },
  {
    "objectID": "code/01_introduction.html#packages",
    "href": "code/01_introduction.html#packages",
    "title": "Introduction",
    "section": "Packages",
    "text": "Packages\nIf you haven’t already, install the {palmerpenguins} and {tidyverse} packages. Remember how to do that?\n\n# &gt;\n\nLet’s look at the penguins data set. What do we need to do first?\n\n# &gt;\n\nView the data set by typing penguins into the console.\n\n# &gt;"
  },
  {
    "objectID": "code/01_introduction.html#plot-data",
    "href": "code/01_introduction.html#plot-data",
    "title": "Introduction",
    "section": "Plot data",
    "text": "Plot data\nExcellent! We now have wrangled the data to where we want it. Let’s say we want to make a scatterplot of the bill length vs. the bill depth for all birds. We need to use the plot() function for this.\n\n# &gt;\n\nHey, hey! We have a plot! 📊 Sweet! We’ve input data, wrangled it, and plotted it. Well done! 🎉 💪"
  },
  {
    "objectID": "code/03_coding.html",
    "href": "code/03_coding.html",
    "title": "Coding basics",
    "section": "",
    "text": "Let’s go to R’s console, which is the direct connection to the R engine. In the console, you give R a command, and it returns the output."
  },
  {
    "objectID": "code/03_coding.html#assignment",
    "href": "code/03_coding.html#assignment",
    "title": "Coding basics",
    "section": "Assignment",
    "text": "Assignment\nRemember our text string with our names?\n\"My name is Jeff!\"\nIt is repetitive to have to copy/paste text. We can assign things to objects, which store the contents in a variable. The assignment operator &lt;- assigns the value of the right hand side to the object on the left hand side. Use the &lt;- operator to assign the name text to an object called my_name.\n\n# &gt;\n\nNow print the contents of my_name by just typing it into the console.\n\n# &gt;\n\nNow apply the toupper() function to my_name rather than the actual character string.\n\n# &gt;\n\nHow do we find out all of the arguments for the toupper() function?\nLet’s specify the argument names not just the value.\n\n# &gt;\n\nPress the up arrow to navigate to the assignment command and change the object name to something different."
  },
  {
    "objectID": "code/03_coding.html#names",
    "href": "code/03_coding.html#names",
    "title": "Coding basics",
    "section": "Names",
    "text": "Names\nWhy did I assign the text to the object my_name and not, for example, names?\nWhat all is wrong with the file name Qualtrics experiment 3 ~ 01/05/22 [final_FINAL].xlsx?\nWhat would be a better name for this file?\nWhy is this date problematic? 01/05/22\nWhat would be an ISO 8601 format for this date?\nWhy is it useful to include dates in files names?"
  },
  {
    "objectID": "code/05_rmarkdown.html",
    "href": "code/05_rmarkdown.html",
    "title": "Literate programming",
    "section": "",
    "text": "Open course RStudio project.\nCreate new R script.\nType library(palmerpenguins).\nIs palmerpenguins loaded? How can you check?\nRun the line to load palmerpenguins.\nType print(penguins).\nSource the whole script.\nComment out the print(penguins) line.\nSource the script."
  },
  {
    "objectID": "code/05_rmarkdown.html#creating-and-working-in-scripts",
    "href": "code/05_rmarkdown.html#creating-and-working-in-scripts",
    "title": "Literate programming",
    "section": "",
    "text": "Open course RStudio project.\nCreate new R script.\nType library(palmerpenguins).\nIs palmerpenguins loaded? How can you check?\nRun the line to load palmerpenguins.\nType print(penguins).\nSource the whole script.\nComment out the print(penguins) line.\nSource the script."
  },
  {
    "objectID": "code/05_rmarkdown.html#creating-and-working-with-r-markdown-files",
    "href": "code/05_rmarkdown.html#creating-and-working-with-r-markdown-files",
    "title": "Literate programming",
    "section": "Creating and working with R Markdown files",
    "text": "Creating and working with R Markdown files\n\nCreate new R Markdown file.\nType “The mean of the first 9 digits is `r mean(1:9)`.”\nKnit/render the document.\nCreate a new code chunk.\nInside the code chunk, load the palmerpenguins package and print the penguins data set.\nRun the code chunk without knitting the file.\nKnit/render the file."
  },
  {
    "objectID": "code/06_datatypes_answers.html",
    "href": "code/06_datatypes_answers.html",
    "title": "Data types",
    "section": "",
    "text": "aa &lt;- 3; bb &lt;- 3L; cc &lt;- \"3\"; dd &lt;- \"TRUE\"; ee &lt;- TRUE; ff &lt;- \"NA\"; gg &lt;- NA\n\naa &lt;- 3\nbb &lt;- 3L\ncc &lt;- \"3\"\ndd &lt;- \"TRUE\"\nee &lt;- TRUE\nff &lt;- \"NA\"\ngg &lt;- NA"
  },
  {
    "objectID": "code/06_datatypes_answers.html#creating-objects",
    "href": "code/06_datatypes_answers.html#creating-objects",
    "title": "Data types",
    "section": "",
    "text": "aa &lt;- 3; bb &lt;- 3L; cc &lt;- \"3\"; dd &lt;- \"TRUE\"; ee &lt;- TRUE; ff &lt;- \"NA\"; gg &lt;- NA\n\naa &lt;- 3\nbb &lt;- 3L\ncc &lt;- \"3\"\ndd &lt;- \"TRUE\"\nee &lt;- TRUE\nff &lt;- \"NA\"\ngg &lt;- NA"
  },
  {
    "objectID": "code/06_datatypes_answers.html#checking-data-types",
    "href": "code/06_datatypes_answers.html#checking-data-types",
    "title": "Data types",
    "section": "Checking data types",
    "text": "Checking data types\n\nGuess what data type each object is then check it.\n\ntypeof(aa)\n\n[1] \"double\"\n\ntypeof(bb)\n\n[1] \"integer\"\n\ntypeof(cc)\n\n[1] \"character\"\n\ntypeof(dd)\n\n[1] \"character\"\n\ntypeof(ee)\n\n[1] \"logical\"\n\ntypeof(ff)\n\n[1] \"character\"\n\ntypeof(gg)\n\n[1] \"logical\"\n\n\n\n\nHow do we test if aa is an integer?\n\nis.integer(aa)\n\n[1] FALSE\n\n\n\n\nWhat will is.logical(dd) return?\n\nis.logical(dd)\n\n[1] FALSE\n\n\n\n\nHow do we test if ff and gg are NA?\n\nis.na(ff)\n\n[1] FALSE\n\nis.na(gg)\n\n[1] TRUE"
  },
  {
    "objectID": "code/06_datatypes_answers.html#checking-if-objects-are-the-same",
    "href": "code/06_datatypes_answers.html#checking-if-objects-are-the-same",
    "title": "Data types",
    "section": "Checking if objects are the same",
    "text": "Checking if objects are the same\n\nAre aa and bb the same? How do we test this?\n\naa\n\n[1] 3\n\nbb\n\n[1] 3\n\naa == bb\n\n[1] TRUE\n\n\n\n\nWhat about aa and cc?\n\naa\n\n[1] 3\n\ncc\n\n[1] \"3\"\n\naa == cc\n\n[1] TRUE\n\n\n\n\nA safer comparison tool is identical(). Test if aa and bb are identical. Then try aa and cc.\n\nidentical(aa, bb)\n\n[1] FALSE\n\nidentical(aa, cc)\n\n[1] FALSE\n\n\n\n\nNow see if aa is identical to 3 and if bb is identical to 3L.\n\nidentical(aa, 3)\n\n[1] TRUE\n\nidentical(bb, 3L)\n\n[1] TRUE"
  },
  {
    "objectID": "code/07_datastructures_answers.html",
    "href": "code/07_datastructures_answers.html",
    "title": "Data structures",
    "section": "",
    "text": "Make a sequence from 0 to 100 in steps of 10.\n\nseq(0, 100, 10)\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\nCreate a repetition of “yes” and “no” with 10 instance of each, alternating between the two. Then make one with 10 “yes” and then 10 “no”.\n\nrep(c(\"yes\", \"no\"), times = 10)\n\n [1] \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n[13] \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n\nrep(c(\"yes\", \"no\"), each = 10)\n\n [1] \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"no\"  \"no\" \n[13] \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\" \n\n\nAdd the argument n = 10 to head(mtcars). What does this do?\n\nhead(mtcars, n =  10)\n\n                   mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360        14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4"
  },
  {
    "objectID": "code/07_datastructures_answers.html#in-class-coding",
    "href": "code/07_datastructures_answers.html#in-class-coding",
    "title": "Data structures",
    "section": "",
    "text": "Make a sequence from 0 to 100 in steps of 10.\n\nseq(0, 100, 10)\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\nCreate a repetition of “yes” and “no” with 10 instance of each, alternating between the two. Then make one with 10 “yes” and then 10 “no”.\n\nrep(c(\"yes\", \"no\"), times = 10)\n\n [1] \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n[13] \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n\nrep(c(\"yes\", \"no\"), each = 10)\n\n [1] \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"yes\" \"no\"  \"no\" \n[13] \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\" \n\n\nAdd the argument n = 10 to head(mtcars). What does this do?\n\nhead(mtcars, n =  10)\n\n                   mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360        14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4"
  },
  {
    "objectID": "code/07_datastructures_answers.html#extra-coding-practice",
    "href": "code/07_datastructures_answers.html#extra-coding-practice",
    "title": "Data structures",
    "section": "Extra coding practice",
    "text": "Extra coding practice\n\nVectors\nCreate a vector called dog_names with the values Bella, Daisy, and Max.\n\ndog_names &lt;- c(\"Bella\", \"Daisy\", \"Max\")\n\nCreate a vector called sex with the values Female, Male, and Male.\n\nsex &lt;- c(\"Female\", \"Female\", \"Male\")\n\nUse the index operator to print to console only Daisy and Max from dog_names.\n\ndog_names[2:3]\n\n[1] \"Daisy\" \"Max\"  \n\n\nReplace the Daisy entry with Luna and print dog_names to console.\n\ndog_names[2] &lt;- \"Luna\"\ndog_names\n\n[1] \"Bella\" \"Luna\"  \"Max\"  \n\n\n\n\nLists\nCopy/paste and run this code: (mylist &lt;- list(a = 1:4, b = c(4, 3, 8, 5), c = LETTERS[10:15], d = c(\"yes\", \"yes\")))\n\n(mylist &lt;- list(a = 1:4, b = c(4, 3, 8, 5), c = LETTERS[10:15], d = c(\"yes\", \"yes\")))\n\n$a\n[1] 1 2 3 4\n\n$b\n[1] 4 3 8 5\n\n$c\n[1] \"J\" \"K\" \"L\" \"M\" \"N\" \"O\"\n\n$d\n[1] \"yes\" \"yes\"\n\n\nCheck the data types for each list element individually.\n\ntypeof(mylist$a)\n\n[1] \"integer\"\n\ntypeof(mylist$b)\n\n[1] \"double\"\n\ntypeof(mylist$c)\n\n[1] \"character\"\n\ntypeof(mylist$d)\n\n[1] \"character\"\n\n\nCheck the data types for each list element with one command.\n\nstr(mylist)\n\nList of 4\n $ a: int [1:4] 1 2 3 4\n $ b: num [1:4] 4 3 8 5\n $ c: chr [1:6] \"J\" \"K\" \"L\" \"M\" ...\n $ d: chr [1:2] \"yes\" \"yes\"\n\n\nCombine list elements a and b into a single vector.\n\nc(mylist$a, mylist$b)\n\n[1] 1 2 3 4 4 3 8 5\n\n\n\n\nData frames\nCreate a data frame called mydf with three columns: x, y, and z and five rows. For x assign any five numbers, for y assign any five character strings, and for z assign any five logical values.\n\n(mydf &lt;- data.frame(x = sample(1:10, 5, replace = TRUE), y = sample(letters, 5), z = sample(c(TRUE, FALSE), 5, replace = TRUE)))\n\n  x y     z\n1 8 p FALSE\n2 2 x FALSE\n3 4 s  TRUE\n4 3 k  TRUE\n5 3 d FALSE\n\n\nCreate a data frame called dogs that combines the dog_names and sex vectors and print to console.\n\n(dogs &lt;- data.frame(dog_names, sex))\n\n  dog_names    sex\n1     Bella Female\n2      Luna Female\n3       Max   Male\n\n\nPrint to console just Luna’s row.\n\ndogs[2, ]\n\n  dog_names    sex\n2      Luna Female\n\n\nPrint to console the number of rows in dogs.\n\nnrow(dogs)\n\n[1] 3"
  },
  {
    "objectID": "code/08_importing_answers.html",
    "href": "code/08_importing_answers.html",
    "title": "Importing data",
    "section": "",
    "text": "Download https://jeffreyrstevens.quarto.pub/dpavir/data/newdata.csv and save it in your data/ directory.\nImport newdata.csv and name it newdata using read.csv().\n\n\nnewdata &lt;- read.csv(here::here(\"data/newdata.csv\"))\n\n\nImport https://jeffreyrstevens.quarto.pub/dpavir/data/newdata2.csv directly from the URL using readr::read_csv().\n\n\nlibrary(readr)\nnewdata2 &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/newdata2.csv\")\n\nRows: 198 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Breed, links, Image\ndbl (8): X2013.Rank, X2014.Rank, X2015.Rank, X2016.Rank, X2017.Rank, X2018.R...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nRepeat the previous import of newdata2.csv, but add the arguments col_select = c(\"Breed\", \"links\") and show_col_types = FALSE and name it newdata3.\n\n\nnewdata3 &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/newdata2.csv\", col_select = c(\"Breed\", \"links\"), show_col_types = FALSE)\n\n\nExport the newdata3 data as a CSV file to your data/ directory.\n\n\nwrite_csv(newdata3, here::here(\"data/newdata3.csv\"))"
  },
  {
    "objectID": "code/09_validating_answers.html",
    "href": "code/09_validating_answers.html",
    "title": "Validating data",
    "section": "",
    "text": "For these exercises, we’ll use the mtcars data set build into base R.\n\nWhat are the dimensions of mtcars?\n\n\ndim(mtcars)\n\n[1] 32 11\n\n\n\nIn one line of code, view the data types for all of the columns in mtcars.\n\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\nWhat is the range of values for the mpg column?\n\n\nrange(mtcars$mpg)\n\n[1] 10.4 33.9\n\n\n\nWhat are all of the possible values used in gear?\n\n\nunique(mtcars$gear)\n\n[1] 4 3 5\n\n\n\nCheck whether the value 5 is found in the carb column.\n\n\n5 %in% mtcars$carb\n\n[1] FALSE\n\n\n\nDo any columns have missing values?\n\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\n\nWhat is the 3rd quartile for mpg?\n\n\nsummary(mtcars$mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\n\n\nCheck whether all horsepower (hp) values fall between 50 and 300. Which row numbers fall out of this range?\n\n\nwhich(mtcars$hp &lt; 50)\n\ninteger(0)\n\nwhich(mtcars$hp &gt; 300)\n\n[1] 31\n\n\n\nMake a codebook for mtcars.\n\n\n#dataReporter::makeCodebook(mtcars, replace = TRUE)"
  },
  {
    "objectID": "code/10_selecting_answers.html",
    "href": "code/10_selecting_answers.html",
    "title": "Selecting columns",
    "section": "",
    "text": "For these exercises, we’ll use the iris data set build into base R.\n\nView iris to see what it looks like.\n\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nReturn a data frame with only the sepal data using inclusion.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nselect(iris, Sepal.Length, Sepal.Width)\n\n    Sepal.Length Sepal.Width\n1            5.1         3.5\n2            4.9         3.0\n3            4.7         3.2\n4            4.6         3.1\n5            5.0         3.6\n6            5.4         3.9\n7            4.6         3.4\n8            5.0         3.4\n9            4.4         2.9\n10           4.9         3.1\n11           5.4         3.7\n12           4.8         3.4\n13           4.8         3.0\n14           4.3         3.0\n15           5.8         4.0\n16           5.7         4.4\n17           5.4         3.9\n18           5.1         3.5\n19           5.7         3.8\n20           5.1         3.8\n21           5.4         3.4\n22           5.1         3.7\n23           4.6         3.6\n24           5.1         3.3\n25           4.8         3.4\n26           5.0         3.0\n27           5.0         3.4\n28           5.2         3.5\n29           5.2         3.4\n30           4.7         3.2\n31           4.8         3.1\n32           5.4         3.4\n33           5.2         4.1\n34           5.5         4.2\n35           4.9         3.1\n36           5.0         3.2\n37           5.5         3.5\n38           4.9         3.6\n39           4.4         3.0\n40           5.1         3.4\n41           5.0         3.5\n42           4.5         2.3\n43           4.4         3.2\n44           5.0         3.5\n45           5.1         3.8\n46           4.8         3.0\n47           5.1         3.8\n48           4.6         3.2\n49           5.3         3.7\n50           5.0         3.3\n51           7.0         3.2\n52           6.4         3.2\n53           6.9         3.1\n54           5.5         2.3\n55           6.5         2.8\n56           5.7         2.8\n57           6.3         3.3\n58           4.9         2.4\n59           6.6         2.9\n60           5.2         2.7\n61           5.0         2.0\n62           5.9         3.0\n63           6.0         2.2\n64           6.1         2.9\n65           5.6         2.9\n66           6.7         3.1\n67           5.6         3.0\n68           5.8         2.7\n69           6.2         2.2\n70           5.6         2.5\n71           5.9         3.2\n72           6.1         2.8\n73           6.3         2.5\n74           6.1         2.8\n75           6.4         2.9\n76           6.6         3.0\n77           6.8         2.8\n78           6.7         3.0\n79           6.0         2.9\n80           5.7         2.6\n81           5.5         2.4\n82           5.5         2.4\n83           5.8         2.7\n84           6.0         2.7\n85           5.4         3.0\n86           6.0         3.4\n87           6.7         3.1\n88           6.3         2.3\n89           5.6         3.0\n90           5.5         2.5\n91           5.5         2.6\n92           6.1         3.0\n93           5.8         2.6\n94           5.0         2.3\n95           5.6         2.7\n96           5.7         3.0\n97           5.7         2.9\n98           6.2         2.9\n99           5.1         2.5\n100          5.7         2.8\n101          6.3         3.3\n102          5.8         2.7\n103          7.1         3.0\n104          6.3         2.9\n105          6.5         3.0\n106          7.6         3.0\n107          4.9         2.5\n108          7.3         2.9\n109          6.7         2.5\n110          7.2         3.6\n111          6.5         3.2\n112          6.4         2.7\n113          6.8         3.0\n114          5.7         2.5\n115          5.8         2.8\n116          6.4         3.2\n117          6.5         3.0\n118          7.7         3.8\n119          7.7         2.6\n120          6.0         2.2\n121          6.9         3.2\n122          5.6         2.8\n123          7.7         2.8\n124          6.3         2.7\n125          6.7         3.3\n126          7.2         3.2\n127          6.2         2.8\n128          6.1         3.0\n129          6.4         2.8\n130          7.2         3.0\n131          7.4         2.8\n132          7.9         3.8\n133          6.4         2.8\n134          6.3         2.8\n135          6.1         2.6\n136          7.7         3.0\n137          6.3         3.4\n138          6.4         3.1\n139          6.0         3.0\n140          6.9         3.1\n141          6.7         3.1\n142          6.9         3.1\n143          5.8         2.7\n144          6.8         3.2\n145          6.7         3.3\n146          6.7         3.0\n147          6.3         2.5\n148          6.5         3.0\n149          6.2         3.4\n150          5.9         3.0\n\n\n\nReturn a data frame with only the sepal data using a helper function.\n\n\nselect(iris, contains(\"Sepal\"))\n\n    Sepal.Length Sepal.Width\n1            5.1         3.5\n2            4.9         3.0\n3            4.7         3.2\n4            4.6         3.1\n5            5.0         3.6\n6            5.4         3.9\n7            4.6         3.4\n8            5.0         3.4\n9            4.4         2.9\n10           4.9         3.1\n11           5.4         3.7\n12           4.8         3.4\n13           4.8         3.0\n14           4.3         3.0\n15           5.8         4.0\n16           5.7         4.4\n17           5.4         3.9\n18           5.1         3.5\n19           5.7         3.8\n20           5.1         3.8\n21           5.4         3.4\n22           5.1         3.7\n23           4.6         3.6\n24           5.1         3.3\n25           4.8         3.4\n26           5.0         3.0\n27           5.0         3.4\n28           5.2         3.5\n29           5.2         3.4\n30           4.7         3.2\n31           4.8         3.1\n32           5.4         3.4\n33           5.2         4.1\n34           5.5         4.2\n35           4.9         3.1\n36           5.0         3.2\n37           5.5         3.5\n38           4.9         3.6\n39           4.4         3.0\n40           5.1         3.4\n41           5.0         3.5\n42           4.5         2.3\n43           4.4         3.2\n44           5.0         3.5\n45           5.1         3.8\n46           4.8         3.0\n47           5.1         3.8\n48           4.6         3.2\n49           5.3         3.7\n50           5.0         3.3\n51           7.0         3.2\n52           6.4         3.2\n53           6.9         3.1\n54           5.5         2.3\n55           6.5         2.8\n56           5.7         2.8\n57           6.3         3.3\n58           4.9         2.4\n59           6.6         2.9\n60           5.2         2.7\n61           5.0         2.0\n62           5.9         3.0\n63           6.0         2.2\n64           6.1         2.9\n65           5.6         2.9\n66           6.7         3.1\n67           5.6         3.0\n68           5.8         2.7\n69           6.2         2.2\n70           5.6         2.5\n71           5.9         3.2\n72           6.1         2.8\n73           6.3         2.5\n74           6.1         2.8\n75           6.4         2.9\n76           6.6         3.0\n77           6.8         2.8\n78           6.7         3.0\n79           6.0         2.9\n80           5.7         2.6\n81           5.5         2.4\n82           5.5         2.4\n83           5.8         2.7\n84           6.0         2.7\n85           5.4         3.0\n86           6.0         3.4\n87           6.7         3.1\n88           6.3         2.3\n89           5.6         3.0\n90           5.5         2.5\n91           5.5         2.6\n92           6.1         3.0\n93           5.8         2.6\n94           5.0         2.3\n95           5.6         2.7\n96           5.7         3.0\n97           5.7         2.9\n98           6.2         2.9\n99           5.1         2.5\n100          5.7         2.8\n101          6.3         3.3\n102          5.8         2.7\n103          7.1         3.0\n104          6.3         2.9\n105          6.5         3.0\n106          7.6         3.0\n107          4.9         2.5\n108          7.3         2.9\n109          6.7         2.5\n110          7.2         3.6\n111          6.5         3.2\n112          6.4         2.7\n113          6.8         3.0\n114          5.7         2.5\n115          5.8         2.8\n116          6.4         3.2\n117          6.5         3.0\n118          7.7         3.8\n119          7.7         2.6\n120          6.0         2.2\n121          6.9         3.2\n122          5.6         2.8\n123          7.7         2.8\n124          6.3         2.7\n125          6.7         3.3\n126          7.2         3.2\n127          6.2         2.8\n128          6.1         3.0\n129          6.4         2.8\n130          7.2         3.0\n131          7.4         2.8\n132          7.9         3.8\n133          6.4         2.8\n134          6.3         2.8\n135          6.1         2.6\n136          7.7         3.0\n137          6.3         3.4\n138          6.4         3.1\n139          6.0         3.0\n140          6.9         3.1\n141          6.7         3.1\n142          6.9         3.1\n143          5.8         2.7\n144          6.8         3.2\n145          6.7         3.3\n146          6.7         3.0\n147          6.3         2.5\n148          6.5         3.0\n149          6.2         3.4\n150          5.9         3.0\n\n\n\nReturn a data frame with the sepal and petal data using a helper function.\n\n\nselect(iris, Sepal.Length:Petal.Width)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width\n1            5.1         3.5          1.4         0.2\n2            4.9         3.0          1.4         0.2\n3            4.7         3.2          1.3         0.2\n4            4.6         3.1          1.5         0.2\n5            5.0         3.6          1.4         0.2\n6            5.4         3.9          1.7         0.4\n7            4.6         3.4          1.4         0.3\n8            5.0         3.4          1.5         0.2\n9            4.4         2.9          1.4         0.2\n10           4.9         3.1          1.5         0.1\n11           5.4         3.7          1.5         0.2\n12           4.8         3.4          1.6         0.2\n13           4.8         3.0          1.4         0.1\n14           4.3         3.0          1.1         0.1\n15           5.8         4.0          1.2         0.2\n16           5.7         4.4          1.5         0.4\n17           5.4         3.9          1.3         0.4\n18           5.1         3.5          1.4         0.3\n19           5.7         3.8          1.7         0.3\n20           5.1         3.8          1.5         0.3\n21           5.4         3.4          1.7         0.2\n22           5.1         3.7          1.5         0.4\n23           4.6         3.6          1.0         0.2\n24           5.1         3.3          1.7         0.5\n25           4.8         3.4          1.9         0.2\n26           5.0         3.0          1.6         0.2\n27           5.0         3.4          1.6         0.4\n28           5.2         3.5          1.5         0.2\n29           5.2         3.4          1.4         0.2\n30           4.7         3.2          1.6         0.2\n31           4.8         3.1          1.6         0.2\n32           5.4         3.4          1.5         0.4\n33           5.2         4.1          1.5         0.1\n34           5.5         4.2          1.4         0.2\n35           4.9         3.1          1.5         0.2\n36           5.0         3.2          1.2         0.2\n37           5.5         3.5          1.3         0.2\n38           4.9         3.6          1.4         0.1\n39           4.4         3.0          1.3         0.2\n40           5.1         3.4          1.5         0.2\n41           5.0         3.5          1.3         0.3\n42           4.5         2.3          1.3         0.3\n43           4.4         3.2          1.3         0.2\n44           5.0         3.5          1.6         0.6\n45           5.1         3.8          1.9         0.4\n46           4.8         3.0          1.4         0.3\n47           5.1         3.8          1.6         0.2\n48           4.6         3.2          1.4         0.2\n49           5.3         3.7          1.5         0.2\n50           5.0         3.3          1.4         0.2\n51           7.0         3.2          4.7         1.4\n52           6.4         3.2          4.5         1.5\n53           6.9         3.1          4.9         1.5\n54           5.5         2.3          4.0         1.3\n55           6.5         2.8          4.6         1.5\n56           5.7         2.8          4.5         1.3\n57           6.3         3.3          4.7         1.6\n58           4.9         2.4          3.3         1.0\n59           6.6         2.9          4.6         1.3\n60           5.2         2.7          3.9         1.4\n61           5.0         2.0          3.5         1.0\n62           5.9         3.0          4.2         1.5\n63           6.0         2.2          4.0         1.0\n64           6.1         2.9          4.7         1.4\n65           5.6         2.9          3.6         1.3\n66           6.7         3.1          4.4         1.4\n67           5.6         3.0          4.5         1.5\n68           5.8         2.7          4.1         1.0\n69           6.2         2.2          4.5         1.5\n70           5.6         2.5          3.9         1.1\n71           5.9         3.2          4.8         1.8\n72           6.1         2.8          4.0         1.3\n73           6.3         2.5          4.9         1.5\n74           6.1         2.8          4.7         1.2\n75           6.4         2.9          4.3         1.3\n76           6.6         3.0          4.4         1.4\n77           6.8         2.8          4.8         1.4\n78           6.7         3.0          5.0         1.7\n79           6.0         2.9          4.5         1.5\n80           5.7         2.6          3.5         1.0\n81           5.5         2.4          3.8         1.1\n82           5.5         2.4          3.7         1.0\n83           5.8         2.7          3.9         1.2\n84           6.0         2.7          5.1         1.6\n85           5.4         3.0          4.5         1.5\n86           6.0         3.4          4.5         1.6\n87           6.7         3.1          4.7         1.5\n88           6.3         2.3          4.4         1.3\n89           5.6         3.0          4.1         1.3\n90           5.5         2.5          4.0         1.3\n91           5.5         2.6          4.4         1.2\n92           6.1         3.0          4.6         1.4\n93           5.8         2.6          4.0         1.2\n94           5.0         2.3          3.3         1.0\n95           5.6         2.7          4.2         1.3\n96           5.7         3.0          4.2         1.2\n97           5.7         2.9          4.2         1.3\n98           6.2         2.9          4.3         1.3\n99           5.1         2.5          3.0         1.1\n100          5.7         2.8          4.1         1.3\n101          6.3         3.3          6.0         2.5\n102          5.8         2.7          5.1         1.9\n103          7.1         3.0          5.9         2.1\n104          6.3         2.9          5.6         1.8\n105          6.5         3.0          5.8         2.2\n106          7.6         3.0          6.6         2.1\n107          4.9         2.5          4.5         1.7\n108          7.3         2.9          6.3         1.8\n109          6.7         2.5          5.8         1.8\n110          7.2         3.6          6.1         2.5\n111          6.5         3.2          5.1         2.0\n112          6.4         2.7          5.3         1.9\n113          6.8         3.0          5.5         2.1\n114          5.7         2.5          5.0         2.0\n115          5.8         2.8          5.1         2.4\n116          6.4         3.2          5.3         2.3\n117          6.5         3.0          5.5         1.8\n118          7.7         3.8          6.7         2.2\n119          7.7         2.6          6.9         2.3\n120          6.0         2.2          5.0         1.5\n121          6.9         3.2          5.7         2.3\n122          5.6         2.8          4.9         2.0\n123          7.7         2.8          6.7         2.0\n124          6.3         2.7          4.9         1.8\n125          6.7         3.3          5.7         2.1\n126          7.2         3.2          6.0         1.8\n127          6.2         2.8          4.8         1.8\n128          6.1         3.0          4.9         1.8\n129          6.4         2.8          5.6         2.1\n130          7.2         3.0          5.8         1.6\n131          7.4         2.8          6.1         1.9\n132          7.9         3.8          6.4         2.0\n133          6.4         2.8          5.6         2.2\n134          6.3         2.8          5.1         1.5\n135          6.1         2.6          5.6         1.4\n136          7.7         3.0          6.1         2.3\n137          6.3         3.4          5.6         2.4\n138          6.4         3.1          5.5         1.8\n139          6.0         3.0          4.8         1.8\n140          6.9         3.1          5.4         2.1\n141          6.7         3.1          5.6         2.4\n142          6.9         3.1          5.1         2.3\n143          5.8         2.7          5.1         1.9\n144          6.8         3.2          5.9         2.3\n145          6.7         3.3          5.7         2.5\n146          6.7         3.0          5.2         2.3\n147          6.3         2.5          5.0         1.9\n148          6.5         3.0          5.2         2.0\n149          6.2         3.4          5.4         2.3\n150          5.9         3.0          5.1         1.8\n\n\n\nReturn a data frame with the sepal and petal data using exclusion.\n\n\nselect(iris, -Species)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width\n1            5.1         3.5          1.4         0.2\n2            4.9         3.0          1.4         0.2\n3            4.7         3.2          1.3         0.2\n4            4.6         3.1          1.5         0.2\n5            5.0         3.6          1.4         0.2\n6            5.4         3.9          1.7         0.4\n7            4.6         3.4          1.4         0.3\n8            5.0         3.4          1.5         0.2\n9            4.4         2.9          1.4         0.2\n10           4.9         3.1          1.5         0.1\n11           5.4         3.7          1.5         0.2\n12           4.8         3.4          1.6         0.2\n13           4.8         3.0          1.4         0.1\n14           4.3         3.0          1.1         0.1\n15           5.8         4.0          1.2         0.2\n16           5.7         4.4          1.5         0.4\n17           5.4         3.9          1.3         0.4\n18           5.1         3.5          1.4         0.3\n19           5.7         3.8          1.7         0.3\n20           5.1         3.8          1.5         0.3\n21           5.4         3.4          1.7         0.2\n22           5.1         3.7          1.5         0.4\n23           4.6         3.6          1.0         0.2\n24           5.1         3.3          1.7         0.5\n25           4.8         3.4          1.9         0.2\n26           5.0         3.0          1.6         0.2\n27           5.0         3.4          1.6         0.4\n28           5.2         3.5          1.5         0.2\n29           5.2         3.4          1.4         0.2\n30           4.7         3.2          1.6         0.2\n31           4.8         3.1          1.6         0.2\n32           5.4         3.4          1.5         0.4\n33           5.2         4.1          1.5         0.1\n34           5.5         4.2          1.4         0.2\n35           4.9         3.1          1.5         0.2\n36           5.0         3.2          1.2         0.2\n37           5.5         3.5          1.3         0.2\n38           4.9         3.6          1.4         0.1\n39           4.4         3.0          1.3         0.2\n40           5.1         3.4          1.5         0.2\n41           5.0         3.5          1.3         0.3\n42           4.5         2.3          1.3         0.3\n43           4.4         3.2          1.3         0.2\n44           5.0         3.5          1.6         0.6\n45           5.1         3.8          1.9         0.4\n46           4.8         3.0          1.4         0.3\n47           5.1         3.8          1.6         0.2\n48           4.6         3.2          1.4         0.2\n49           5.3         3.7          1.5         0.2\n50           5.0         3.3          1.4         0.2\n51           7.0         3.2          4.7         1.4\n52           6.4         3.2          4.5         1.5\n53           6.9         3.1          4.9         1.5\n54           5.5         2.3          4.0         1.3\n55           6.5         2.8          4.6         1.5\n56           5.7         2.8          4.5         1.3\n57           6.3         3.3          4.7         1.6\n58           4.9         2.4          3.3         1.0\n59           6.6         2.9          4.6         1.3\n60           5.2         2.7          3.9         1.4\n61           5.0         2.0          3.5         1.0\n62           5.9         3.0          4.2         1.5\n63           6.0         2.2          4.0         1.0\n64           6.1         2.9          4.7         1.4\n65           5.6         2.9          3.6         1.3\n66           6.7         3.1          4.4         1.4\n67           5.6         3.0          4.5         1.5\n68           5.8         2.7          4.1         1.0\n69           6.2         2.2          4.5         1.5\n70           5.6         2.5          3.9         1.1\n71           5.9         3.2          4.8         1.8\n72           6.1         2.8          4.0         1.3\n73           6.3         2.5          4.9         1.5\n74           6.1         2.8          4.7         1.2\n75           6.4         2.9          4.3         1.3\n76           6.6         3.0          4.4         1.4\n77           6.8         2.8          4.8         1.4\n78           6.7         3.0          5.0         1.7\n79           6.0         2.9          4.5         1.5\n80           5.7         2.6          3.5         1.0\n81           5.5         2.4          3.8         1.1\n82           5.5         2.4          3.7         1.0\n83           5.8         2.7          3.9         1.2\n84           6.0         2.7          5.1         1.6\n85           5.4         3.0          4.5         1.5\n86           6.0         3.4          4.5         1.6\n87           6.7         3.1          4.7         1.5\n88           6.3         2.3          4.4         1.3\n89           5.6         3.0          4.1         1.3\n90           5.5         2.5          4.0         1.3\n91           5.5         2.6          4.4         1.2\n92           6.1         3.0          4.6         1.4\n93           5.8         2.6          4.0         1.2\n94           5.0         2.3          3.3         1.0\n95           5.6         2.7          4.2         1.3\n96           5.7         3.0          4.2         1.2\n97           5.7         2.9          4.2         1.3\n98           6.2         2.9          4.3         1.3\n99           5.1         2.5          3.0         1.1\n100          5.7         2.8          4.1         1.3\n101          6.3         3.3          6.0         2.5\n102          5.8         2.7          5.1         1.9\n103          7.1         3.0          5.9         2.1\n104          6.3         2.9          5.6         1.8\n105          6.5         3.0          5.8         2.2\n106          7.6         3.0          6.6         2.1\n107          4.9         2.5          4.5         1.7\n108          7.3         2.9          6.3         1.8\n109          6.7         2.5          5.8         1.8\n110          7.2         3.6          6.1         2.5\n111          6.5         3.2          5.1         2.0\n112          6.4         2.7          5.3         1.9\n113          6.8         3.0          5.5         2.1\n114          5.7         2.5          5.0         2.0\n115          5.8         2.8          5.1         2.4\n116          6.4         3.2          5.3         2.3\n117          6.5         3.0          5.5         1.8\n118          7.7         3.8          6.7         2.2\n119          7.7         2.6          6.9         2.3\n120          6.0         2.2          5.0         1.5\n121          6.9         3.2          5.7         2.3\n122          5.6         2.8          4.9         2.0\n123          7.7         2.8          6.7         2.0\n124          6.3         2.7          4.9         1.8\n125          6.7         3.3          5.7         2.1\n126          7.2         3.2          6.0         1.8\n127          6.2         2.8          4.8         1.8\n128          6.1         3.0          4.9         1.8\n129          6.4         2.8          5.6         2.1\n130          7.2         3.0          5.8         1.6\n131          7.4         2.8          6.1         1.9\n132          7.9         3.8          6.4         2.0\n133          6.4         2.8          5.6         2.2\n134          6.3         2.8          5.1         1.5\n135          6.1         2.6          5.6         1.4\n136          7.7         3.0          6.1         2.3\n137          6.3         3.4          5.6         2.4\n138          6.4         3.1          5.5         1.8\n139          6.0         3.0          4.8         1.8\n140          6.9         3.1          5.4         2.1\n141          6.7         3.1          5.6         2.4\n142          6.9         3.1          5.1         2.3\n143          5.8         2.7          5.1         1.9\n144          6.8         3.2          5.9         2.3\n145          6.7         3.3          5.7         2.5\n146          6.7         3.0          5.2         2.3\n147          6.3         2.5          5.0         1.9\n148          6.5         3.0          5.2         2.0\n149          6.2         3.4          5.4         2.3\n150          5.9         3.0          5.1         1.8\n\n\n\nMove Species to be the first column using select() and a helper function.\n\n\nselect(iris, Species, everything())\n\n       Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1       setosa          5.1         3.5          1.4         0.2\n2       setosa          4.9         3.0          1.4         0.2\n3       setosa          4.7         3.2          1.3         0.2\n4       setosa          4.6         3.1          1.5         0.2\n5       setosa          5.0         3.6          1.4         0.2\n6       setosa          5.4         3.9          1.7         0.4\n7       setosa          4.6         3.4          1.4         0.3\n8       setosa          5.0         3.4          1.5         0.2\n9       setosa          4.4         2.9          1.4         0.2\n10      setosa          4.9         3.1          1.5         0.1\n11      setosa          5.4         3.7          1.5         0.2\n12      setosa          4.8         3.4          1.6         0.2\n13      setosa          4.8         3.0          1.4         0.1\n14      setosa          4.3         3.0          1.1         0.1\n15      setosa          5.8         4.0          1.2         0.2\n16      setosa          5.7         4.4          1.5         0.4\n17      setosa          5.4         3.9          1.3         0.4\n18      setosa          5.1         3.5          1.4         0.3\n19      setosa          5.7         3.8          1.7         0.3\n20      setosa          5.1         3.8          1.5         0.3\n21      setosa          5.4         3.4          1.7         0.2\n22      setosa          5.1         3.7          1.5         0.4\n23      setosa          4.6         3.6          1.0         0.2\n24      setosa          5.1         3.3          1.7         0.5\n25      setosa          4.8         3.4          1.9         0.2\n26      setosa          5.0         3.0          1.6         0.2\n27      setosa          5.0         3.4          1.6         0.4\n28      setosa          5.2         3.5          1.5         0.2\n29      setosa          5.2         3.4          1.4         0.2\n30      setosa          4.7         3.2          1.6         0.2\n31      setosa          4.8         3.1          1.6         0.2\n32      setosa          5.4         3.4          1.5         0.4\n33      setosa          5.2         4.1          1.5         0.1\n34      setosa          5.5         4.2          1.4         0.2\n35      setosa          4.9         3.1          1.5         0.2\n36      setosa          5.0         3.2          1.2         0.2\n37      setosa          5.5         3.5          1.3         0.2\n38      setosa          4.9         3.6          1.4         0.1\n39      setosa          4.4         3.0          1.3         0.2\n40      setosa          5.1         3.4          1.5         0.2\n41      setosa          5.0         3.5          1.3         0.3\n42      setosa          4.5         2.3          1.3         0.3\n43      setosa          4.4         3.2          1.3         0.2\n44      setosa          5.0         3.5          1.6         0.6\n45      setosa          5.1         3.8          1.9         0.4\n46      setosa          4.8         3.0          1.4         0.3\n47      setosa          5.1         3.8          1.6         0.2\n48      setosa          4.6         3.2          1.4         0.2\n49      setosa          5.3         3.7          1.5         0.2\n50      setosa          5.0         3.3          1.4         0.2\n51  versicolor          7.0         3.2          4.7         1.4\n52  versicolor          6.4         3.2          4.5         1.5\n53  versicolor          6.9         3.1          4.9         1.5\n54  versicolor          5.5         2.3          4.0         1.3\n55  versicolor          6.5         2.8          4.6         1.5\n56  versicolor          5.7         2.8          4.5         1.3\n57  versicolor          6.3         3.3          4.7         1.6\n58  versicolor          4.9         2.4          3.3         1.0\n59  versicolor          6.6         2.9          4.6         1.3\n60  versicolor          5.2         2.7          3.9         1.4\n61  versicolor          5.0         2.0          3.5         1.0\n62  versicolor          5.9         3.0          4.2         1.5\n63  versicolor          6.0         2.2          4.0         1.0\n64  versicolor          6.1         2.9          4.7         1.4\n65  versicolor          5.6         2.9          3.6         1.3\n66  versicolor          6.7         3.1          4.4         1.4\n67  versicolor          5.6         3.0          4.5         1.5\n68  versicolor          5.8         2.7          4.1         1.0\n69  versicolor          6.2         2.2          4.5         1.5\n70  versicolor          5.6         2.5          3.9         1.1\n71  versicolor          5.9         3.2          4.8         1.8\n72  versicolor          6.1         2.8          4.0         1.3\n73  versicolor          6.3         2.5          4.9         1.5\n74  versicolor          6.1         2.8          4.7         1.2\n75  versicolor          6.4         2.9          4.3         1.3\n76  versicolor          6.6         3.0          4.4         1.4\n77  versicolor          6.8         2.8          4.8         1.4\n78  versicolor          6.7         3.0          5.0         1.7\n79  versicolor          6.0         2.9          4.5         1.5\n80  versicolor          5.7         2.6          3.5         1.0\n81  versicolor          5.5         2.4          3.8         1.1\n82  versicolor          5.5         2.4          3.7         1.0\n83  versicolor          5.8         2.7          3.9         1.2\n84  versicolor          6.0         2.7          5.1         1.6\n85  versicolor          5.4         3.0          4.5         1.5\n86  versicolor          6.0         3.4          4.5         1.6\n87  versicolor          6.7         3.1          4.7         1.5\n88  versicolor          6.3         2.3          4.4         1.3\n89  versicolor          5.6         3.0          4.1         1.3\n90  versicolor          5.5         2.5          4.0         1.3\n91  versicolor          5.5         2.6          4.4         1.2\n92  versicolor          6.1         3.0          4.6         1.4\n93  versicolor          5.8         2.6          4.0         1.2\n94  versicolor          5.0         2.3          3.3         1.0\n95  versicolor          5.6         2.7          4.2         1.3\n96  versicolor          5.7         3.0          4.2         1.2\n97  versicolor          5.7         2.9          4.2         1.3\n98  versicolor          6.2         2.9          4.3         1.3\n99  versicolor          5.1         2.5          3.0         1.1\n100 versicolor          5.7         2.8          4.1         1.3\n101  virginica          6.3         3.3          6.0         2.5\n102  virginica          5.8         2.7          5.1         1.9\n103  virginica          7.1         3.0          5.9         2.1\n104  virginica          6.3         2.9          5.6         1.8\n105  virginica          6.5         3.0          5.8         2.2\n106  virginica          7.6         3.0          6.6         2.1\n107  virginica          4.9         2.5          4.5         1.7\n108  virginica          7.3         2.9          6.3         1.8\n109  virginica          6.7         2.5          5.8         1.8\n110  virginica          7.2         3.6          6.1         2.5\n111  virginica          6.5         3.2          5.1         2.0\n112  virginica          6.4         2.7          5.3         1.9\n113  virginica          6.8         3.0          5.5         2.1\n114  virginica          5.7         2.5          5.0         2.0\n115  virginica          5.8         2.8          5.1         2.4\n116  virginica          6.4         3.2          5.3         2.3\n117  virginica          6.5         3.0          5.5         1.8\n118  virginica          7.7         3.8          6.7         2.2\n119  virginica          7.7         2.6          6.9         2.3\n120  virginica          6.0         2.2          5.0         1.5\n121  virginica          6.9         3.2          5.7         2.3\n122  virginica          5.6         2.8          4.9         2.0\n123  virginica          7.7         2.8          6.7         2.0\n124  virginica          6.3         2.7          4.9         1.8\n125  virginica          6.7         3.3          5.7         2.1\n126  virginica          7.2         3.2          6.0         1.8\n127  virginica          6.2         2.8          4.8         1.8\n128  virginica          6.1         3.0          4.9         1.8\n129  virginica          6.4         2.8          5.6         2.1\n130  virginica          7.2         3.0          5.8         1.6\n131  virginica          7.4         2.8          6.1         1.9\n132  virginica          7.9         3.8          6.4         2.0\n133  virginica          6.4         2.8          5.6         2.2\n134  virginica          6.3         2.8          5.1         1.5\n135  virginica          6.1         2.6          5.6         1.4\n136  virginica          7.7         3.0          6.1         2.3\n137  virginica          6.3         3.4          5.6         2.4\n138  virginica          6.4         3.1          5.5         1.8\n139  virginica          6.0         3.0          4.8         1.8\n140  virginica          6.9         3.1          5.4         2.1\n141  virginica          6.7         3.1          5.6         2.4\n142  virginica          6.9         3.1          5.1         2.3\n143  virginica          5.8         2.7          5.1         1.9\n144  virginica          6.8         3.2          5.9         2.3\n145  virginica          6.7         3.3          5.7         2.5\n146  virginica          6.7         3.0          5.2         2.3\n147  virginica          6.3         2.5          5.0         1.9\n148  virginica          6.5         3.0          5.2         2.0\n149  virginica          6.2         3.4          5.4         2.3\n150  virginica          5.9         3.0          5.1         1.8\n\n\n\nMove Species to be the first column using relocate().\n\n\nrelocate(iris, Species, .before = 1)\n\n       Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1       setosa          5.1         3.5          1.4         0.2\n2       setosa          4.9         3.0          1.4         0.2\n3       setosa          4.7         3.2          1.3         0.2\n4       setosa          4.6         3.1          1.5         0.2\n5       setosa          5.0         3.6          1.4         0.2\n6       setosa          5.4         3.9          1.7         0.4\n7       setosa          4.6         3.4          1.4         0.3\n8       setosa          5.0         3.4          1.5         0.2\n9       setosa          4.4         2.9          1.4         0.2\n10      setosa          4.9         3.1          1.5         0.1\n11      setosa          5.4         3.7          1.5         0.2\n12      setosa          4.8         3.4          1.6         0.2\n13      setosa          4.8         3.0          1.4         0.1\n14      setosa          4.3         3.0          1.1         0.1\n15      setosa          5.8         4.0          1.2         0.2\n16      setosa          5.7         4.4          1.5         0.4\n17      setosa          5.4         3.9          1.3         0.4\n18      setosa          5.1         3.5          1.4         0.3\n19      setosa          5.7         3.8          1.7         0.3\n20      setosa          5.1         3.8          1.5         0.3\n21      setosa          5.4         3.4          1.7         0.2\n22      setosa          5.1         3.7          1.5         0.4\n23      setosa          4.6         3.6          1.0         0.2\n24      setosa          5.1         3.3          1.7         0.5\n25      setosa          4.8         3.4          1.9         0.2\n26      setosa          5.0         3.0          1.6         0.2\n27      setosa          5.0         3.4          1.6         0.4\n28      setosa          5.2         3.5          1.5         0.2\n29      setosa          5.2         3.4          1.4         0.2\n30      setosa          4.7         3.2          1.6         0.2\n31      setosa          4.8         3.1          1.6         0.2\n32      setosa          5.4         3.4          1.5         0.4\n33      setosa          5.2         4.1          1.5         0.1\n34      setosa          5.5         4.2          1.4         0.2\n35      setosa          4.9         3.1          1.5         0.2\n36      setosa          5.0         3.2          1.2         0.2\n37      setosa          5.5         3.5          1.3         0.2\n38      setosa          4.9         3.6          1.4         0.1\n39      setosa          4.4         3.0          1.3         0.2\n40      setosa          5.1         3.4          1.5         0.2\n41      setosa          5.0         3.5          1.3         0.3\n42      setosa          4.5         2.3          1.3         0.3\n43      setosa          4.4         3.2          1.3         0.2\n44      setosa          5.0         3.5          1.6         0.6\n45      setosa          5.1         3.8          1.9         0.4\n46      setosa          4.8         3.0          1.4         0.3\n47      setosa          5.1         3.8          1.6         0.2\n48      setosa          4.6         3.2          1.4         0.2\n49      setosa          5.3         3.7          1.5         0.2\n50      setosa          5.0         3.3          1.4         0.2\n51  versicolor          7.0         3.2          4.7         1.4\n52  versicolor          6.4         3.2          4.5         1.5\n53  versicolor          6.9         3.1          4.9         1.5\n54  versicolor          5.5         2.3          4.0         1.3\n55  versicolor          6.5         2.8          4.6         1.5\n56  versicolor          5.7         2.8          4.5         1.3\n57  versicolor          6.3         3.3          4.7         1.6\n58  versicolor          4.9         2.4          3.3         1.0\n59  versicolor          6.6         2.9          4.6         1.3\n60  versicolor          5.2         2.7          3.9         1.4\n61  versicolor          5.0         2.0          3.5         1.0\n62  versicolor          5.9         3.0          4.2         1.5\n63  versicolor          6.0         2.2          4.0         1.0\n64  versicolor          6.1         2.9          4.7         1.4\n65  versicolor          5.6         2.9          3.6         1.3\n66  versicolor          6.7         3.1          4.4         1.4\n67  versicolor          5.6         3.0          4.5         1.5\n68  versicolor          5.8         2.7          4.1         1.0\n69  versicolor          6.2         2.2          4.5         1.5\n70  versicolor          5.6         2.5          3.9         1.1\n71  versicolor          5.9         3.2          4.8         1.8\n72  versicolor          6.1         2.8          4.0         1.3\n73  versicolor          6.3         2.5          4.9         1.5\n74  versicolor          6.1         2.8          4.7         1.2\n75  versicolor          6.4         2.9          4.3         1.3\n76  versicolor          6.6         3.0          4.4         1.4\n77  versicolor          6.8         2.8          4.8         1.4\n78  versicolor          6.7         3.0          5.0         1.7\n79  versicolor          6.0         2.9          4.5         1.5\n80  versicolor          5.7         2.6          3.5         1.0\n81  versicolor          5.5         2.4          3.8         1.1\n82  versicolor          5.5         2.4          3.7         1.0\n83  versicolor          5.8         2.7          3.9         1.2\n84  versicolor          6.0         2.7          5.1         1.6\n85  versicolor          5.4         3.0          4.5         1.5\n86  versicolor          6.0         3.4          4.5         1.6\n87  versicolor          6.7         3.1          4.7         1.5\n88  versicolor          6.3         2.3          4.4         1.3\n89  versicolor          5.6         3.0          4.1         1.3\n90  versicolor          5.5         2.5          4.0         1.3\n91  versicolor          5.5         2.6          4.4         1.2\n92  versicolor          6.1         3.0          4.6         1.4\n93  versicolor          5.8         2.6          4.0         1.2\n94  versicolor          5.0         2.3          3.3         1.0\n95  versicolor          5.6         2.7          4.2         1.3\n96  versicolor          5.7         3.0          4.2         1.2\n97  versicolor          5.7         2.9          4.2         1.3\n98  versicolor          6.2         2.9          4.3         1.3\n99  versicolor          5.1         2.5          3.0         1.1\n100 versicolor          5.7         2.8          4.1         1.3\n101  virginica          6.3         3.3          6.0         2.5\n102  virginica          5.8         2.7          5.1         1.9\n103  virginica          7.1         3.0          5.9         2.1\n104  virginica          6.3         2.9          5.6         1.8\n105  virginica          6.5         3.0          5.8         2.2\n106  virginica          7.6         3.0          6.6         2.1\n107  virginica          4.9         2.5          4.5         1.7\n108  virginica          7.3         2.9          6.3         1.8\n109  virginica          6.7         2.5          5.8         1.8\n110  virginica          7.2         3.6          6.1         2.5\n111  virginica          6.5         3.2          5.1         2.0\n112  virginica          6.4         2.7          5.3         1.9\n113  virginica          6.8         3.0          5.5         2.1\n114  virginica          5.7         2.5          5.0         2.0\n115  virginica          5.8         2.8          5.1         2.4\n116  virginica          6.4         3.2          5.3         2.3\n117  virginica          6.5         3.0          5.5         1.8\n118  virginica          7.7         3.8          6.7         2.2\n119  virginica          7.7         2.6          6.9         2.3\n120  virginica          6.0         2.2          5.0         1.5\n121  virginica          6.9         3.2          5.7         2.3\n122  virginica          5.6         2.8          4.9         2.0\n123  virginica          7.7         2.8          6.7         2.0\n124  virginica          6.3         2.7          4.9         1.8\n125  virginica          6.7         3.3          5.7         2.1\n126  virginica          7.2         3.2          6.0         1.8\n127  virginica          6.2         2.8          4.8         1.8\n128  virginica          6.1         3.0          4.9         1.8\n129  virginica          6.4         2.8          5.6         2.1\n130  virginica          7.2         3.0          5.8         1.6\n131  virginica          7.4         2.8          6.1         1.9\n132  virginica          7.9         3.8          6.4         2.0\n133  virginica          6.4         2.8          5.6         2.2\n134  virginica          6.3         2.8          5.1         1.5\n135  virginica          6.1         2.6          5.6         1.4\n136  virginica          7.7         3.0          6.1         2.3\n137  virginica          6.3         3.4          5.6         2.4\n138  virginica          6.4         3.1          5.5         1.8\n139  virginica          6.0         3.0          4.8         1.8\n140  virginica          6.9         3.1          5.4         2.1\n141  virginica          6.7         3.1          5.6         2.4\n142  virginica          6.9         3.1          5.1         2.3\n143  virginica          5.8         2.7          5.1         1.9\n144  virginica          6.8         3.2          5.9         2.3\n145  virginica          6.7         3.3          5.7         2.5\n146  virginica          6.7         3.0          5.2         2.3\n147  virginica          6.3         2.5          5.0         1.9\n148  virginica          6.5         3.0          5.2         2.0\n149  virginica          6.2         3.4          5.4         2.3\n150  virginica          5.9         3.0          5.1         1.8\n\n\n\nRename Species to species using select().\n\n\nselect(iris, everything(), species = Species)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\nRename Species to species using rename().\n\n\nrename(iris, species = Species)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica"
  },
  {
    "objectID": "code/11_mutating_answers.html",
    "href": "code/11_mutating_answers.html",
    "title": "Mutating columns",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set, so import that from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv (if you don’t already have it) and assign it to traits.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits.csv\"))\n\nRows: 195 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Breed, Coat Type, Coat Length\ndbl (14): Affectionate With Family, Good With Young Children, Good With Othe...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nView traits to see what it looks like.\n\n\nhead(traits)\n\n# A tibble: 6 × 17\n  Breed     Affectionate With Fa…¹ Good With Young Chil…² `Good With Other Dogs`\n  &lt;chr&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Retrieve…                      5                      5                      5\n2 French B…                      5                      5                      4\n3 German S…                      5                      5                      3\n4 Retrieve…                      5                      5                      5\n5 Bulldogs                       4                      3                      3\n6 Poodles                        5                      5                      3\n# ℹ abbreviated names: ¹​`Affectionate With Family`, ²​`Good With Young Children`\n# ℹ 13 more variables: `Shedding Level` &lt;dbl&gt;, `Coat Grooming Frequency` &lt;dbl&gt;,\n#   `Drooling Level` &lt;dbl&gt;, `Coat Type` &lt;chr&gt;, `Coat Length` &lt;chr&gt;,\n#   `Openness To Strangers` &lt;dbl&gt;, `Playfulness Level` &lt;dbl&gt;,\n#   `Watchdog/Protective Nature` &lt;dbl&gt;, `Adaptability Level` &lt;dbl&gt;,\n#   `Trainability Level` &lt;dbl&gt;, `Energy Level` &lt;dbl&gt;, `Barking Level` &lt;dbl&gt;,\n#   `Mental Stimulation Needs` &lt;dbl&gt;\n\n\n\nReassign traits with only the columns Breed through Coat Length.\n\n\ntraits &lt;- select(traits, Breed:`Coat Length`)\n\n\nReassign traits removing the Drooling Level column. That’s gross.\n\n\ntraits &lt;- select(traits, -`Drooling Level`)\n\n\nWhat terrible column names! Reassign traits and change the column names to \"breed\", \"affectionate\", \"children\", \"other_dogs\", \"shedding\", \"grooming\", \"coat_type\", \"coat_length\". Note, use the colnames() function rather than select() or rename() since you already have the full vector of names.\n\n\ncolnames(traits) &lt;- c(\"breed\", \"affectionate\", \"children\", \"other_dogs\", \"shedding\", \"grooming\", \"coat_type\", \"coat_length\")\n\n\nThe ratings are supposed to run from 0 to 4 rather than 1 to 5. Change the affectionate column by subtracting 1 from the original numbers to rescale the values. Don’t reassign traits.\n\n\nmutate(traits, affectionate = affectionate - 1)\n\n# A tibble: 195 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            4        5          5        4        2 Double   \n 2 French Bulldogs             4        5          4        3        1 Smooth   \n 3 German Shepherd…            4        5          3        4        2 Double   \n 4 Retrievers (Gol…            4        5          5        4        2 Double   \n 5 Bulldogs                    3        3          3        3        3 Smooth   \n 6 Poodles                     4        5          3        1        4 Curly    \n 7 Beagles                     2        5          5        3        2 Smooth   \n 8 Rottweilers                 4        3          3        3        1 Smooth   \n 9 Pointers (Germa…            4        5          4        3        2 Smooth   \n10 Dachshunds                  4        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nActually, all of the ratings need to be rescaled. Subtract 1 from all of the ratings columns by using across().\n\n\nmutate(traits, across(affectionate:grooming, ~ .x - 1))\n\n# A tibble: 195 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            4        4          4        3        1 Double   \n 2 French Bulldogs             4        4          3        2        0 Smooth   \n 3 German Shepherd…            4        4          2        3        1 Double   \n 4 Retrievers (Gol…            4        4          4        3        1 Double   \n 5 Bulldogs                    3        2          2        2        2 Smooth   \n 6 Poodles                     4        4          2        0        3 Curly    \n 7 Beagles                     2        4          4        2        1 Smooth   \n 8 Rottweilers                 4        2          2        2        0 Smooth   \n 9 Pointers (Germa…            4        4          3        2        1 Smooth   \n10 Dachshunds                  4        2          3        1        1 Smooth   \n# ℹ 185 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nCreate a new column called coat that combines the coat_type and coat_length columns by pasting the values of those two columns separated by -.\n\n\nmutate(traits, coat = paste(coat_type, coat_length, sep = \"-\"))\n\n# A tibble: 195 × 9\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 2 more variables: coat_length &lt;chr&gt;, coat &lt;chr&gt;\n\n\n\nCreate a new column called shed that dichotomizes shedding such that values of 3 and above are “A lot” and values below 3 are “Not much”. Do you need to account for missing data?\n\n\nmutate(traits, shed = ifelse(shedding &gt; 2, \"A lot\", \"Not much\"))\n\n# A tibble: 195 × 9\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 2 more variables: coat_length &lt;chr&gt;, shed &lt;chr&gt;\n\n\n\nUse rowwise() to calculate the mean rating for the children and other_dogs columns in a column called mean_rating.\n\n\nrowwise(traits) %&gt;%\n  mutate(mean_rating = mean(children, other_dogs))\n\n# A tibble: 195 × 9\n# Rowwise: \n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 2 more variables: coat_length &lt;chr&gt;, mean_rating &lt;dbl&gt;\n\n\n\nCreate a column called coat_type2 that categorizes the coat_type values in the following way and puts it after coat_type:\n\n\n“very petable” = “Smooth”, “Silky”, “Wavy”\n“petable” = “Double”, “Curly”\n“not petable” = “Wiry”, “Hairless”, “Rough”, “Corded”\n\n\nmutate(traits, coat_type2 = case_when(\n  coat_type %in% c(\"Smooth\", \"Silky\", \"Wavy\") ~ \"very petable\",\n  coat_type %in% c(\"Wiry\", \"Hairless\", \"Rough\", \"Corded\") ~ \"not petable\",\n  coat_type %in% c(\"Double\", \"Curly\") ~ \"petable\"),\n  .after = coat_type\n)\n\n# A tibble: 195 × 9\n   breed affectionate children other_dogs shedding grooming coat_type coat_type2\n   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n 1 Retr…            5        5          5        4        2 Double    petable   \n 2 Fren…            5        5          4        3        1 Smooth    very peta…\n 3 Germ…            5        5          3        4        2 Double    petable   \n 4 Retr…            5        5          5        4        2 Double    petable   \n 5 Bull…            4        3          3        3        3 Smooth    very peta…\n 6 Pood…            5        5          3        1        4 Curly     petable   \n 7 Beag…            3        5          5        3        2 Smooth    very peta…\n 8 Rott…            5        3          3        3        1 Smooth    very peta…\n 9 Poin…            5        5          4        3        2 Smooth    very peta…\n10 Dach…            5        3          4        2        2 Smooth    very peta…\n# ℹ 185 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;"
  },
  {
    "objectID": "code/12_piping_answers.html",
    "href": "code/12_piping_answers.html",
    "title": "Piping",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nCreate a pipeline to do all of the following:\n\n\nassign pipeline to traits\nimport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv\nsubset only the columns Breed through Coat Length\nremove the Drooling Level column\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits.csv\") |&gt; \n  select(Breed:`Coat Length`) |&gt; \n  select(-`Drooling Level`)\n\nRows: 195 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Breed, Coat Type, Coat Length\ndbl (14): Affectionate With Family, Good With Young Children, Good With Othe...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nRename the column names to \"breed\", \"affectionate\", \"children\", \"other_dogs\", \"shedding\", \"grooming\", \"coat_type\", \"coat_length\".\n\n\ncolnames(traits) &lt;- c(\"breed\", \"affectionate\", \"children\", \"other_dogs\", \"shedding\", \"grooming\", \"coat_type\", \"coat_length\")\n\n\nDo the following using traits.\n\n\nassign to traits2\nrescale all of the ratings columns by subtracting 1 from all of the values\ncreate a new column called coat that combines the coat_type and coat_length columns by pasting the values of those two columns separated by -\ncreate a new column called shed that dichotomizes shedding such that values of 3 and above are “A lot” and values below 3 are “Not much” and places the new column after shedding\ncalculate the mean rating for the children and other_dogs columns in a column called mean_rating and place it after other_dogs\n\n\ntraits2 &lt;- traits |&gt; \n  mutate(across(affectionate:grooming, ~ .x - 1)) |&gt; \n  mutate(coat = paste(coat_type, coat_length, sep = \"-\")) |&gt; \n  mutate(shed = ifelse(shedding &gt; 2, \"A lot\", \"Not much\"), .after = \"shedding\") |&gt; \n  rowwise() %&gt;%\n  mutate(mean_rating = mean(c(children, other_dogs)), .after = \"other_dogs\")\n\n\nDo the following using traits2.\n\n\nassign to coat_grooming\nsubset only the grooming and coat_type columns\nrun a linear model (lm) using the formula grooming ~ coat_type (remember to use a placeholder for the data)\napply the summary() function\nprint the results to console\n\n\n(coat_grooming &lt;- traits2 |&gt; \n  select(grooming, coat_type) |&gt; \n  lm(grooming ~ coat_type, data = _) |&gt; \n   summary())\n\n\nCall:\nlm(formula = grooming ~ coat_type, data = select(traits2, grooming, \n    coat_type))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5000 -0.5909  0.3134  0.4091  2.4091 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.5000     0.4025   6.212 3.35e-09 ***\ncoat_typeCurly     -0.5000     0.5045  -0.991 0.322938    \ncoat_typeDouble    -0.9091     0.4145  -2.193 0.029520 *  \ncoat_typeHairless  -2.1667     0.6148  -3.524 0.000534 ***\ncoat_typeRough     -0.8333     0.6148  -1.356 0.176889    \ncoat_typeSilky     -0.1667     0.4837  -0.345 0.730805    \ncoat_typeSmooth    -1.8134     0.4143  -4.377 2.00e-05 ***\ncoat_typeWavy      -1.0000     0.5196  -1.925 0.055796 .  \ncoat_typeWiry      -1.2000     0.4284  -2.801 0.005636 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8049 on 186 degrees of freedom\nMultiple R-squared:  0.3054,    Adjusted R-squared:  0.2755 \nF-statistic: 10.22 on 8 and 186 DF,  p-value: 8.381e-12"
  },
  {
    "objectID": "code/13_filtering_answers.html",
    "href": "code/13_filtering_answers.html",
    "title": "Filtering rows",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nImport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv and assign to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv\")\n\nRows: 197 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): breed, coat_type, coat_length\ndbl (5): affectionate, children, other_dogs, shedding, grooming\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nView dogs only with short coats.\n\n\nfilter(traits, coat_length == \"Short\")\n\n# A tibble: 87 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 Bulldogs                    4        3          3        3        3 Smooth   \n 4 Beagles                     3        5          5        3        2 Smooth   \n 5 Rottweilers                 5        3          3        3        1 Smooth   \n 6 Pointers (Germa…            5        5          4        3        2 Smooth   \n 7 Dachshunds                  5        3          4        2        2 Smooth   \n 8 Pembroke Welsh …            5        3          4        4        2 Double   \n 9 Boxers                      4        5          3        2        2 Smooth   \n10 Great Danes                 5        3          3        3        1 Smooth   \n# ℹ 77 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nView a data frame excluding dogs with short coats.\n\n\nfilter(traits, coat_length != \"Short\")\n\n# A tibble: 109 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 German Shepherd…            5        5          3        4        2 Double   \n 2 Retrievers (Gol…            5        5          5        4        2 Double   \n 3 Poodles                     5        5          3        1        4 Curly    \n 4 Australian Shep…            3        5          3        3        2 Double   \n 5 Yorkshire Terri…            5        5          3        1        5 Silky    \n 6 Siberian Huskies            5        5          5        4        2 Double   \n 7 Cavalier King C…            5        5          5        2        2 Wavy     \n 8 Miniature Schna…            5        5          3        3        4 Wiry     \n 9 Shih Tzu                    5        5          5        1        4 Double   \n10 Bernese Mountai…            5        5          5        5        3 Double   \n# ℹ 99 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nView dogs with double or silky coats.\n\n\nfilter(traits, coat_type %in% c(\"Double\", \"Silky\"))\n\n# A tibble: 75 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 German Shepherd…            5        5          3        4        2 Double   \n 3 Retrievers (Gol…            5        5          5        4        2 Double   \n 4 Pembroke Welsh …            5        3          4        4        2 Double   \n 5 Australian Shep…            3        5          3        3        2 Double   \n 6 Yorkshire Terri…            5        5          3        1        5 Silky    \n 7 Siberian Huskies            5        5          5        4        2 Double   \n 8 Shih Tzu                    5        5          5        1        4 Double   \n 9 Bernese Mountai…            5        5          5        5        3 Double   \n10 Pomeranians                 5        3          3        2        3 Double   \n# ℹ 65 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nView dogs with double or silky coats and shedding ratings 3 or below.\n\n\nfilter(traits, coat_type %in% c(\"Double\", \"Silky\") & shedding &lt;= 3)\n\n# A tibble: 65 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Australian Shep…            3        5          3        3        2 Double   \n 2 Yorkshire Terri…            5        5          3        1        5 Silky    \n 3 Shih Tzu                    5        5          5        1        4 Double   \n 4 Pomeranians                 5        3          3        2        3 Double   \n 5 Havanese                    5        5          5        2        3 Double   \n 6 Spaniels (Engli…            5        3          4        3        2 Double   \n 7 Shetland Sheepd…            5        5          5        3        3 Double   \n 8 Brittanys                   3        4          4        3        3 Double   \n 9 Spaniels (Cocke…            4        5          5        3        4 Double   \n10 Miniature Ameri…            5        5          5        3        3 Double   \n# ℹ 55 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nView dogs with NA for coat_type.\n\n\nfilter(traits, is.na(coat_type))\n\n# A tibble: 1 × 8\n  breed affectionate children other_dogs shedding grooming coat_type coat_length\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;      \n1 Engl…            4        5          5        3        2 &lt;NA&gt;      &lt;NA&gt;       \n\n\n\nView dogs with NA for any column.\n\n\nfilter(traits, if_any(everything(), is.na))\n\n# A tibble: 2 × 8\n  breed affectionate children other_dogs shedding grooming coat_type coat_length\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;      \n1 Amer…            5        2          4        5       NA Rough     Medium     \n2 Engl…            4        5          5        3        2 &lt;NA&gt;      &lt;NA&gt;       \n\n\n\nView dogs not missing any data.\n\n\ndrop_na(traits)\n\n# A tibble: 195 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nView dogs sorted by breed name.\n\n\narrange(traits, breed)\n\n# A tibble: 197 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Affenpinschers              3        3          3        3        3 Wiry     \n 2 Afghan Hounds               3        3          3        1        4 Silky    \n 3 Airedale Terrie…            3        3          3        1        3 Wiry     \n 4 Akitas                      3        3          1        3        3 Double   \n 5 Alaskan Malamut…            3        3          3        3        3 Double   \n 6 American Englis…            3        3          5        2        1 Smooth   \n 7 American Eskimo…            5        5          3        3        3 Double   \n 8 American Foxhou…            3        5          5        3        1 Smooth   \n 9 American Hairle…            5        5          3        1        1 Hairless \n10 American Rearsn…            5        2          4        5       NA Rough    \n# ℹ 187 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nView dogs sorted by coat type then coat length then affectionate rating.\n\n\narrange(traits, coat_type, coat_length, affectionate)\n\n# A tibble: 197 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Bergamasco Shee…            3        3          3        1        1 Corded   \n 2 Pulik                       5        3          3        1        5 Corded   \n 3 Komondorok                  5        3          2        1        4 Corded   \n 4 Spanish Water D…            5        4          3        1        4 Corded   \n 5 Poodles                     5        5          3        1        4 Curly    \n 6 Portuguese Wate…            5        5          4        2        4 Curly    \n 7 Borzois                     3        3          3        3        2 Curly    \n 8 Bedlington Terr…            3        3          3        1        3 Curly    \n 9 Barbets                     4        5          5        1        3 Curly    \n10 Pumik                       5        3          3        1        2 Curly    \n# ℹ 187 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;"
  },
  {
    "objectID": "code/14_summarizing_answers.html",
    "href": "code/14_summarizing_answers.html",
    "title": "Summarizing rows",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nImport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv and assign to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv\")\n\nRows: 197 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): breed, coat_type, coat_length\ndbl (5): affectionate, children, other_dogs, shedding, grooming\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nWhat is the overall mean rating for affectionate?\n\n\nsummarise(traits, mean(affectionate))\n\n# A tibble: 1 × 1\n  `mean(affectionate)`\n                 &lt;dbl&gt;\n1                 4.50\n\n\n\nWhat is the overall mean rating for all rating columns ignoring NAs?\n\n\nsummarise(traits, across(affectionate:grooming, ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 5\n  affectionate children other_dogs shedding grooming\n         &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1         4.50     3.88       3.55     2.61     2.28\n\n\n\nHow many breeds are there in each coat type?\n\n\ncount(traits, coat_type)\n\n# A tibble: 10 × 2\n   coat_type     n\n   &lt;chr&gt;     &lt;int&gt;\n 1 Corded        4\n 2 Curly         7\n 3 Double       66\n 4 Hairless      3\n 5 Rough         4\n 6 Silky         9\n 7 Smooth       67\n 8 Wavy          6\n 9 Wiry         30\n10 &lt;NA&gt;          1\n\n\n\nWhat is the median grooming rating for each coat type?\n\n\ntraits |&gt; \n  group_by(coat_type) |&gt; \n  summarise(median(grooming, na.rm = TRUE))\n\n# A tibble: 10 × 2\n   coat_type `median(grooming, na.rm = TRUE)`\n   &lt;chr&gt;                                &lt;dbl&gt;\n 1 Corded                                 4  \n 2 Curly                                  3  \n 3 Double                                 2.5\n 4 Hairless                               1  \n 5 Rough                                  2  \n 6 Silky                                  3  \n 7 Smooth                                 2  \n 8 Wavy                                   2  \n 9 Wiry                                   2  \n10 &lt;NA&gt;                                   2  \n\n\n\nWhat is the lowest rating per coat length for each of the rating columns, ignoring NAs?\n\n\ntraits |&gt; \n  group_by(coat_length) |&gt; \n  summarise(across(affectionate:grooming, ~ min(.x, na.rm = TRUE)))\n\n# A tibble: 4 × 6\n  coat_length affectionate children other_dogs shedding grooming\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Long                   3        3          2        1        1\n2 Medium                 3        2          1        1        1\n3 Short                  1        1          1        1        1\n4 &lt;NA&gt;                   4        5          5        3        2\n\n\n\nWhat are the sample size, mean, and standard deviation of shedding ratings for medium coat length dogs per coat type sorted from largest to smallest sample size and only including coat types with 5 or more samples?\n\n\ntraits |&gt; \n  filter(coat_length == \"Medium\") |&gt; \n  group_by(coat_type) |&gt; \n  summarise(n = n(), shedding_mean = mean(shedding), shedding_sd = sd(shedding)) |&gt; \n  arrange(desc(n)) |&gt; \n  filter(n &gt; 4)\n\n# A tibble: 5 × 4\n  coat_type     n shedding_mean shedding_sd\n  &lt;chr&gt;     &lt;int&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 Double       39          3.03       0.707\n2 Wiry         19          2.53       0.612\n3 Curly         5          1.4        0.894\n4 Smooth        5          3          0    \n5 Wavy          5          1.8        0.837\n\n\n\nCalculate each breed’s mean rating across all ratings columns and return a data frame with the highest rating for each coat type. Don’t forget to undo rowwise() with ungroup() before further calculations.\n\n\ntraits |&gt;\n  rowwise() |&gt; \n  mutate(mean_rating = mean(c(affectionate, children, other_dogs, shedding, grooming), na.rm = TRUE)) |&gt; \n  ungroup() |&gt; \n  group_by(coat_type) |&gt; \n  slice_max(mean_rating)\n\n# A tibble: 16 × 9\n# Groups:   coat_type [10]\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Pulik                       5        3          3        1        5 Corded   \n 2 Spanish Water D…            5        4          3        1        4 Corded   \n 3 Portuguese Wate…            5        5          4        2        4 Curly    \n 4 Bernese Mountai…            5        5          5        5        3 Double   \n 5 American Hairle…            5        5          3        1        1 Hairless \n 6 American Rearsn…            5        2          4        5       NA Rough    \n 7 Setters (Irish)             5        5          5        3        3 Silky    \n 8 Bearded Collies             4        5          5        3        4 Silky    \n 9 Pugs                        5        5          4        4        2 Smooth   \n10 Retrievers (Fla…            5        5          5        3        2 Smooth   \n11 Redbone Coonhou…            5        5          5        3        2 Smooth   \n12 Chinooks                    4        5          5        3        3 Smooth   \n13 Cavalier King C…            5        5          5        2        2 Wavy     \n14 Miniature Schna…            5        5          3        3        4 Wiry     \n15 Portuguese Pode…            5        5          5        3        2 Wiry     \n16 English Buttdra…            4        5          5        3        2 &lt;NA&gt;     \n# ℹ 2 more variables: coat_length &lt;chr&gt;, mean_rating &lt;dbl&gt;"
  },
  {
    "objectID": "code/15_pivoting_answers.html",
    "href": "code/15_pivoting_answers.html",
    "title": "Pivoting data",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nImport data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv and assign to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv\")\n\nRows: 197 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): breed, coat_type, coat_length\ndbl (5): affectionate, children, other_dogs, shedding, grooming\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nCreate traits2 where we delete the coat columns, so we only have breed and ratings data.\n\n\ntraits2 &lt;- traits |&gt; \n  select(-contains(\"coat\"))\n\n\nIs traits2 tidy?\nIs traits2 in wide or long format?\nReshape traits2 so that all of the ratings scores are in a single column called rating with a column labeling what kind of rating it is called scale. Assign this to traits3.\n\n\ntraits3 &lt;- traits2 |&gt; \n  pivot_longer(affectionate:grooming, names_to = \"scale\", values_to = \"rating\")\n\n\nHow would we check if traits3 has the expected number of rows?\nCreate traits4 by removing the rows with affectionate, children, and other_dogs as values of scale.\n\n\ntraits4 &lt;- traits3 |&gt; \n  filter(!scale %in% c(\"affectionate\", \"children\", \"other_dogs\"))\n\n\nSpread out the data into wide format with separate columns for the shedding and grooming data, then create a new column diff that subtracts grooming from shedding ratings.\n\n\ntraits4 |&gt;\n  pivot_wider(id_cols = breed, names_from = scale, values_from = rating) |&gt; \n  mutate(diff = shedding - grooming)\n\n# A tibble: 197 × 4\n   breed                         shedding grooming  diff\n   &lt;chr&gt;                            &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Retrievers (Labrador)                4        2     2\n 2 French Bulldogs                      3        1     2\n 3 German Shepherd Dogs                 4        2     2\n 4 Retrievers (Golden)                  4        2     2\n 5 Bulldogs                             3        3     0\n 6 Poodles                              1        4    -3\n 7 Beagles                              3        2     1\n 8 Rottweilers                          3        1     2\n 9 Pointers (German Shorthaired)        3        2     1\n10 Dachshunds                           2        2     0\n# ℹ 187 more rows"
  },
  {
    "objectID": "code/16_separating_answers.html",
    "href": "code/16_separating_answers.html",
    "title": "Separating and uniting data",
    "section": "",
    "text": "For these exercises, we’ll use a new clean version of the dog breed traits data set.\n\nLoad tidyverse, import data from https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv, and assign it to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(\"https://jeffreyrstevens.quarto.pub/dpavir/data/dog_breed_traits_clean.csv\", show_col_types = FALSE)\n\n\nCreate traits2 which adds a coat column that combines coat_type and coat_length into single column delimited by “-”.\n\n\ntraits2 &lt;- traits |&gt; \n  unite(\"coat\", contains(\"coat_\"), sep = \"-\")\n\n\nSplit the coat column into type and length and keep the original coat column.\n\n\ntraits2 |&gt; \n  separate(coat, into = c(\"type\", \"length\"), remove = FALSE)\n\n# A tibble: 197 × 9\n   breed   affectionate children other_dogs shedding grooming coat  type  length\n   &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Retrie…            5        5          5        4        2 Doub… Doub… Short \n 2 French…            5        5          4        3        1 Smoo… Smoo… Short \n 3 German…            5        5          3        4        2 Doub… Doub… Medium\n 4 Retrie…            5        5          5        4        2 Doub… Doub… Medium\n 5 Bulldo…            4        3          3        3        3 Smoo… Smoo… Short \n 6 Poodles            5        5          3        1        4 Curl… Curly Long  \n 7 Beagles            3        5          5        3        2 Smoo… Smoo… Short \n 8 Rottwe…            5        3          3        3        1 Smoo… Smoo… Short \n 9 Pointe…            5        5          4        3        2 Smoo… Smoo… Short \n10 Dachsh…            5        3          4        2        2 Smoo… Smoo… Short \n# ℹ 187 more rows\n\n\n\nCreate traits3 from traits that (1) removes the coat columns, (2) turns the ratings columns into long format, and (3) removes the children row for Bulldogs.\n\n\ntraits3 &lt;- traits |&gt; \n  select(-contains(\"coat_\")) |&gt; \n  pivot_longer(affectionate:grooming, names_to = \"scale\", values_to = \"rating\") |&gt; \n  filter(breed != \"Bulldogs\" | scale != \"children\")\n\n\nCreate traits4 from traits3 that ensures a complete data set with all five ratings for all breeds (and fills in missing combinations with NA) and check for the missing Bulldog children row.\n\n\ntraits4 &lt;- traits3 |&gt; \n  complete(breed, scale)\n\n\nHow could we copy the rating from the previous row into the Bulldog children row to replace the NA? (Note this is not a good idea in this case!)\n\n\ntraits4 |&gt; \n  fill(rating) |&gt; \n  filter(breed == \"Bulldogs\")\n\n# A tibble: 5 × 3\n  breed    scale        rating\n  &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt;\n1 Bulldogs affectionate      4\n2 Bulldogs children          4\n3 Bulldogs grooming          3\n4 Bulldogs other_dogs        3\n5 Bulldogs shedding          3\n\n\n\nFrom traits, generate all combinations of coat type and length observed in the data, excluding NA.\n\n\ntraits |&gt; \n  expand(nesting(coat_type, coat_length)) |&gt; \n  drop_na()\n\n# A tibble: 18 × 2\n   coat_type coat_length\n   &lt;chr&gt;     &lt;chr&gt;      \n 1 Corded    Long       \n 2 Corded    Medium     \n 3 Curly     Long       \n 4 Curly     Medium     \n 5 Double    Long       \n 6 Double    Medium     \n 7 Double    Short      \n 8 Hairless  Short      \n 9 Rough     Long       \n10 Rough     Medium     \n11 Silky     Long       \n12 Silky     Medium     \n13 Smooth    Medium     \n14 Smooth    Short      \n15 Wavy      Long       \n16 Wavy      Medium     \n17 Wiry      Medium     \n18 Wiry      Short      \n\n\n\nFrom traits, generate all possible combinations of coat type and length, excluding NA.\n\n\ntraits |&gt; \n  expand(coat_type, coat_length) |&gt; \n  drop_na()\n\n# A tibble: 27 × 2\n   coat_type coat_length\n   &lt;chr&gt;     &lt;chr&gt;      \n 1 Corded    Long       \n 2 Corded    Medium     \n 3 Corded    Short      \n 4 Curly     Long       \n 5 Curly     Medium     \n 6 Curly     Short      \n 7 Double    Long       \n 8 Double    Medium     \n 9 Double    Short      \n10 Hairless  Long       \n# ℹ 17 more rows"
  },
  {
    "objectID": "code/17_mergingcolumns_answers.html",
    "href": "code/17_mergingcolumns_answers.html",
    "title": "Merging columns",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set along with the data on breed popularity rankings.\n\nLoad tidyverse, download and import dog_breed_traits_clean.csv to traits, and import dog_breed_ranks.csv to ranks. Make sure to download both files from the website, as they have changed or are new.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits_clean.csv\"), show_col_types = FALSE)\nranks &lt;- read_csv(here::here(\"data/dog_breed_ranks.csv\"), show_col_types = FALSE)\n\n\nWhich breeds differ between traits and ranks?\n\n\ntraits$breed[!traits$breed %in% ranks$breed]\n\n[1] \"American Rearsniffer\" \"English Buttdragger\" \n\nranks$breed[!ranks$breed %in% traits$breed]\n\n[1] \"Bergamasco\" \"Pumi\"       \"Puli\"      \n\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes breeds shared by both data sets. How many rows are there?\n\n\ntraits |&gt; \n  inner_join(ranks, by = \"breed\")\n\n# A tibble: 195 × 16\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 9 more variables: coat_length &lt;chr&gt;, `2013 Rank` &lt;dbl&gt;, `2014 Rank` &lt;dbl&gt;,\n#   `2015 Rank` &lt;dbl&gt;, `2016 Rank` &lt;dbl&gt;, `2017 Rank` &lt;dbl&gt;, `2018 Rank` &lt;dbl&gt;,\n#   `2019 Rank` &lt;dbl&gt;, `2020 Rank` &lt;dbl&gt;\n\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes all breeds included in either data set. How many rows are there?\n\n\ntraits |&gt; \n  full_join(ranks, by = \"breed\")\n\n# A tibble: 200 × 16\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 190 more rows\n# ℹ 9 more variables: coat_length &lt;chr&gt;, `2013 Rank` &lt;dbl&gt;, `2014 Rank` &lt;dbl&gt;,\n#   `2015 Rank` &lt;dbl&gt;, `2016 Rank` &lt;dbl&gt;, `2017 Rank` &lt;dbl&gt;, `2018 Rank` &lt;dbl&gt;,\n#   `2019 Rank` &lt;dbl&gt;, `2020 Rank` &lt;dbl&gt;\n\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes only breeds included in traits. How many rows are there?\n\n\ntraits |&gt; \n  left_join(ranks, by = \"breed\")\n\n# A tibble: 197 × 16\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 187 more rows\n# ℹ 9 more variables: coat_length &lt;chr&gt;, `2013 Rank` &lt;dbl&gt;, `2014 Rank` &lt;dbl&gt;,\n#   `2015 Rank` &lt;dbl&gt;, `2016 Rank` &lt;dbl&gt;, `2017 Rank` &lt;dbl&gt;, `2018 Rank` &lt;dbl&gt;,\n#   `2019 Rank` &lt;dbl&gt;, `2020 Rank` &lt;dbl&gt;\n\n\n\nMerge traits and ranks (in that order) to produce a data frame that includes only breeds included in ranks. How many rows are there?\n\n\ntraits |&gt; \n  right_join(ranks, by = \"breed\")\n\n# A tibble: 198 × 16\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 188 more rows\n# ℹ 9 more variables: coat_length &lt;chr&gt;, `2013 Rank` &lt;dbl&gt;, `2014 Rank` &lt;dbl&gt;,\n#   `2015 Rank` &lt;dbl&gt;, `2016 Rank` &lt;dbl&gt;, `2017 Rank` &lt;dbl&gt;, `2018 Rank` &lt;dbl&gt;,\n#   `2019 Rank` &lt;dbl&gt;, `2020 Rank` &lt;dbl&gt;\n\n\n\nMake table4a and table4b tidy then join them to replicate table1.\n\n\ntable4a_tidy &lt;- pivot_longer(table4a, -country, names_to = \"year\", values_to = \"cases\")\ntable4b_tidy &lt;- pivot_longer(table4b, -country, names_to = \"year\", values_to = \"population\")\nleft_join(table4a_tidy, table4b_tidy)\n\nJoining with `by = join_by(country, year)`\n\n\n# A tibble: 6 × 4\n  country     year   cases population\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan 1999     745   19987071\n2 Afghanistan 2000    2666   20595360\n3 Brazil      1999   37737  172006362\n4 Brazil      2000   80488  174504898\n5 China       1999  212258 1272915272\n6 China       2000  213766 1280428583"
  },
  {
    "objectID": "code/18_mergingrows_answers.html",
    "href": "code/18_mergingrows_answers.html",
    "title": "Merging rows",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits and dog breed popularity rankings data sets.\n\nLoad tidyverse, import dog_breed_traits_clean.csv to traits, import dog_breed_ranks.csv to ranks, and import dog_breed_ranks.csv to popularity.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits_clean.csv\"), show_col_types = FALSE)\nranks &lt;- read_csv(here::here(\"data/dog_breed_ranks.csv\"), show_col_types = FALSE)\npopularity &lt;- read_csv(here::here(\"data/dog_breed_popularity.csv\"), show_col_types = FALSE)\n\n\nFirst, set a random seed by using set.seed(2). Then create a subset of ranks that is a random selection of 10% of the rows, sort by breed name, and assign to ranks2.\n\n\nset.seed(2)\nranks2 &lt;- slice_sample(ranks, prop = 0.1) |&gt; \n  arrange(breed)\n\n\nUse a filtering join to return the subset of traits that matches the breeds in ranks2 and assign this to traits2.\n\n\ntraits2 &lt;- traits |&gt; \n  semi_join(ranks2, by = \"breed\")\n\n\nUse a filtering join to return the subset of traits that excludes the breeds in ranks2.\n\n\ntraits |&gt; \n  anti_join(ranks2, by = \"breed\")\n\n# A tibble: 178 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 168 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nNow we want to filter traits based on breeds in popularity. Notice that the breeds column in popularity is called Breed. This is problematic because the breed column in traits is called breed and names are case-sensitive. Use join_by() to filter traits by breeds in popularity. How many rows are there?\n\n\ntraits |&gt; \n  semi_join(popularity, by = join_by(breed == Breed))\n\n# A tibble: 195 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 185 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nUse filter() (not joins) to return the subset of traits that excludes the breeds in ranks2.\n\n\ntraits |&gt; \n  filter(!breed %in% ranks2$breed)\n\n# A tibble: 178 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Retrievers (Lab…            5        5          5        4        2 Double   \n 2 French Bulldogs             5        5          4        3        1 Smooth   \n 3 German Shepherd…            5        5          3        4        2 Double   \n 4 Retrievers (Gol…            5        5          5        4        2 Double   \n 5 Bulldogs                    4        3          3        3        3 Smooth   \n 6 Poodles                     5        5          3        1        4 Curly    \n 7 Beagles                     3        5          5        3        2 Smooth   \n 8 Rottweilers                 5        3          3        3        1 Smooth   \n 9 Pointers (Germa…            5        5          4        3        2 Smooth   \n10 Dachshunds                  5        3          4        2        2 Smooth   \n# ℹ 168 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nAppend traits2 to the bottom of itself.\n\n\nbind_rows(traits2, traits2)\n\n# A tibble: 38 × 8\n   breed            affectionate children other_dogs shedding grooming coat_type\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 Yorkshire Terri…            5        5          3        1        5 Silky    \n 2 Miniature Schna…            5        5          3        3        4 Wiry     \n 3 Cane Corso                  4        3          3        2        1 Smooth   \n 4 Weimaraners                 5        5          3        3        2 Smooth   \n 5 Bullmastiffs                4        3          3        3        1 Smooth   \n 6 Scottish Terrie…            5        3          2        2        3 Wiry     \n 7 Chinese Shar-Pei            4        3          3        3        1 Smooth   \n 8 Cardigan Welsh …            4        4          3        3        2 Double   \n 9 Lhasa Apsos                 5        3          3        1        3 Silky    \n10 Coton de Tulear             5        5          5        2        4 Double   \n# ℹ 28 more rows\n# ℹ 1 more variable: coat_length &lt;chr&gt;\n\n\n\nAppend traits2 to the right of itself.\n\n\nbind_cols(traits2, traits2)\n\nNew names:\n• `breed` -&gt; `breed...1`\n• `affectionate` -&gt; `affectionate...2`\n• `children` -&gt; `children...3`\n• `other_dogs` -&gt; `other_dogs...4`\n• `shedding` -&gt; `shedding...5`\n• `grooming` -&gt; `grooming...6`\n• `coat_type` -&gt; `coat_type...7`\n• `coat_length` -&gt; `coat_length...8`\n• `breed` -&gt; `breed...9`\n• `affectionate` -&gt; `affectionate...10`\n• `children` -&gt; `children...11`\n• `other_dogs` -&gt; `other_dogs...12`\n• `shedding` -&gt; `shedding...13`\n• `grooming` -&gt; `grooming...14`\n• `coat_type` -&gt; `coat_type...15`\n• `coat_length` -&gt; `coat_length...16`\n\n\n# A tibble: 19 × 16\n   breed...1           affectionate...2 children...3 other_dogs...4 shedding...5\n   &lt;chr&gt;                          &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n 1 Yorkshire Terriers                 5            5              3            1\n 2 Miniature Schnauze…                5            5              3            3\n 3 Cane Corso                         4            3              3            2\n 4 Weimaraners                        5            5              3            3\n 5 Bullmastiffs                       4            3              3            3\n 6 Scottish Terriers                  5            3              2            2\n 7 Chinese Shar-Pei                   4            3              3            3\n 8 Cardigan Welsh Cor…                4            4              3            3\n 9 Lhasa Apsos                        5            3              3            1\n10 Coton de Tulear                    5            5              5            2\n11 Anatolian Shepherd…                1            3              3            3\n12 Basenjis                           3            3              3            2\n13 Miniature Bull Ter…                5            3              3            2\n14 Setters (Gordon)                   5            3              3            3\n15 Spaniels (Clumber)                 4            3              3            3\n16 Pulik                              5            3              3            1\n17 Salukis                            5            3              3            2\n18 Barbets                            4            5              5            1\n19 Pharaoh Hounds                     5            3              5            3\n# ℹ 11 more variables: grooming...6 &lt;dbl&gt;, coat_type...7 &lt;chr&gt;,\n#   coat_length...8 &lt;chr&gt;, breed...9 &lt;chr&gt;, affectionate...10 &lt;dbl&gt;,\n#   children...11 &lt;dbl&gt;, other_dogs...12 &lt;dbl&gt;, shedding...13 &lt;dbl&gt;,\n#   grooming...14 &lt;dbl&gt;, coat_type...15 &lt;chr&gt;, coat_length...16 &lt;chr&gt;\n\n\n\nAppend traits2 to the right of ranks2.\n\n\nbind_cols(ranks2, traits2)\n\nNew names:\n• `breed` -&gt; `breed...1`\n• `breed` -&gt; `breed...10`\n\n\n# A tibble: 19 × 17\n   breed...1         `2013 Rank` `2014 Rank` `2015 Rank` `2016 Rank` `2017 Rank`\n   &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 Anatolian Shephe…          93          94          92          84          86\n 2 Barbets                    NA          NA          NA          NA          NA\n 3 Basenjis                   85          86          87          88          84\n 4 Bullmastiffs               41          45          43          48          51\n 5 Cane Corso                 50          48          35          40          37\n 6 Cardigan Welsh C…          75          78          76          69          68\n 7 Chinese Shar-Pei           54          58          59          61          64\n 8 Coton de Tulear            NA          31          85          80          81\n 9 Lhasa Apsos                63          67          65          71          77\n10 Miniature Bull T…         125         129         121         120         115\n11 Miniature Schnau…          17          16          16          17          18\n12 Pharaoh Hounds            160         164         171         168         174\n13 Pulik                     136         151         154         159         142\n14 Salukis                   115         134         132         125         123\n15 Scottish Terriers          55          59          58          58          58\n16 Setters (Gordon)          105         100         105         104         104\n17 Spaniels (Clumbe…         131         143         134         144         140\n18 Weimaraners                33          35          34          34          34\n19 Yorkshire Terrie…           6           6           7           9           9\n# ℹ 11 more variables: `2018 Rank` &lt;dbl&gt;, `2019 Rank` &lt;dbl&gt;, `2020 Rank` &lt;dbl&gt;,\n#   breed...10 &lt;chr&gt;, affectionate &lt;dbl&gt;, children &lt;dbl&gt;, other_dogs &lt;dbl&gt;,\n#   shedding &lt;dbl&gt;, grooming &lt;dbl&gt;, coat_type &lt;chr&gt;, coat_length &lt;chr&gt;\n\n\n\nWhy is this not a good idea? What would be a better way to achieve this?\n\n\nleft_join(ranks2, traits2)\n\nJoining with `by = join_by(breed)`\n\n\n# A tibble: 19 × 16\n   breed `2013 Rank` `2014 Rank` `2015 Rank` `2016 Rank` `2017 Rank` `2018 Rank`\n   &lt;chr&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 Anat…          93          94          92          84          86          90\n 2 Barb…          NA          NA          NA          NA          NA          NA\n 3 Base…          85          86          87          88          84          87\n 4 Bull…          41          45          43          48          51          51\n 5 Cane…          50          48          35          40          37          32\n 6 Card…          75          78          76          69          68          68\n 7 Chin…          54          58          59          61          64          64\n 8 Coto…          NA          31          85          80          81          81\n 9 Lhas…          63          67          65          71          77          71\n10 Mini…         125         129         121         120         115         110\n11 Mini…          17          16          16          17          18          19\n12 Phar…         160         164         171         168         174         172\n13 Pulik         136         151         154         159         142         160\n14 Salu…         115         134         132         125         123         120\n15 Scot…          55          59          58          58          58          57\n16 Sett…         105         100         105         104         104         115\n17 Span…         131         143         134         144         140         143\n18 Weim…          33          35          34          34          34          36\n19 York…           6           6           7           9           9          10\n# ℹ 9 more variables: `2019 Rank` &lt;dbl&gt;, `2020 Rank` &lt;dbl&gt;, affectionate &lt;dbl&gt;,\n#   children &lt;dbl&gt;, other_dogs &lt;dbl&gt;, shedding &lt;dbl&gt;, grooming &lt;dbl&gt;,\n#   coat_type &lt;chr&gt;, coat_length &lt;chr&gt;"
  },
  {
    "objectID": "code/19_numbers_answers.html",
    "href": "code/19_numbers_answers.html",
    "title": "Numbers",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits and dog breed popularity rankings data sets.\n\nLoad tidyverse and import dog_breed_traits_clean.csv to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits_clean.csv\"), show_col_types = FALSE)\n\n\nCreate a column of per-row means over all rating columns called mean_ratings and assign to traits2.\n\n\ntraits2 &lt;- traits |&gt; \n  rowwise() |&gt; \n  mutate(mean_ratings = mean(c(affectionate, children, other_dogs, shedding, grooming, na.rm = TRUE)))\n\n\nConvert mean_ratings to a proportion in a column called pmean_ratings and add to traits2.\n\n\ntraits2 &lt;- traits2 |&gt; \n  mutate(pmean_ratings = mean_ratings / 5)\n\n\nApply a natural log transformation to the pmeans_ratings vector.\n\n\nlog(traits2$pmean_ratings)\n\n  [1] -0.3101549 -0.4567584 -0.4054651 -0.3101549 -0.5679840 -0.4567584\n  [7] -0.4567584 -0.6286087 -0.4054651 -0.5679840 -0.4567584 -0.5679840\n [13] -0.4054651 -0.5679840 -0.6286087 -0.3101549 -0.4054651 -0.4567584\n [19] -0.3566749 -0.3566749 -0.4567584 -0.2231436 -0.5679840 -0.3566749\n [25] -0.7621401 -0.5108256 -0.3101549 -0.5108256 -0.3566749 -0.3101549\n [31] -0.3101549 -0.5108256 -0.5108256 -0.9162907 -0.4054651 -0.4567584\n [37] -0.6931472 -0.5679840 -0.4567584 -0.4567584 -0.3566749 -0.4567584\n [43] -0.5679840 -0.4054651 -0.3101549 -0.6286087 -0.3101549 -0.7621401\n [49] -0.3566749 -0.5679840 -0.5108256 -0.4567584 -0.4567584 -0.7621401\n [55] -0.6931472 -0.4054651 -0.6286087 -0.4567584 -0.4567584 -0.6286087\n [61] -0.6931472 -0.7621401 -0.4567584 -0.7621401 -0.6286087 -0.5679840\n [67] -0.4567584 -0.3566749 -0.5108256 -0.5679840 -0.5679840 -0.4567584\n [73] -0.6931472 -0.5108256 -0.3101549 -0.4567584 -0.5679840 -0.6286087\n [79] -0.7621401 -0.3101549 -0.5108256 -0.6931472 -0.4567584 -0.6286087\n [85] -0.8362480 -0.8362480 -0.4054651 -0.5679840 -0.5679840 -0.4054651\n [91] -0.5679840 -0.5108256 -0.5679840 -0.5679840 -0.5108256 -0.3101549\n [97] -0.5679840 -0.3101549 -0.5108256 -0.6931472 -0.4054651 -0.3566749\n[103] -0.6931472 -0.4567584 -0.6931472 -0.6931472 -0.5679840 -0.5679840\n[109] -0.4567584 -0.5108256 -0.4567584 -0.4567584 -0.5679840 -0.5679840\n[115] -0.5108256 -0.4567584 -0.6931472 -0.4567584 -0.4054651 -0.6931472\n[121] -0.5679840 -0.6931472 -0.5679840 -0.5679840 -0.3101549 -0.5679840\n[127] -0.4054651 -0.4054651 -0.6286087 -0.4567584 -0.7621401 -0.5679840\n[133] -0.6286087 -0.6931472 -0.6286087 -0.6286087 -0.5679840 -0.3101549\n[139] -0.6286087 -0.5108256 -0.7621401 -0.6931472 -0.5108256 -0.6931472\n[145] -0.4567584 -0.3566749 -0.4054651 -0.5108256 -0.5108256 -0.6931472\n[151] -0.7621401 -0.5108256 -0.4054651 -0.4054651 -0.5108256 -0.6931472\n[157] -0.3566749 -0.7621401 -0.5679840 -0.4054651 -0.5108256 -0.5679840\n[163] -0.6286087 -0.4567584 -0.4567584 -0.5108256 -0.5679840 -0.5679840\n[169] -0.5679840 -0.4054651 -0.5679840 -0.5108256 -0.9162907 -0.6286087\n[175] -0.5108256 -0.6286087 -0.5679840 -0.6286087 -0.7621401 -0.4567584\n[181] -0.6286087 -0.5679840 -0.5108256 -0.6286087 -0.6931472 -0.3566749\n[187] -0.4054651 -0.5108256 -0.6931472 -0.4054651 -0.5679840 -0.5108256\n[193] -0.7621401 -0.4054651 -0.6931472         NA -0.4054651\n\n\n\nRound pmean_ratings to two decimal places.\n\n\nround(traits2$pmean_ratings, digits = 2)\n\n  [1] 0.73 0.63 0.67 0.73 0.57 0.63 0.63 0.53 0.67 0.57 0.63 0.57 0.67 0.57 0.53\n [16] 0.73 0.67 0.63 0.70 0.70 0.63 0.80 0.57 0.70 0.47 0.60 0.73 0.60 0.70 0.73\n [31] 0.73 0.60 0.60 0.40 0.67 0.63 0.50 0.57 0.63 0.63 0.70 0.63 0.57 0.67 0.73\n [46] 0.53 0.73 0.47 0.70 0.57 0.60 0.63 0.63 0.47 0.50 0.67 0.53 0.63 0.63 0.53\n [61] 0.50 0.47 0.63 0.47 0.53 0.57 0.63 0.70 0.60 0.57 0.57 0.63 0.50 0.60 0.73\n [76] 0.63 0.57 0.53 0.47 0.73 0.60 0.50 0.63 0.53 0.43 0.43 0.67 0.57 0.57 0.67\n [91] 0.57 0.60 0.57 0.57 0.60 0.73 0.57 0.73 0.60 0.50 0.67 0.70 0.50 0.63 0.50\n[106] 0.50 0.57 0.57 0.63 0.60 0.63 0.63 0.57 0.57 0.60 0.63 0.50 0.63 0.67 0.50\n[121] 0.57 0.50 0.57 0.57 0.73 0.57 0.67 0.67 0.53 0.63 0.47 0.57 0.53 0.50 0.53\n[136] 0.53 0.57 0.73 0.53 0.60 0.47 0.50 0.60 0.50 0.63 0.70 0.67 0.60 0.60 0.50\n[151] 0.47 0.60 0.67 0.67 0.60 0.50 0.70 0.47 0.57 0.67 0.60 0.57 0.53 0.63 0.63\n[166] 0.60 0.57 0.57 0.57 0.67 0.57 0.60 0.40 0.53 0.60 0.53 0.57 0.53 0.47 0.63\n[181] 0.53 0.57 0.60 0.53 0.50 0.70 0.67 0.60 0.50 0.67 0.57 0.60 0.47 0.67 0.50\n[196]   NA 0.67\n\n\n\nConvert pmean_ratings to scientific notation.\n\n\nformat(traits2$pmean_ratings, scientific = TRUE)\n\n  [1] \"7.333333e-01\" \"6.333333e-01\" \"6.666667e-01\" \"7.333333e-01\" \"5.666667e-01\"\n  [6] \"6.333333e-01\" \"6.333333e-01\" \"5.333333e-01\" \"6.666667e-01\" \"5.666667e-01\"\n [11] \"6.333333e-01\" \"5.666667e-01\" \"6.666667e-01\" \"5.666667e-01\" \"5.333333e-01\"\n [16] \"7.333333e-01\" \"6.666667e-01\" \"6.333333e-01\" \"7.000000e-01\" \"7.000000e-01\"\n [21] \"6.333333e-01\" \"8.000000e-01\" \"5.666667e-01\" \"7.000000e-01\" \"4.666667e-01\"\n [26] \"6.000000e-01\" \"7.333333e-01\" \"6.000000e-01\" \"7.000000e-01\" \"7.333333e-01\"\n [31] \"7.333333e-01\" \"6.000000e-01\" \"6.000000e-01\" \"4.000000e-01\" \"6.666667e-01\"\n [36] \"6.333333e-01\" \"5.000000e-01\" \"5.666667e-01\" \"6.333333e-01\" \"6.333333e-01\"\n [41] \"7.000000e-01\" \"6.333333e-01\" \"5.666667e-01\" \"6.666667e-01\" \"7.333333e-01\"\n [46] \"5.333333e-01\" \"7.333333e-01\" \"4.666667e-01\" \"7.000000e-01\" \"5.666667e-01\"\n [51] \"6.000000e-01\" \"6.333333e-01\" \"6.333333e-01\" \"4.666667e-01\" \"5.000000e-01\"\n [56] \"6.666667e-01\" \"5.333333e-01\" \"6.333333e-01\" \"6.333333e-01\" \"5.333333e-01\"\n [61] \"5.000000e-01\" \"4.666667e-01\" \"6.333333e-01\" \"4.666667e-01\" \"5.333333e-01\"\n [66] \"5.666667e-01\" \"6.333333e-01\" \"7.000000e-01\" \"6.000000e-01\" \"5.666667e-01\"\n [71] \"5.666667e-01\" \"6.333333e-01\" \"5.000000e-01\" \"6.000000e-01\" \"7.333333e-01\"\n [76] \"6.333333e-01\" \"5.666667e-01\" \"5.333333e-01\" \"4.666667e-01\" \"7.333333e-01\"\n [81] \"6.000000e-01\" \"5.000000e-01\" \"6.333333e-01\" \"5.333333e-01\" \"4.333333e-01\"\n [86] \"4.333333e-01\" \"6.666667e-01\" \"5.666667e-01\" \"5.666667e-01\" \"6.666667e-01\"\n [91] \"5.666667e-01\" \"6.000000e-01\" \"5.666667e-01\" \"5.666667e-01\" \"6.000000e-01\"\n [96] \"7.333333e-01\" \"5.666667e-01\" \"7.333333e-01\" \"6.000000e-01\" \"5.000000e-01\"\n[101] \"6.666667e-01\" \"7.000000e-01\" \"5.000000e-01\" \"6.333333e-01\" \"5.000000e-01\"\n[106] \"5.000000e-01\" \"5.666667e-01\" \"5.666667e-01\" \"6.333333e-01\" \"6.000000e-01\"\n[111] \"6.333333e-01\" \"6.333333e-01\" \"5.666667e-01\" \"5.666667e-01\" \"6.000000e-01\"\n[116] \"6.333333e-01\" \"5.000000e-01\" \"6.333333e-01\" \"6.666667e-01\" \"5.000000e-01\"\n[121] \"5.666667e-01\" \"5.000000e-01\" \"5.666667e-01\" \"5.666667e-01\" \"7.333333e-01\"\n[126] \"5.666667e-01\" \"6.666667e-01\" \"6.666667e-01\" \"5.333333e-01\" \"6.333333e-01\"\n[131] \"4.666667e-01\" \"5.666667e-01\" \"5.333333e-01\" \"5.000000e-01\" \"5.333333e-01\"\n[136] \"5.333333e-01\" \"5.666667e-01\" \"7.333333e-01\" \"5.333333e-01\" \"6.000000e-01\"\n[141] \"4.666667e-01\" \"5.000000e-01\" \"6.000000e-01\" \"5.000000e-01\" \"6.333333e-01\"\n[146] \"7.000000e-01\" \"6.666667e-01\" \"6.000000e-01\" \"6.000000e-01\" \"5.000000e-01\"\n[151] \"4.666667e-01\" \"6.000000e-01\" \"6.666667e-01\" \"6.666667e-01\" \"6.000000e-01\"\n[156] \"5.000000e-01\" \"7.000000e-01\" \"4.666667e-01\" \"5.666667e-01\" \"6.666667e-01\"\n[161] \"6.000000e-01\" \"5.666667e-01\" \"5.333333e-01\" \"6.333333e-01\" \"6.333333e-01\"\n[166] \"6.000000e-01\" \"5.666667e-01\" \"5.666667e-01\" \"5.666667e-01\" \"6.666667e-01\"\n[171] \"5.666667e-01\" \"6.000000e-01\" \"4.000000e-01\" \"5.333333e-01\" \"6.000000e-01\"\n[176] \"5.333333e-01\" \"5.666667e-01\" \"5.333333e-01\" \"4.666667e-01\" \"6.333333e-01\"\n[181] \"5.333333e-01\" \"5.666667e-01\" \"6.000000e-01\" \"5.333333e-01\" \"5.000000e-01\"\n[186] \"7.000000e-01\" \"6.666667e-01\" \"6.000000e-01\" \"5.000000e-01\" \"6.666667e-01\"\n[191] \"5.666667e-01\" \"6.000000e-01\" \"4.666667e-01\" \"6.666667e-01\" \"5.000000e-01\"\n[196] \"          NA\" \"6.666667e-01\"\n\n\n\nSum up the total grooming ratings for each coat type.\n\n\ntraits |&gt; \n  count(coat_type, wt = grooming)\n\n# A tibble: 10 × 2\n   coat_type     n\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 Corded       14\n 2 Curly        21\n 3 Double      171\n 4 Hairless      4\n 5 Rough         8\n 6 Silky        30\n 7 Smooth      113\n 8 Wavy         15\n 9 Wiry         69\n10 &lt;NA&gt;          2\n\n\n\nAdd inline R code to the following sentence in R Markdown to say how many rows have NA for grooming:\n\nWe are missing grooming data for [insert inline R code] breeds."
  },
  {
    "objectID": "code/20_strings_answers.html",
    "href": "code/20_strings_answers.html",
    "title": "Strings",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nLoad tidyverse and import dog_breed_traits_clean.csv to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits_clean.csv\"), show_col_types = FALSE)\n\n\nReturn the first ten letters of the alphabet in upper case.\n\n\nLETTERS[1:10]\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\"\n\n\n\nCreate this character string and assign it to mystring: The elephant said “Hello” then ‘Bye!’ Then view how it would be printed.\n\n\n(mystring &lt;- \"The elephant said \\\"Hello\\\" then 'Bye'!\")\n\n[1] \"The elephant said \\\"Hello\\\" then 'Bye'!\"\n\nwriteLines(mystring)\n\nThe elephant said \"Hello\" then 'Bye'!\n\n\n\nFind how many characters are in mystring.\n\n\nstr_length(mystring)\n\n[1] 37\n\n\n\nCreate a vector of the first four characters of the coat_length column from traits.\n\n\nstr_sub(traits$coat_length, 1, 4)\n\n  [1] \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Shor\" \"Long\" \"Shor\" \"Shor\" \"Shor\" \"Shor\"\n [11] \"Shor\" \"Medi\" \"Long\" \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Shor\" \"Medi\" \"Long\"\n [21] \"Shor\" \"Medi\" \"Long\" \"Long\" \"Shor\" \"Medi\" \"Long\" \"Shor\" \"Shor\" \"Long\"\n [31] \"Medi\" \"Medi\" \"Shor\" \"Shor\" \"Shor\" \"Shor\" \"Shor\" \"Long\" \"Shor\" \"Shor\"\n [41] \"Medi\" \"Shor\" \"Shor\" \"Medi\" \"Long\" \"Shor\" \"Medi\" \"Medi\" \"Long\" \"Medi\"\n [51] \"Shor\" \"Shor\" \"Medi\" \"Shor\" \"Shor\" \"Long\" \"Medi\" \"Medi\" \"Shor\" \"Medi\"\n [61] \"Shor\" \"Shor\" \"Medi\" \"Shor\" \"Medi\" \"Medi\" \"Medi\" \"Long\" \"Shor\" \"Medi\"\n [71] \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Medi\" \"Shor\" \"Shor\" \"Long\" \"Shor\" \"Long\"\n [81] \"Shor\" \"Shor\" \"Shor\" \"Medi\" \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Shor\" \"Medi\"\n [91] \"Medi\" \"Medi\" \"Shor\" \"Medi\" \"Long\" \"Long\" \"Shor\" \"Long\" \"Long\" \"Shor\"\n[101] \"Medi\" \"Medi\" \"Medi\" \"Medi\" \"Shor\" \"Medi\" \"Medi\" \"Long\" \"Shor\" \"Medi\"\n[111] \"Medi\" \"Medi\" \"Shor\" \"Shor\" \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Medi\" \"Medi\"\n[121] \"Shor\" \"Long\" \"Shor\" \"Shor\" \"Long\" \"Medi\" \"Shor\" \"Medi\" \"Shor\" \"Shor\"\n[131] \"Shor\" \"Shor\" \"Medi\" \"Shor\" \"Medi\" \"Shor\" \"Shor\" \"Medi\" \"Shor\" \"Medi\"\n[141] \"Medi\" \"Shor\" \"Long\" \"Shor\" \"Medi\" \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Long\"\n[151] \"Medi\" \"Shor\" \"Shor\" \"Medi\" \"Shor\" \"Medi\" \"Medi\" \"Medi\" \"Shor\" \"Medi\"\n[161] \"Long\" \"Medi\" \"Shor\" \"Long\" \"Medi\" \"Medi\" \"Shor\" \"Medi\" \"Medi\" \"Medi\"\n[171] \"Shor\" \"Medi\" \"Long\" \"Medi\" \"Long\" \"Medi\" \"Medi\" \"Long\" \"Shor\" \"Shor\"\n[181] \"Medi\" \"Medi\" \"Long\" \"Shor\" \"Shor\" \"Medi\" \"Medi\" \"Medi\" \"Shor\" \"Shor\"\n[191] \"Medi\" \"Shor\" \"Shor\" \"Shor\" \"Shor\" \"Medi\" NA    \n\n\n\nConvert the breed column of traits to sentence case.\n\n\nstr_to_sentence(traits$breed)\n\n  [1] \"Retrievers (labrador)\"                \n  [2] \"French bulldogs\"                      \n  [3] \"German shepherd dogs\"                 \n  [4] \"Retrievers (golden)\"                  \n  [5] \"Bulldogs\"                             \n  [6] \"Poodles\"                              \n  [7] \"Beagles\"                              \n  [8] \"Rottweilers\"                          \n  [9] \"Pointers (german shorthaired)\"        \n [10] \"Dachshunds\"                           \n [11] \"Pembroke welsh corgis\"                \n [12] \"Australian shepherds\"                 \n [13] \"Yorkshire terriers\"                   \n [14] \"Boxers\"                               \n [15] \"Great danes\"                          \n [16] \"Siberian huskies\"                     \n [17] \"Cavalier king charles spaniels\"       \n [18] \"Doberman pinschers\"                   \n [19] \"Miniature schnauzers\"                 \n [20] \"Shih tzu\"                             \n [21] \"Boston terriers\"                      \n [22] \"Bernese mountain dogs\"                \n [23] \"Pomeranians\"                          \n [24] \"Havanese\"                             \n [25] \"Cane corso\"                           \n [26] \"Spaniels (english springer)\"          \n [27] \"Shetland sheepdogs\"                   \n [28] \"Brittanys\"                            \n [29] \"Pugs\"                                 \n [30] \"Spaniels (cocker)\"                    \n [31] \"Miniature american shepherds\"         \n [32] \"Border collies\"                       \n [33] \"Mastiffs\"                             \n [34] \"Chihuahuas\"                           \n [35] \"Vizslas\"                              \n [36] \"Basset hounds\"                        \n [37] \"Belgian malinois\"                     \n [38] \"Maltese\"                              \n [39] \"Weimaraners\"                          \n [40] \"Collies\"                              \n [41] \"Newfoundlands\"                        \n [42] \"Rhodesian ridgebacks\"                 \n [43] \"Shiba inu\"                            \n [44] \"West highland white terriers\"         \n [45] \"Bichons frises\"                       \n [46] \"Bloodhounds\"                          \n [47] \"Spaniels (english cocker)\"            \n [48] \"Akitas\"                               \n [49] \"Portuguese water dogs\"                \n [50] \"Retrievers (chesapeake bay)\"          \n [51] \"Dalmatians\"                           \n [52] \"St. Bernards\"                         \n [53] \"Papillons\"                            \n [54] \"Australian cattle dogs\"               \n [55] \"Bullmastiffs\"                         \n [56] \"Samoyeds\"                             \n [57] \"Scottish terriers\"                    \n [58] \"Soft coated wheaten terriers\"         \n [59] \"Whippets\"                             \n [60] \"Pointers (german wirehaired)\"         \n [61] \"Chinese shar-pei\"                     \n [62] \"Airedale terriers\"                    \n [63] \"Wirehaired pointing griffons\"         \n [64] \"Bull terriers\"                        \n [65] \"Alaskan malamutes\"                    \n [66] \"Cardigan welsh corgis\"                \n [67] \"Giant schnauzers\"                     \n [68] \"Old english sheepdogs\"                \n [69] \"Italian greyhounds\"                   \n [70] \"Great pyrenees\"                       \n [71] \"Dogues de bordeaux\"                   \n [72] \"Russell terriers\"                     \n [73] \"Cairn terriers\"                       \n [74] \"Irish wolfhounds\"                     \n [75] \"Setters (irish)\"                      \n [76] \"Greater swiss mountain dogs\"          \n [77] \"Miniature pinschers\"                  \n [78] \"Lhasa apsos\"                          \n [79] \"Chinese crested\"                      \n [80] \"Coton de tulear\"                      \n [81] \"Staffordshire bull terriers\"          \n [82] \"American staffordshire terriers\"      \n [83] \"Rat terriers\"                         \n [84] \"Chow chows\"                           \n [85] \"Anatolian shepherd dogs\"              \n [86] \"Basenjis\"                             \n [87] \"Spaniels (boykin)\"                    \n [88] \"Lagotti romagnoli\"                    \n [89] \"Brussels griffons\"                    \n [90] \"Retrievers (nova scotia duck tolling)\"\n [91] \"Norwegian elkhounds\"                  \n [92] \"Standard schnauzers\"                  \n [93] \"Dogo argentinos\"                      \n [94] \"Bouviers des flandres\"                \n [95] \"Pekingese\"                            \n [96] \"Keeshonden\"                           \n [97] \"Border terriers\"                      \n [98] \"Leonbergers\"                          \n [99] \"Tibetan terriers\"                     \n[100] \"Neapolitan mastiffs\"                  \n[101] \"Setters (english)\"                    \n[102] \"Retrievers (flat-coated)\"             \n[103] \"Borzois\"                              \n[104] \"Fox terriers (wire)\"                  \n[105] \"Miniature bull terriers\"              \n[106] \"Belgian tervuren\"                     \n[107] \"Setters (gordon)\"                     \n[108] \"Silky terriers\"                       \n[109] \"Norwich terriers\"                     \n[110] \"Spinoni italiani\"                     \n[111] \"Japanese chin\"                        \n[112] \"Welsh terriers\"                       \n[113] \"Toy fox terriers\"                     \n[114] \"Schipperkes\"                          \n[115] \"Parson russell terriers\"              \n[116] \"Pointers\"                             \n[117] \"Belgian sheepdogs\"                    \n[118] \"Tibetan spaniels\"                     \n[119] \"American eskimo dogs\"                 \n[120] \"Irish terriers\"                       \n[121] \"Beaucerons\"                           \n[122] \"Afghan hounds\"                        \n[123] \"Boerboels\"                            \n[124] \"Fox terriers (smooth)\"                \n[125] \"Bearded collies\"                      \n[126] \"Black russian terriers\"               \n[127] \"Black and tan coonhounds\"             \n[128] \"Spaniels (welsh springer)\"            \n[129] \"American hairless terriers\"           \n[130] \"Norfolk terriers\"                     \n[131] \"Xoloitzcuintli\"                       \n[132] \"Manchester terriers\"                  \n[133] \"Kerry blue terriers\"                  \n[134] \"Australian terriers\"                  \n[135] \"Spaniels (clumber)\"                   \n[136] \"Lakeland terriers\"                    \n[137] \"Bluetick coonhounds\"                  \n[138] \"English toy spaniels\"                 \n[139] \"German pinschers\"                     \n[140] \"Tibetan mastiffs\"                     \n[141] \"Bedlington terriers\"                  \n[142] \"Greyhounds\"                           \n[143] \"Pulik\"                                \n[144] \"Salukis\"                              \n[145] \"Barbets\"                              \n[146] \"Redbone coonhounds\"                   \n[147] \"Swedish vallhunds\"                    \n[148] \"Sealyham terriers\"                    \n[149] \"Spanish water dogs\"                   \n[150] \"Briards\"                              \n[151] \"Berger picards\"                       \n[152] \"Entlebucher mountain dogs\"            \n[153] \"Treeing walker coonhounds\"            \n[154] \"Icelandic sheepdogs\"                  \n[155] \"Wirehaired vizslas\"                   \n[156] \"Pumik\"                                \n[157] \"Portuguese podengo pequenos\"          \n[158] \"Spaniels (american water)\"            \n[159] \"Retrievers (curly-coated)\"            \n[160] \"Spaniels (field)\"                     \n[161] \"Lowchen\"                              \n[162] \"Nederlandse kooikerhondjes\"           \n[163] \"Affenpinschers\"                       \n[164] \"Petits bassets griffons vendeens\"     \n[165] \"Finnish lapphunds\"                    \n[166] \"Scottish deerhounds\"                  \n[167] \"Plott hounds\"                         \n[168] \"Norwegian buhunds\"                    \n[169] \"Glen of imaal terriers\"               \n[170] \"Setters (irish red and white)\"        \n[171] \"Ibizan hounds\"                        \n[172] \"Spaniels (sussex)\"                    \n[173] \"Bergamasco sheepdogs\"                 \n[174] \"Spaniels (irish water)\"               \n[175] \"Polish lowland sheepdogs\"             \n[176] \"Otterhounds\"                          \n[177] \"Kuvaszok\"                             \n[178] \"Komondorok\"                           \n[179] \"Cirnechi dell etna\"                   \n[180] \"Pharaoh hounds\"                       \n[181] \"Dandie dinmont terriers\"              \n[182] \"Pyrenean shepherds\"                   \n[183] \"Skye terriers\"                        \n[184] \"Canaan dogs\"                          \n[185] \"American english coonhounds\"          \n[186] \"Chinooks\"                             \n[187] \"Finnish spitz\"                        \n[188] \"Grand basset griffon vendeens\"        \n[189] \"Sloughis\"                             \n[190] \"Harriers\"                             \n[191] \"Cesky terriers\"                       \n[192] \"American foxhounds\"                   \n[193] \"Azawakhs\"                             \n[194] \"English foxhounds\"                    \n[195] \"Norwegian lundehunds\"                 \n[196] \"American rearsniffer\"                 \n[197] \"English buttdragger\"                  \n\n\n\nCreate series of sentences using breed and coat_length that states “[insert breed name] have a [insert coat length] coat” that uses the proper cases.\n\n\nstr_glue(\"{traits$breed} have a {str_to_lower(traits$coat_length)} coat\")\n\nRetrievers (Labrador) have a short coat\nFrench Bulldogs have a short coat\nGerman Shepherd Dogs have a medium coat\nRetrievers (Golden) have a medium coat\nBulldogs have a short coat\nPoodles have a long coat\nBeagles have a short coat\nRottweilers have a short coat\nPointers (German Shorthaired) have a short coat\nDachshunds have a short coat\nPembroke Welsh Corgis have a short coat\nAustralian Shepherds have a medium coat\nYorkshire Terriers have a long coat\nBoxers have a short coat\nGreat Danes have a short coat\nSiberian Huskies have a medium coat\nCavalier King Charles Spaniels have a medium coat\nDoberman Pinschers have a short coat\nMiniature Schnauzers have a medium coat\nShih Tzu have a long coat\nBoston Terriers have a short coat\nBernese Mountain Dogs have a medium coat\nPomeranians have a long coat\nHavanese have a long coat\nCane Corso have a short coat\nSpaniels (English Springer) have a medium coat\nShetland Sheepdogs have a long coat\nBrittanys have a short coat\nPugs have a short coat\nSpaniels (Cocker) have a long coat\nMiniature American Shepherds have a medium coat\nBorder Collies have a medium coat\nMastiffs have a short coat\nChihuahuas have a short coat\nVizslas have a short coat\nBasset Hounds have a short coat\nBelgian Malinois have a short coat\nMaltese have a long coat\nWeimaraners have a short coat\nCollies have a short coat\nNewfoundlands have a medium coat\nRhodesian Ridgebacks have a short coat\nShiba Inu have a short coat\nWest Highland White Terriers have a medium coat\nBichons Frises have a long coat\nBloodhounds have a short coat\nSpaniels (English Cocker) have a medium coat\nAkitas have a medium coat\nPortuguese Water Dogs have a long coat\nRetrievers (Chesapeake Bay) have a medium coat\nDalmatians have a short coat\nSt. Bernards have a short coat\nPapillons have a medium coat\nAustralian Cattle Dogs have a short coat\nBullmastiffs have a short coat\nSamoyeds have a long coat\nScottish Terriers have a medium coat\nSoft Coated Wheaten Terriers have a medium coat\nWhippets have a short coat\nPointers (German Wirehaired) have a medium coat\nChinese Shar-Pei have a short coat\nAiredale Terriers have a short coat\nWirehaired Pointing Griffons have a medium coat\nBull Terriers have a short coat\nAlaskan Malamutes have a medium coat\nCardigan Welsh Corgis have a medium coat\nGiant Schnauzers have a medium coat\nOld English Sheepdogs have a long coat\nItalian Greyhounds have a short coat\nGreat Pyrenees have a medium coat\nDogues de Bordeaux have a short coat\nRussell Terriers have a short coat\nCairn Terriers have a medium coat\nIrish Wolfhounds have a medium coat\nSetters (Irish) have a medium coat\nGreater Swiss Mountain Dogs have a short coat\nMiniature Pinschers have a short coat\nLhasa Apsos have a long coat\nChinese Crested have a short coat\nCoton de Tulear have a long coat\nStaffordshire Bull Terriers have a short coat\nAmerican Staffordshire Terriers have a short coat\nRat Terriers have a short coat\nChow Chows have a medium coat\nAnatolian Shepherd Dogs have a short coat\nBasenjis have a short coat\nSpaniels (Boykin) have a medium coat\nLagotti Romagnoli have a medium coat\nBrussels Griffons have a short coat\nRetrievers (Nova Scotia Duck Tolling) have a medium coat\nNorwegian Elkhounds have a medium coat\nStandard Schnauzers have a medium coat\nDogo Argentinos have a short coat\nBouviers des Flandres have a medium coat\nPekingese have a long coat\nKeeshonden have a long coat\nBorder Terriers have a short coat\nLeonbergers have a long coat\nTibetan Terriers have a long coat\nNeapolitan Mastiffs have a short coat\nSetters (English) have a medium coat\nRetrievers (Flat-Coated) have a medium coat\nBorzois have a medium coat\nFox Terriers (Wire) have a medium coat\nMiniature Bull Terriers have a short coat\nBelgian Tervuren have a medium coat\nSetters (Gordon) have a medium coat\nSilky Terriers have a long coat\nNorwich Terriers have a short coat\nSpinoni Italiani have a medium coat\nJapanese Chin have a medium coat\nWelsh Terriers have a medium coat\nToy Fox Terriers have a short coat\nSchipperkes have a short coat\nParson Russell Terriers have a short coat\nPointers have a short coat\nBelgian Sheepdogs have a medium coat\nTibetan Spaniels have a medium coat\nAmerican Eskimo Dogs have a medium coat\nIrish Terriers have a medium coat\nBeaucerons have a short coat\nAfghan Hounds have a long coat\nBoerboels have a short coat\nFox Terriers (Smooth) have a short coat\nBearded Collies have a long coat\nBlack Russian Terriers have a medium coat\nBlack and Tan Coonhounds have a short coat\nSpaniels (Welsh Springer) have a medium coat\nAmerican Hairless Terriers have a short coat\nNorfolk Terriers have a short coat\nXoloitzcuintli have a short coat\nManchester Terriers have a short coat\nKerry Blue Terriers have a medium coat\nAustralian Terriers have a short coat\nSpaniels (Clumber) have a medium coat\nLakeland Terriers have a short coat\nBluetick Coonhounds have a short coat\nEnglish Toy Spaniels have a medium coat\nGerman Pinschers have a short coat\nTibetan Mastiffs have a medium coat\nBedlington Terriers have a medium coat\nGreyhounds have a short coat\nPulik have a long coat\nSalukis have a short coat\nBarbets have a medium coat\nRedbone Coonhounds have a short coat\nSwedish Vallhunds have a short coat\nSealyham Terriers have a medium coat\nSpanish Water Dogs have a medium coat\nBriards have a long coat\nBerger Picards have a medium coat\nEntlebucher Mountain Dogs have a short coat\nTreeing Walker Coonhounds have a short coat\nIcelandic Sheepdogs have a medium coat\nWirehaired Vizslas have a short coat\nPumik have a medium coat\nPortuguese Podengo Pequenos have a medium coat\nSpaniels (American Water) have a medium coat\nRetrievers (Curly-Coated) have a short coat\nSpaniels (Field) have a medium coat\nLowchen have a long coat\nNederlandse Kooikerhondjes have a medium coat\nAffenpinschers have a short coat\nPetits Bassets Griffons Vendeens have a long coat\nFinnish Lapphunds have a medium coat\nScottish Deerhounds have a medium coat\nPlott Hounds have a short coat\nNorwegian Buhunds have a medium coat\nGlen of Imaal Terriers have a medium coat\nSetters (Irish Red and White) have a medium coat\nIbizan Hounds have a short coat\nSpaniels (Sussex) have a medium coat\nBergamasco Sheepdogs have a long coat\nSpaniels (Irish Water) have a medium coat\nPolish Lowland Sheepdogs have a long coat\nOtterhounds have a medium coat\nKuvaszok have a medium coat\nKomondorok have a long coat\nCirnechi dell Etna have a short coat\nPharaoh Hounds have a short coat\nDandie Dinmont Terriers have a medium coat\nPyrenean Shepherds have a medium coat\nSkye Terriers have a long coat\nCanaan Dogs have a short coat\nAmerican English Coonhounds have a short coat\nChinooks have a medium coat\nFinnish Spitz have a medium coat\nGrand Basset Griffon Vendeens have a medium coat\nSloughis have a short coat\nHarriers have a short coat\nCesky Terriers have a medium coat\nAmerican Foxhounds have a short coat\nAzawakhs have a short coat\nEnglish Foxhounds have a short coat\nNorwegian Lundehunds have a short coat\nAmerican Rearsniffer have a medium coat\nEnglish Buttdragger have a NA coat\n\n\n\nIn the mtcars data set, extract the first two digits of the mpg variable and the last three digits of the car names and combine them into a single string.\n\n\nstr_glue(\"{str_sub(mtcars$mpg, 1, 2)}{str_sub(row.names(mtcars), -3, -1)}\")\n\n21RX4\n21Wag\n22710\n21ive\n18out\n18ant\n14360\n2440D\n22230\n19280\n1780C\n160SE\n170SL\n15SLC\n10ood\n10tal\n14ial\n32128\n30vic\n33lla\n21ona\n15ger\n15lin\n13Z28\n19ird\n271-9\n264-2\n30opa\n15a L\n19ino\n15ora\n2142E\n\n\n\nPrint the fruit data set, then capitalize all first word letters in the data set, then capitalize all words in the data set.\n\n\nfruit\n\n [1] \"apple\"             \"apricot\"           \"avocado\"          \n [4] \"banana\"            \"bell pepper\"       \"bilberry\"         \n [7] \"blackberry\"        \"blackcurrant\"      \"blood orange\"     \n[10] \"blueberry\"         \"boysenberry\"       \"breadfruit\"       \n[13] \"canary melon\"      \"cantaloupe\"        \"cherimoya\"        \n[16] \"cherry\"            \"chili pepper\"      \"clementine\"       \n[19] \"cloudberry\"        \"coconut\"           \"cranberry\"        \n[22] \"cucumber\"          \"currant\"           \"damson\"           \n[25] \"date\"              \"dragonfruit\"       \"durian\"           \n[28] \"eggplant\"          \"elderberry\"        \"feijoa\"           \n[31] \"fig\"               \"goji berry\"        \"gooseberry\"       \n[34] \"grape\"             \"grapefruit\"        \"guava\"            \n[37] \"honeydew\"          \"huckleberry\"       \"jackfruit\"        \n[40] \"jambul\"            \"jujube\"            \"kiwi fruit\"       \n[43] \"kumquat\"           \"lemon\"             \"lime\"             \n[46] \"loquat\"            \"lychee\"            \"mandarine\"        \n[49] \"mango\"             \"mulberry\"          \"nectarine\"        \n[52] \"nut\"               \"olive\"             \"orange\"           \n[55] \"pamelo\"            \"papaya\"            \"passionfruit\"     \n[58] \"peach\"             \"pear\"              \"persimmon\"        \n[61] \"physalis\"          \"pineapple\"         \"plum\"             \n[64] \"pomegranate\"       \"pomelo\"            \"purple mangosteen\"\n[67] \"quince\"            \"raisin\"            \"rambutan\"         \n[70] \"raspberry\"         \"redcurrant\"        \"rock melon\"       \n[73] \"salal berry\"       \"satsuma\"           \"star fruit\"       \n[76] \"strawberry\"        \"tamarillo\"         \"tangerine\"        \n[79] \"ugli fruit\"        \"watermelon\"       \n\nstr_to_sentence(fruit)\n\n [1] \"Apple\"             \"Apricot\"           \"Avocado\"          \n [4] \"Banana\"            \"Bell pepper\"       \"Bilberry\"         \n [7] \"Blackberry\"        \"Blackcurrant\"      \"Blood orange\"     \n[10] \"Blueberry\"         \"Boysenberry\"       \"Breadfruit\"       \n[13] \"Canary melon\"      \"Cantaloupe\"        \"Cherimoya\"        \n[16] \"Cherry\"            \"Chili pepper\"      \"Clementine\"       \n[19] \"Cloudberry\"        \"Coconut\"           \"Cranberry\"        \n[22] \"Cucumber\"          \"Currant\"           \"Damson\"           \n[25] \"Date\"              \"Dragonfruit\"       \"Durian\"           \n[28] \"Eggplant\"          \"Elderberry\"        \"Feijoa\"           \n[31] \"Fig\"               \"Goji berry\"        \"Gooseberry\"       \n[34] \"Grape\"             \"Grapefruit\"        \"Guava\"            \n[37] \"Honeydew\"          \"Huckleberry\"       \"Jackfruit\"        \n[40] \"Jambul\"            \"Jujube\"            \"Kiwi fruit\"       \n[43] \"Kumquat\"           \"Lemon\"             \"Lime\"             \n[46] \"Loquat\"            \"Lychee\"            \"Mandarine\"        \n[49] \"Mango\"             \"Mulberry\"          \"Nectarine\"        \n[52] \"Nut\"               \"Olive\"             \"Orange\"           \n[55] \"Pamelo\"            \"Papaya\"            \"Passionfruit\"     \n[58] \"Peach\"             \"Pear\"              \"Persimmon\"        \n[61] \"Physalis\"          \"Pineapple\"         \"Plum\"             \n[64] \"Pomegranate\"       \"Pomelo\"            \"Purple mangosteen\"\n[67] \"Quince\"            \"Raisin\"            \"Rambutan\"         \n[70] \"Raspberry\"         \"Redcurrant\"        \"Rock melon\"       \n[73] \"Salal berry\"       \"Satsuma\"           \"Star fruit\"       \n[76] \"Strawberry\"        \"Tamarillo\"         \"Tangerine\"        \n[79] \"Ugli fruit\"        \"Watermelon\"       \n\nstr_to_title(fruit)\n\n [1] \"Apple\"             \"Apricot\"           \"Avocado\"          \n [4] \"Banana\"            \"Bell Pepper\"       \"Bilberry\"         \n [7] \"Blackberry\"        \"Blackcurrant\"      \"Blood Orange\"     \n[10] \"Blueberry\"         \"Boysenberry\"       \"Breadfruit\"       \n[13] \"Canary Melon\"      \"Cantaloupe\"        \"Cherimoya\"        \n[16] \"Cherry\"            \"Chili Pepper\"      \"Clementine\"       \n[19] \"Cloudberry\"        \"Coconut\"           \"Cranberry\"        \n[22] \"Cucumber\"          \"Currant\"           \"Damson\"           \n[25] \"Date\"              \"Dragonfruit\"       \"Durian\"           \n[28] \"Eggplant\"          \"Elderberry\"        \"Feijoa\"           \n[31] \"Fig\"               \"Goji Berry\"        \"Gooseberry\"       \n[34] \"Grape\"             \"Grapefruit\"        \"Guava\"            \n[37] \"Honeydew\"          \"Huckleberry\"       \"Jackfruit\"        \n[40] \"Jambul\"            \"Jujube\"            \"Kiwi Fruit\"       \n[43] \"Kumquat\"           \"Lemon\"             \"Lime\"             \n[46] \"Loquat\"            \"Lychee\"            \"Mandarine\"        \n[49] \"Mango\"             \"Mulberry\"          \"Nectarine\"        \n[52] \"Nut\"               \"Olive\"             \"Orange\"           \n[55] \"Pamelo\"            \"Papaya\"            \"Passionfruit\"     \n[58] \"Peach\"             \"Pear\"              \"Persimmon\"        \n[61] \"Physalis\"          \"Pineapple\"         \"Plum\"             \n[64] \"Pomegranate\"       \"Pomelo\"            \"Purple Mangosteen\"\n[67] \"Quince\"            \"Raisin\"            \"Rambutan\"         \n[70] \"Raspberry\"         \"Redcurrant\"        \"Rock Melon\"       \n[73] \"Salal Berry\"       \"Satsuma\"           \"Star Fruit\"       \n[76] \"Strawberry\"        \"Tamarillo\"         \"Tangerine\"        \n[79] \"Ugli Fruit\"        \"Watermelon\""
  },
  {
    "objectID": "code/21_patterns_answers.html",
    "href": "code/21_patterns_answers.html",
    "title": "Matching patterns",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nLoad tidyverse, import dog_breed_traits_clean.csv to traits, and extract the breed column into an object called breeds that randomly shuffles the breeds using 12 as a seed for randomization.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits_clean.csv\"), show_col_types = FALSE)\nset.seed(12)\nbreeds &lt;- sample(traits$breed)\n\n\nView the breeds ending with the letter “s”.\n\n\nstr_view_all(breeds, \"s$\")\n\nWarning: `str_view_all()` was deprecated in stringr 1.5.0.\nℹ Please use `str_view()` instead.\n\n\n [1] │ English Foxhound&lt;s&gt;\n [2] │ Retrievers (Nova Scotia Duck Tolling)\n [3] │ Coton de Tulear\n [4] │ Norwegian Elkhound&lt;s&gt;\n [5] │ Spaniels (Irish Water)\n [6] │ Italian Greyhound&lt;s&gt;\n [7] │ Chihuahua&lt;s&gt;\n [8] │ Lakeland Terrier&lt;s&gt;\n [9] │ English Buttdragger\n[10] │ American Staffordshire Terrier&lt;s&gt;\n[11] │ Bearded Collie&lt;s&gt;\n[12] │ Beauceron&lt;s&gt;\n[13] │ Maltese\n[14] │ Silky Terrier&lt;s&gt;\n[15] │ Belgian Tervuren\n[16] │ Otterhound&lt;s&gt;\n[17] │ Yorkshire Terrier&lt;s&gt;\n[18] │ Entlebucher Mountain Dog&lt;s&gt;\n[19] │ Scottish Terrier&lt;s&gt;\n[20] │ Russell Terrier&lt;s&gt;\n... and 177 more\n\n\n\nCreate a logical vector showing whether breeds have at least two words in their names.\n\n\nstr_detect(breeds, \" \")\n\n  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE\n [13] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n [25] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE\n [61]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n [73]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[109] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n[121]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n[133]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE\n[145]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n[157]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[169]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[181]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n[193]  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\nExtract the hounds (but don’t release them). That is, return a vector of all breeds that include the string “hound” or “Hound”.\n\n\nstr_subset(breeds, \"hound|Hound\")\n\n [1] \"English Foxhounds\"           \"Norwegian Elkhounds\"        \n [3] \"Italian Greyhounds\"          \"Otterhounds\"                \n [5] \"Black and Tan Coonhounds\"    \"Afghan Hounds\"              \n [7] \"Ibizan Hounds\"               \"Plott Hounds\"               \n [9] \"Redbone Coonhounds\"          \"Irish Wolfhounds\"           \n[11] \"American English Coonhounds\" \"Treeing Walker Coonhounds\"  \n[13] \"Bluetick Coonhounds\"         \"Scottish Deerhounds\"        \n[15] \"American Foxhounds\"          \"Greyhounds\"                 \n[17] \"Pharaoh Hounds\"              \"Basset Hounds\"              \n[19] \"Bloodhounds\"                \n\n\n\nExtract the breeds that include the following pattern “&lt;wildcard&gt;ep”.\n\n\nstr_subset(breeds, \".ep\")\n\n [1] \"Icelandic Sheepdogs\"          \"Shetland Sheepdogs\"          \n [3] \"Anatolian Shepherd Dogs\"      \"Australian Shepherds\"        \n [5] \"Pyrenean Shepherds\"           \"German Shepherd Dogs\"        \n [7] \"Bergamasco Sheepdogs\"         \"Old English Sheepdogs\"       \n [9] \"Polish Lowland Sheepdogs\"     \"Miniature American Shepherds\"\n[11] \"Belgian Sheepdogs\"           \n\n\n\nOK, maybe English Buttdragger isn’t the proper AKC name for this breed. Replace English Buttdragger with English Chaser.\n\n\nstr_replace(breeds, \"English Buttdragger\", \"English Chaser\")\n\n  [1] \"English Foxhounds\"                    \n  [2] \"Retrievers (Nova Scotia Duck Tolling)\"\n  [3] \"Coton de Tulear\"                      \n  [4] \"Norwegian Elkhounds\"                  \n  [5] \"Spaniels (Irish Water)\"               \n  [6] \"Italian Greyhounds\"                   \n  [7] \"Chihuahuas\"                           \n  [8] \"Lakeland Terriers\"                    \n  [9] \"English Chaser\"                       \n [10] \"American Staffordshire Terriers\"      \n [11] \"Bearded Collies\"                      \n [12] \"Beaucerons\"                           \n [13] \"Maltese\"                              \n [14] \"Silky Terriers\"                       \n [15] \"Belgian Tervuren\"                     \n [16] \"Otterhounds\"                          \n [17] \"Yorkshire Terriers\"                   \n [18] \"Entlebucher Mountain Dogs\"            \n [19] \"Scottish Terriers\"                    \n [20] \"Russell Terriers\"                     \n [21] \"Black and Tan Coonhounds\"             \n [22] \"Afghan Hounds\"                        \n [23] \"Ibizan Hounds\"                        \n [24] \"Azawakhs\"                             \n [25] \"Borzois\"                              \n [26] \"Spaniels (Cocker)\"                    \n [27] \"Finnish Lapphunds\"                    \n [28] \"Chinooks\"                             \n [29] \"Cesky Terriers\"                       \n [30] \"Plott Hounds\"                         \n [31] \"Dogues de Bordeaux\"                   \n [32] \"Icelandic Sheepdogs\"                  \n [33] \"Border Collies\"                       \n [34] \"Chow Chows\"                           \n [35] \"Sealyham Terriers\"                    \n [36] \"Miniature Schnauzers\"                 \n [37] \"Petits Bassets Griffons Vendeens\"     \n [38] \"Retrievers (Golden)\"                  \n [39] \"Bedlington Terriers\"                  \n [40] \"Welsh Terriers\"                       \n [41] \"Sloughis\"                             \n [42] \"Akitas\"                               \n [43] \"Norwegian Buhunds\"                    \n [44] \"Shetland Sheepdogs\"                   \n [45] \"Miniature Pinschers\"                  \n [46] \"Lowchen\"                              \n [47] \"Fox Terriers (Wire)\"                  \n [48] \"Kerry Blue Terriers\"                  \n [49] \"Redbone Coonhounds\"                   \n [50] \"Anatolian Shepherd Dogs\"              \n [51] \"Soft Coated Wheaten Terriers\"         \n [52] \"Dandie Dinmont Terriers\"              \n [53] \"Lagotti Romagnoli\"                    \n [54] \"Weimaraners\"                          \n [55] \"Brittanys\"                            \n [56] \"Collies\"                              \n [57] \"Great Danes\"                          \n [58] \"Berger Picards\"                       \n [59] \"Spaniels (Clumber)\"                   \n [60] \"Boxers\"                               \n [61] \"Irish Wolfhounds\"                     \n [62] \"Rhodesian Ridgebacks\"                 \n [63] \"Norwegian Lundehunds\"                 \n [64] \"Briards\"                              \n [65] \"Setters (Irish)\"                      \n [66] \"Bernese Mountain Dogs\"                \n [67] \"Giant Schnauzers\"                     \n [68] \"Pointers\"                             \n [69] \"Xoloitzcuintli\"                       \n [70] \"Bulldogs\"                             \n [71] \"Basenjis\"                             \n [72] \"Harriers\"                             \n [73] \"Siberian Huskies\"                     \n [74] \"Whippets\"                             \n [75] \"American English Coonhounds\"          \n [76] \"Doberman Pinschers\"                   \n [77] \"Cardigan Welsh Corgis\"                \n [78] \"Tibetan Mastiffs\"                     \n [79] \"Rat Terriers\"                         \n [80] \"Dachshunds\"                           \n [81] \"Retrievers (Chesapeake Bay)\"          \n [82] \"Chinese Crested\"                      \n [83] \"Poodles\"                              \n [84] \"Retrievers (Labrador)\"                \n [85] \"Fox Terriers (Smooth)\"                \n [86] \"Wirehaired Vizslas\"                   \n [87] \"Bichons Frises\"                       \n [88] \"West Highland White Terriers\"         \n [89] \"Miniature Bull Terriers\"              \n [90] \"Spaniels (Field)\"                     \n [91] \"Australian Shepherds\"                 \n [92] \"Bullmastiffs\"                         \n [93] \"Pyrenean Shepherds\"                   \n [94] \"Cirnechi dell Etna\"                   \n [95] \"Chinese Shar-Pei\"                     \n [96] \"Skye Terriers\"                        \n [97] \"Norwich Terriers\"                     \n [98] \"Treeing Walker Coonhounds\"            \n [99] \"Barbets\"                              \n[100] \"Rottweilers\"                          \n[101] \"Cairn Terriers\"                       \n[102] \"Spanish Water Dogs\"                   \n[103] \"Portuguese Podengo Pequenos\"          \n[104] \"Bluetick Coonhounds\"                  \n[105] \"Shih Tzu\"                             \n[106] \"Toy Fox Terriers\"                     \n[107] \"Scottish Deerhounds\"                  \n[108] \"Spaniels (Welsh Springer)\"            \n[109] \"Beagles\"                              \n[110] \"German Shepherd Dogs\"                 \n[111] \"Glen of Imaal Terriers\"               \n[112] \"American Foxhounds\"                   \n[113] \"Bergamasco Sheepdogs\"                 \n[114] \"Pugs\"                                 \n[115] \"Affenpinschers\"                       \n[116] \"Pumik\"                                \n[117] \"Setters (Gordon)\"                     \n[118] \"French Bulldogs\"                      \n[119] \"Leonbergers\"                          \n[120] \"Pointers (German Wirehaired)\"         \n[121] \"Alaskan Malamutes\"                    \n[122] \"Pembroke Welsh Corgis\"                \n[123] \"Nederlandse Kooikerhondjes\"           \n[124] \"Retrievers (Curly-Coated)\"            \n[125] \"Australian Terriers\"                  \n[126] \"Cavalier King Charles Spaniels\"       \n[127] \"Retrievers (Flat-Coated)\"             \n[128] \"Mastiffs\"                             \n[129] \"Shiba Inu\"                            \n[130] \"Dalmatians\"                           \n[131] \"Spaniels (American Water)\"            \n[132] \"Greyhounds\"                           \n[133] \"Black Russian Terriers\"               \n[134] \"Salukis\"                              \n[135] \"Spaniels (Sussex)\"                    \n[136] \"Pharaoh Hounds\"                       \n[137] \"Setters (English)\"                    \n[138] \"Spaniels (English Cocker)\"            \n[139] \"Kuvaszok\"                             \n[140] \"Cane Corso\"                           \n[141] \"Pomeranians\"                          \n[142] \"Great Pyrenees\"                       \n[143] \"Schipperkes\"                          \n[144] \"Papillons\"                            \n[145] \"Finnish Spitz\"                        \n[146] \"Tibetan Terriers\"                     \n[147] \"Newfoundlands\"                        \n[148] \"Neapolitan Mastiffs\"                  \n[149] \"Samoyeds\"                             \n[150] \"Keeshonden\"                           \n[151] \"Setters (Irish Red and White)\"        \n[152] \"Greater Swiss Mountain Dogs\"          \n[153] \"Canaan Dogs\"                          \n[154] \"St. Bernards\"                         \n[155] \"Pulik\"                                \n[156] \"Spinoni Italiani\"                     \n[157] \"Old English Sheepdogs\"                \n[158] \"Tibetan Spaniels\"                     \n[159] \"Japanese Chin\"                        \n[160] \"Basset Hounds\"                        \n[161] \"Havanese\"                             \n[162] \"Wirehaired Pointing Griffons\"         \n[163] \"American Eskimo Dogs\"                 \n[164] \"English Toy Spaniels\"                 \n[165] \"Polish Lowland Sheepdogs\"             \n[166] \"Portuguese Water Dogs\"                \n[167] \"Irish Terriers\"                       \n[168] \"Lhasa Apsos\"                          \n[169] \"German Pinschers\"                     \n[170] \"Border Terriers\"                      \n[171] \"Komondorok\"                           \n[172] \"Parson Russell Terriers\"              \n[173] \"Bouviers des Flandres\"                \n[174] \"Staffordshire Bull Terriers\"          \n[175] \"Norfolk Terriers\"                     \n[176] \"Belgian Malinois\"                     \n[177] \"Swedish Vallhunds\"                    \n[178] \"Grand Basset Griffon Vendeens\"        \n[179] \"Brussels Griffons\"                    \n[180] \"Pointers (German Shorthaired)\"        \n[181] \"Miniature American Shepherds\"         \n[182] \"Bloodhounds\"                          \n[183] \"Australian Cattle Dogs\"               \n[184] \"Boerboels\"                            \n[185] \"Dogo Argentinos\"                      \n[186] \"Pekingese\"                            \n[187] \"Bull Terriers\"                        \n[188] \"Vizslas\"                              \n[189] \"Standard Schnauzers\"                  \n[190] \"Spaniels (English Springer)\"          \n[191] \"Airedale Terriers\"                    \n[192] \"Spaniels (Boykin)\"                    \n[193] \"Belgian Sheepdogs\"                    \n[194] \"Manchester Terriers\"                  \n[195] \"American Rearsniffer\"                 \n[196] \"Boston Terriers\"                      \n[197] \"American Hairless Terriers\"           \n\n\n\nReplace all instances of “English” with “British” and then return the breeds that include “English” or “British” in them (to check our work).\n\n\nstr_replace(breeds, \"English\", \"British\") |&gt; \n  str_subset(\"English|British\")\n\n[1] \"British Foxhounds\"           \"British Buttdragger\"        \n[3] \"American British Coonhounds\" \"Setters (British)\"          \n[5] \"Spaniels (British Cocker)\"   \"Old British Sheepdogs\"      \n[7] \"British Toy Spaniels\"        \"Spaniels (British Springer)\"\n\n\n\nExtract the Spaniels and then separate the breed names into different strings for each word and create a matrix out of it.\n\n\nbreeds |&gt; \n  str_subset(\"spaniel|Spaniel\") |&gt; \n  str_split(\"\\\\s\", simplify = TRUE)\n\n      [,1]       [,2]        [,3]        [,4]      \n [1,] \"Spaniels\" \"(Irish\"    \"Water)\"    \"\"        \n [2,] \"Spaniels\" \"(Cocker)\"  \"\"          \"\"        \n [3,] \"Spaniels\" \"(Clumber)\" \"\"          \"\"        \n [4,] \"Spaniels\" \"(Field)\"   \"\"          \"\"        \n [5,] \"Spaniels\" \"(Welsh\"    \"Springer)\" \"\"        \n [6,] \"Cavalier\" \"King\"      \"Charles\"   \"Spaniels\"\n [7,] \"Spaniels\" \"(American\" \"Water)\"    \"\"        \n [8,] \"Spaniels\" \"(Sussex)\"  \"\"          \"\"        \n [9,] \"Spaniels\" \"(English\"  \"Cocker)\"   \"\"        \n[10,] \"Tibetan\"  \"Spaniels\"  \"\"          \"\"        \n[11,] \"English\"  \"Toy\"       \"Spaniels\"  \"\"        \n[12,] \"Spaniels\" \"(English\"  \"Springer)\" \"\"        \n[13,] \"Spaniels\" \"(Boykin)\"  \"\"          \"\""
  },
  {
    "objectID": "code/22_factors_answers.html",
    "href": "code/22_factors_answers.html",
    "title": "Factors",
    "section": "",
    "text": "For these exercises, we’ll use the dog breed traits data set.\n\nLoad tidyverse, import dog_breed_traits_clean.csv to traits.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntraits &lt;- read_csv(here::here(\"data/dog_breed_traits_clean.csv\"), show_col_types = FALSE)\nset.seed(12)\nbreeds &lt;- sample(traits$breed)\n\n\nConvert both coat_type and coat_length into factors using across() and save as traits2.\n\n\ntraits2 &lt;- traits |&gt; \n  mutate(across(contains(\"coat\"), factor))\n\n\nCheck the levels for both columns, one using a pipe and one without using a pipe.\n\n\nlevels(traits2$coat_type)\n\n[1] \"Corded\"   \"Curly\"    \"Double\"   \"Hairless\" \"Rough\"    \"Silky\"    \"Smooth\"  \n[8] \"Wavy\"     \"Wiry\"    \n\ntraits2 |&gt; \n  pull(coat_length) |&gt; \n  levels()\n\n[1] \"Long\"   \"Medium\" \"Short\" \n\n\n\nReorder the levels for coat_length to be Short, Medium, Long (reassigned to traits2) and then check the levels.\n\n\ntraits2 &lt;- traits2 |&gt; \n  mutate(coat_length = fct_relevel(coat_length, \"Short\", \"Medium\", \"Long\"))\nlevels(traits2$coat_length)\n\n[1] \"Short\"  \"Medium\" \"Long\"  \n\n\n\nReorder the levels for coat_type to be in the order of the most to least frequent coat type and then check the levels.\n\n\ntraits2 &lt;- traits2 |&gt; \n  mutate(coat_type = fct_infreq(coat_type))\nlevels(traits2$coat_type)\n\n[1] \"Smooth\"   \"Double\"   \"Wiry\"     \"Silky\"    \"Curly\"    \"Wavy\"     \"Corded\"  \n[8] \"Rough\"    \"Hairless\"\n\n\n\nRelabel coat_length to be Stubby, Mid, and Lush rather than Short, Medium, and Long.\n\n\ntraits2 &lt;- traits2 |&gt; \n  mutate(coat_length = fct_recode(coat_length, \"Stubby\" = \"Short\",\n                                  \"Mid\" = \"Medium\",\n                                  \"Lush\" = \"Long\"))\nlevels(traits2$coat_length)\n\n[1] \"Stubby\" \"Mid\"    \"Lush\"  \n\n\n\nThe new AKC standard subsumes Rough coats with Wiry coats and Silky with Wavy. Please update the coat_type variable accordingly.\n\n\ntraits2 &lt;- traits2 |&gt; \n  mutate(coat_type = fct_collapse(coat_type, Wiry = c(\"Rough\", \"Wiry\"),\n                                  Wavy = c(\"Silky\", \"Wavy\")))\nlevels(traits2$coat_type)\n\n[1] \"Smooth\"   \"Double\"   \"Wiry\"     \"Wavy\"     \"Curly\"    \"Corded\"   \"Hairless\""
  },
  {
    "objectID": "code/23_dates_answers.html",
    "href": "code/23_dates_answers.html",
    "title": "Dates and times",
    "section": "",
    "text": "For these exercises, we’ll use the dates data set.\n\nLoad tidyverse, import dates.csv to dates, and view the data set.\n\n\nlibrary(tidyverse)\ndates &lt;- read_csv(here::here(\"data/dates.csv\"), show_col_types = FALSE)\n\n\nConvert birth_date to a date object and resave dates.\n\n\ndates &lt;- dates |&gt; \n  mutate(birth_date = mdy(birth_date))\n\n\nCreate a column called time1 that converts test1 to datetime and change the time zone to “America/Chicago”.\n\n\ndates |&gt; \n  mutate(time1 = as_datetime(test1, tz = \"America/Chicago\"))\n\n# A tibble: 20 × 5\n      id birth_date test1      test2      time1              \n   &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;dttm&gt;             \n 1     1 1968-02-13 2022-02-23 2022-06-16 2022-02-23 00:00:00\n 2     2 1990-09-14 2022-01-09 2022-08-14 2022-01-09 00:00:00\n 3     3 1964-12-05 2022-03-26 2022-08-24 2022-03-26 00:00:00\n 4     4 1998-10-23 2022-02-26 2022-08-26 2022-02-26 00:00:00\n 5     5 1957-06-05 2022-01-18 2022-06-14 2022-01-18 00:00:00\n 6     6 1969-09-14 2022-03-21 2022-08-24 2022-03-21 00:00:00\n 7     7 1958-08-09 2022-03-27 2022-09-30 2022-03-27 00:00:00\n 8     8 2001-11-18 2022-03-30 2022-08-03 2022-03-30 00:00:00\n 9     9 1988-08-10 2022-01-29 2022-06-02 2022-01-29 00:00:00\n10    10 1955-03-19 2022-01-11 2022-07-11 2022-01-11 00:00:00\n11    11 1960-02-21 2022-02-27 2022-09-30 2022-02-27 00:00:00\n12    12 1951-11-07 2022-02-06 2022-06-07 2022-02-06 00:00:00\n13    13 1978-07-03 2022-03-22 2022-06-24 2022-03-22 00:00:00\n14    14 1965-04-14 2022-03-16 2022-09-10 2022-03-16 00:00:00\n15    15 1973-06-12 2022-03-24 2022-07-02 2022-03-24 00:00:00\n16    16 1969-10-24 2022-01-05 2022-09-10 2022-01-05 00:00:00\n17    17 1973-09-04 2022-03-02 2022-07-03 2022-03-02 00:00:00\n18    18 1963-09-16 2022-03-29 2022-06-09 2022-03-29 00:00:00\n19    19 1950-10-21 2022-03-19 2022-07-04 2022-03-19 00:00:00\n20    20 1974-02-20 2022-02-14 2022-08-03 2022-02-14 00:00:00\n\n\n\nCalculate each participant’s age in years at the time of test 1, rounded to 1 decimal place, stored in age and resave dates.\n\n\ndates &lt;- dates |&gt; \n  mutate(age = round(as.numeric(test1 - birth_date) / 365.25, 1))\n\n\nCalculate the number of days between test 1 and test 2 for each participant and label this column test_diff (and resave dates).\n\n\ndates &lt;- dates |&gt; \n  mutate(test_diff = test2 - test1)\n\n\nCreate dates2 that subsets the participants who were born after January 1, 1970.\n\n\ndates2 &lt;- dates |&gt; \n  filter(birth_date &gt; \"1970-01-01\")\n\n\nCreate a column named diff_text that writes the following sentence for each participant in dates2: “Participant [insert id] (age: [insert age]) had test 1 on [insert test1] and test 2 on [insert test2], which were [insert test_diff] days apart.”\n\n\ndates2 |&gt; \n  mutate(diff_text = stringr::str_glue(\"Participant {id} (age: {age}) had test 1 on {test1} and test 2 on {test2}, which were {test_diff} days apart.\"))\n\n# A tibble: 8 × 7\n     id birth_date test1      test2        age test_diff diff_text              \n  &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;drtn&gt;    &lt;glue&gt;                 \n1     2 1990-09-14 2022-01-09 2022-08-14  31.3 217 days  Participant 2 (age: 31…\n2     4 1998-10-23 2022-02-26 2022-08-26  23.3 181 days  Participant 4 (age: 23…\n3     8 2001-11-18 2022-03-30 2022-08-03  20.4 126 days  Participant 8 (age: 20…\n4     9 1988-08-10 2022-01-29 2022-06-02  33.5 124 days  Participant 9 (age: 33…\n5    13 1978-07-03 2022-03-22 2022-06-24  43.7  94 days  Participant 13 (age: 4…\n6    15 1973-06-12 2022-03-24 2022-07-02  48.8 100 days  Participant 15 (age: 4…\n7    17 1973-09-04 2022-03-02 2022-07-03  48.5 123 days  Participant 17 (age: 4…\n8    20 1974-02-20 2022-02-14 2022-08-03  48   170 days  Participant 20 (age: 4…"
  },
  {
    "objectID": "code/24_functions_answers.html",
    "href": "code/24_functions_answers.html",
    "title": "Functions",
    "section": "",
    "text": "Write a function called mystring that takes a vector as an argument and returns the first three characters from the string. Test it on words[1:10].\n\n\nlibrary(stringr)\nmystring &lt;- function(x) {\n  str_sub(x, 1, 3)\n}\nmystring(words[1:10])\n\n [1] \"a\"   \"abl\" \"abo\" \"abs\" \"acc\" \"acc\" \"ach\" \"acr\" \"act\" \"act\"\n\n\n\nAdd an argument to mystring() that allows the user to control how many of the first characters should be returned. Test it on words[1:10] with 5 characters.\n\n\nmystring &lt;- function(x, chars) {\n  str_sub(x, 1, chars)\n}\nmystring(words[1:10], chars = 5)\n\n [1] \"a\"     \"able\"  \"about\" \"absol\" \"accep\" \"accou\" \"achie\" \"acros\" \"act\"  \n[10] \"activ\"\n\n\n\nSet the default number of characters returned by mystring() to be 3 and test that the default works and that you can override the default.\n\n\nmystring &lt;- function(x, chars = 3) {\n  str_sub(x, 1, chars)\n}\nmystring(words[1:10])\n\n [1] \"a\"   \"abl\" \"abo\" \"abs\" \"acc\" \"acc\" \"ach\" \"acr\" \"act\" \"act\"\n\nmystring(words[1:10], chars = 5)\n\n [1] \"a\"     \"able\"  \"about\" \"absol\" \"accep\" \"accou\" \"achie\" \"acros\" \"act\"  \n[10] \"activ\"\n\n\n\nAdd a step that checks whether the inputted vector is a character string. If it is, continue to return the truncated strings. If the vector is not a character string, use the stop() function to stop the computation and return a message to the console telling the user that the vector was not a character vector. Test your function with a character vector, a numeric vector, and a logical vector.\n\n\nmystring &lt;- function(x, chars = 3) {\n  if (!is.character(x)) {\n    stop(\"Please enter a character vector.\")\n  } else {\n  str_sub(x, 1, chars)\n  }\n}\n\nmystring(words[1:10])\n\n [1] \"a\"   \"abl\" \"abo\" \"abs\" \"acc\" \"acc\" \"ach\" \"acr\" \"act\" \"act\"\n\n# mystring(1:10)\n# mystring(c(TRUE, FALSE))\n\n\nCreate a function called parse_my_vector that does the following:\n\n\nAllows users to input a vector and a response to the argument type that determines whether the vector is a numeric (\"num\"), character (\"char\"), or logical (\"logical\") vector. There should be no default value. If the user response does not match any of these three strings, stop with a message asking the user to specify one of the three strings.\nFor each type, checks whether the vector is actually the type specified by the user and stops with a message if they do not match.\nFor numeric vectors, multiplies by 10. For character vectors, extracts the first three characters. For logical vectors, returns the number of TRUE responses.\nBefore returning output, prints a message thanking the user.\nReturns the original vector and output of the functions described above.\n\n\nparse_my_vector &lt;- function(x, type) {\n  if (type == \"num\") {\n    if (is.numeric(x)) {\n      output &lt;- x / 10\n    } else {\n      stop(\"Type response does not match vector type.\")\n    }\n  } else if (type == \"char\") {\n    if (is.character(x)) {\n      output &lt;- str_sub(x, 1, 3)\n    } else {\n      stop(\"Type response does not match vector type.\")\n    }\n  } else if (type == \"logical\") {\n    output &lt;- sum(x)\n  } else {\n    stop(\"Please enter either 'num', 'char', or 'logical'.\")\n  }\n  message(\"Thank you!\")\n  list(x,output)\n}\n\n\nCheck the following with parse_my_vector():\n\n\nx = 1:10, type = “num”\nx = 1:10, type = “char”\nx = words[1:10], type = “num”\nx = words[1:10], type = “char”\nx = c(TRUE, FALSE, TRUE), type = “num”\nx = c(TRUE, FALSE, TRUE), type = “logical”\nx = 1:10, type = “nums”\n\n\nparse_my_vector(x = 1:10, type = \"num\")\n\nThank you!\n\n\n[[1]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[2]]\n [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n# parse_my_vector(x = 1:10, type = \"char\")\n# parse_my_vector(x = words[1:10], type = \"num\")\nparse_my_vector(x = words[1:10], type = \"char\")\n\nThank you!\n\n\n[[1]]\n [1] \"a\"        \"able\"     \"about\"    \"absolute\" \"accept\"   \"account\" \n [7] \"achieve\"  \"across\"   \"act\"      \"active\"  \n\n[[2]]\n [1] \"a\"   \"abl\" \"abo\" \"abs\" \"acc\" \"acc\" \"ach\" \"acr\" \"act\" \"act\"\n\n# parse_my_vector(x = c(TRUE, FALSE, TRUE), type = \"num\")\nparse_my_vector(x = c(TRUE, FALSE, TRUE), type = \"logical\")\n\nThank you!\n\n\n[[1]]\n[1]  TRUE FALSE  TRUE\n\n[[2]]\n[1] 2\n\n# parse_my_vector(x = 1:10, type = \"nums\")"
  },
  {
    "objectID": "code/25_iteration_answers.html",
    "href": "code/25_iteration_answers.html",
    "title": "Iteration",
    "section": "",
    "text": "Write a for loop that calculates the mean bill length for each species in the penguins data set (don’t use group_by()) and saves them as species_means.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\npenguin_species &lt;- unique(penguins$species)\nspecies_means &lt;- NA\nfor (i in penguin_species) {\n  species_means[i] &lt;- penguins |&gt; \n    filter(species == i) |&gt; \n    summarise(mean_bill_length = mean(bill_length_mm, na.rm = TRUE)) |&gt; \n    pull()\n}\nspecies_means &lt;- species_means[!is.na(species_means)]\n\n\nTurn #1 into a function called species_mean that lets the user determine which variable to calculate the mean over.\n\n\nspecies_mean &lt;- function(var) {\n  penguin_species &lt;- unique(penguins$species)\n  species_means &lt;- NA\n  for (i in penguin_species) {\n    species_means[i] &lt;- penguins |&gt; \n      filter(species == i) |&gt; \n      summarise(mean({{var}}, na.rm = TRUE)) |&gt; \n      pull()\n  }\n  species_means &lt;- species_means[!is.na(species_means)]\n  return(species_means)\n}\nspecies_mean(bill_length_mm)\n\n   Adelie    Gentoo Chinstrap \n 38.79139  47.50488  48.83382 \n\n\n\nCreate a list penguins_island that separates the penguins data by island.\n\n\npenguins_island &lt;- penguins |&gt; \n  split(penguins$island)\n\n\nApply map() to find the number of observations for each year.\n\n\nmap(penguins_island, nrow)\n\n$Biscoe\n[1] 168\n\n$Dream\n[1] 124\n\n$Torgersen\n[1] 52\n\n\n\nApply map() to calculate the mean body weight for each island.\n\n\nmap(penguins_island, ~ mean(.x$body_mass_g, na.rm = TRUE))\n\n$Biscoe\n[1] 4716.018\n\n$Dream\n[1] 3712.903\n\n$Torgersen\n[1] 3706.373\n\n\n\nRework #5 to return a numeric vector with values rounded to 1 decimal place.\n\n\nmap_dbl(penguins_island, ~ round(mean(.x$body_mass_g, na.rm = TRUE), 1))\n\n   Biscoe     Dream Torgersen \n   4716.0    3712.9    3706.4"
  },
  {
    "objectID": "code/26_grammar1_answers.html",
    "href": "code/26_grammar1_answers.html",
    "title": "Grammar of graphics I",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nRepeat the plot but only with vehicles having 4 or 6 cylinders.\n\n\nmtcars |&gt; \n  filter(cyl &lt; 8) |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nRepeat plot #1 but add a smooth line underneath the data points.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_smooth() +\n  geom_point()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nMake a boxplot of fuel efficiency for each cylinder size.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = cyl, y = mpg)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nAdd ” cylinders” to the end of each value in the cylinder column of data and replot #4.\n\n\nmtcars |&gt; \n  mutate(cyl = paste0(cyl, \" cylinders\")) |&gt; \n  ggplot(aes(x = cyl, y = mpg)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nReplot #4 ordering the cylinders such that the median mpg increases from left to right.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = fct_reorder(cyl, mpg), y = mpg)) +\n  geom_boxplot()"
  },
  {
    "objectID": "code/27_grammar2_answers.html",
    "href": "code/27_grammar2_answers.html",
    "title": "Grammar of graphics II",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot, but make the points violet open squares of size 5.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(color = \"violet\", shape = 0, size = 5)\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot but with separate colors for cylinder levels.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nWhy does the legend look like that? Fix it so there are separate colors for cylinder levels.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg, color = as.factor(cyl))) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nOverlay separate regression lines for each cylinder level.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg, color = as.factor(cyl))) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nOverlay a single firebrick regression line over the points with a firebrick1-colored confidence band.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = as.factor(cyl))) +\n  geom_smooth(method = \"lm\", color = \"firebrick\", fill = \"firebrick1\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nPlot the mean and standard error of the mean of fuel efficiency for each level of cylinder and color them sienna.\n\n\nmtcars |&gt; \n  ggplot(aes(x = as.factor(cyl), y = mpg)) +\n  stat_summary(color = \"sienna\")\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "code/28_themes_answers.html",
    "href": "code/28_themes_answers.html",
    "title": "Design and themes",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight with color based on the number of cylinders.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot but with classic, bw, and dark themes.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme_classic()\n\n\n\n\n\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme_dark()\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot from #1 but with no minor grid lines and no legend.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot from #1 but no minor grid lines for the x-axis (keep them for the y-axis) and move the legend inside the plot area and remove the legend title.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme(panel.grid.minor.x = element_blank(),\n        legend.position = c(0.8, 0.8),\n        legend.title = element_blank())\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot from #1 but make the major y-axis grid lines black dashed lines and change the text font to 12 point Times font.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme(panel.grid.major.y = element_line(color = \"black\", linetype = 2),\n        text = element_text(family = \"Times\", size = 12))\n\n\n\n\n\n\n\n\n\nCreate a version of scatterplot #1 that minimizes the data-ink ratio by reducing non-data-ink.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        legend.title = element_blank(),\n        legend.position = c(0.8, 0.8))"
  },
  {
    "objectID": "code/29_color_answers.html",
    "href": "code/29_color_answers.html",
    "title": "Color",
    "section": "",
    "text": "Using the mtcars data, create a scatterplot of the fuel efficiency as a function of weight with color based on the number of cylinders.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nRepeat the scatterplot but use scale_color_brewer() to set the palette to Set1.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\nWhy did you use scale_color_brewer() not scale_fill_brewer() or scale_color_distiller()?\nRepeat scatterplot #1 but use scale_color_manual() to set the three colors to red, green, and blue.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  scale_color_manual(values = c(\"red\", \"green\", \"blue\"))\n\n\n\n\n\n\n\n\n\nFind three colors (either names or hex codes), and repeat scatterplot #4 with your own colors.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  scale_color_manual(values = c(\"coral2\", \"palegreen4\", \"slateblue4\"))\n\n\n\n\n\n\n\n\n\nUsing the mtcars data, create a scatterplot of the fuel efficiency as a function of weight with color based on horsepower using the BuPu palette and reverse the direction of the gradient.\n\n\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg, color = hp)) +\n  geom_point() +\n  scale_color_distiller(palette = \"BuPu\", direction = 2)\n\n\n\n\n\n\n\n\n\nCreate a new column in mtcars that centers and scales displacement with the scale() function. Create a scatterplot of fuel efficiency as a function of weight with color based on the rescaled displacement, using a diverging scale of your choice.\n\n\nmtcars |&gt; \n  mutate(disp2 = scale(disp)) |&gt; \n  ggplot(aes(x = wt, y = mpg, color = disp2)) +\n  geom_point() +\n  scale_color_distiller(palette = \"RdBu\")"
  },
  {
    "objectID": "code/30_histograms_answers.html",
    "href": "code/30_histograms_answers.html",
    "title": "Plotting distributions: histograms",
    "section": "",
    "text": "Using the mtcars data, create a histogram of the fuel efficiency values.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmtcars |&gt; \n  ggplot(aes(x = mpg)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nNot a great histogram. Mess with the number of bins until you get a nice histogram.\n\n\nmtcars |&gt; \n  ggplot(aes(x = mpg)) +\n  geom_histogram(bins = 8)\n\n\n\n\n\n\n\n\n\nNow change the bin width to generate the same plot as #2.\n\n\nmtcars |&gt; \n  ggplot(aes(x = mpg)) +\n  geom_histogram(binwidth = 3.35)\n\n\n\n\n\n\n\n\n\nUsing the same binwidth from #3, plot a histogram with lightseagreen lines and aquamarine3 shaded areas. Then overlay a density plot with a aquamarine4 line with width 2.\n\n\nmtcars |&gt; \n  ggplot(aes(x = mpg)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 3.35, fill = \"aquamarine3\", color = \"lightseagreen\") +\n  geom_density(bw = 3.35, color = \"aquamarine4\", linewidth = 2)\n\n\n\n\n\n\n\n\n\nWhat is the difference between a frequency polygon and a density plot?\nMake a density plot with bandwidth of 3 and separate line colors for different cylinder levels.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = mpg, color = cyl)) +\n  geom_density(bw = 3)\n\n\n\n\n\n\n\n\n\nRepeat #6 but also include separate colors for the shaded areas with a transparency of 0.5. Use viridis colors for both lines and shaded areas, and reverse the direction of the colors where 4 is yellow, 6 is greenish, and 8 is purplish.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = mpg, color = cyl, fill = cyl)) +\n  geom_density(bw = 3, alpha = 0.5) +\n  scale_color_viridis_d(direction = -1) +\n  scale_fill_viridis_d(direction = -1)"
  },
  {
    "objectID": "code/31_boxplots_answers.html",
    "href": "code/31_boxplots_answers.html",
    "title": "Plotting distributions: boxplots",
    "section": "",
    "text": "Using the penguins data, create a boxplot that shows penguin flipper length by island without outliers.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\npenguins %&gt;%\n  ggplot(aes(x = island, y = flipper_length_mm)) +\n  geom_boxplot(outlier.shape = NA)\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nAdd the means and standard error for each boxplot.\n\n\npenguins %&gt;%\n  ggplot(aes(x = island, y = flipper_length_mm)) +\n  geom_boxplot(outlier.shape = NA) +\n  stat_summary()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n\nSwitch from standard errors to confidence intervals, increase the size of the point, and color the box shading chocolate.\n\n\npenguins %&gt;%\n  ggplot(aes(x = island, y = flipper_length_mm)) +\n  geom_boxplot(outlier.shape = NA, fill = \"chocolate\") +\n  stat_summary(fun.data = mean_cl_normal, size = 0.75)\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n\n\nFill the boxplots with color separately for each island and remove the legend.\n\n\npenguins %&gt;%\n  ggplot(aes(x = island, y = flipper_length_mm, fill = island)) +\n  geom_boxplot(outlier.shape = NA) +\n  stat_summary(fun.data = mean_cl_normal, size = 0.75) +\n  theme(legend.position = \"none\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n\n\nCreate a boxplot to show how flipper length differs for each species by island.\n\n\npenguins %&gt;%\n  ggplot(aes(x = island, y = flipper_length_mm, fill = island)) +\n  geom_boxplot(outlier.shape = NA) +\n  stat_summary(fun.data = mean_cl_normal, size = 0.75) +\n  facet_wrap(vars(species)) +\n  theme(legend.position = \"none\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n\n\nRecreate the boxplot #5 as a violin plot with a white background.\n\n\npenguins %&gt;%\n  ggplot(aes(x = island, y = flipper_length_mm, fill = island)) +\n  geom_violin(outlier.shape = NA) +\n  stat_summary(fun.data = mean_cl_normal, size = 0.75) +\n  facet_wrap(vars(species)) +\n  theme(legend.position = \"none\",\n        panel.background = element_rect(fill = \"white\"))\n\nWarning in geom_violin(outlier.shape = NA): Ignoring unknown parameters:\n`outlier.shape`\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_summary()`)."
  },
  {
    "objectID": "code/32_barcharts_answers.html",
    "href": "code/32_barcharts_answers.html",
    "title": "Plotting amounts: barcharts and dot plots",
    "section": "",
    "text": "Using the mtcars data, create a barchart of the counts for each level of cylinder.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl),\n         gear = as.factor(gear)) |&gt; \n  ggplot(aes(x = cyl)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nRepeat the barchart but stack the counts by gear.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl),\n         gear = as.factor(gear)) |&gt; \n  ggplot(aes(x = cyl, fill = gear)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nRecreate this plot:\n\n\n\nmtcars |&gt;\n  mutate(cyl = as.factor(cyl),\n         cyl = str_c(cyl, \" cylinders\"),\n         gear = as.factor(gear),\n         gear = str_c(gear, \" gears\")) |&gt;\n  ggplot(aes(x = cyl, fill = gear)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\nRepeat barchart #2 but set the position to “dodge”.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl),\n         gear = as.factor(gear)) |&gt; \n  ggplot(aes(x = cyl, fill = gear)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\nWhoa, what happened to 8 cylinders? Unfortunately, since there were only two levels of gear for 8 cylinders, it just split the bars in two. To hold the numbers of bars the same across all levels, you can set position to position_dodge(preserve = \"single\"). Try that.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl),\n         gear = as.factor(gear)) |&gt; \n  ggplot(aes(x = cyl, fill = gear)) +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\n\n\n\n\n\n\nWell, that’s better—the two bars are the same width as all of the other bars. But the 4 gears should show up as 0. To fix, we need to count the data first, find implicitly missing data, and plot using geom_col(). So first, find counts for the combinations of cylinders and gears. Then use complete() to find the implicitly missing combinations. Then replace the NAs with 0s. Then use geom_col() to plot these values with the position dodged.\n\n\nmtcars |&gt; \n  mutate(cyl = as.factor(cyl),\n         gear = as.factor(gear)) |&gt; \n  count(cyl, gear) |&gt; \n  complete(cyl, gear) |&gt; \n  mutate(n = as.numeric(str_replace_na(n, \"0\"))) |&gt; \n  ggplot(aes(x = cyl, y = n, fill = gear)) +\n  geom_col(position = position_dodge())\n\n\n\n\n\n\n\n\n\nMake a dotplot of the counts for each level of carb and plot carb on the y-axis and the count on the x-axis. Reminder that first you’ll need to count the observations in each level of carb before starting the plot.\n\n\nmtcars |&gt; \n  count(carb) |&gt; \n  ggplot(aes(x = carb, y = n)) +\n  geom_point() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nRepeat dotplot #8 but order carb based on the counts from highest to lowest count.\n\n\nmtcars |&gt; \n  count(carb) |&gt; \n  ggplot(aes(x = fct_reorder(as.factor(carb), n), y = n)) +\n  geom_point() +\n  coord_flip()"
  },
  {
    "objectID": "code/33_associations_answers.html",
    "href": "code/33_associations_answers.html",
    "title": "Plotting x-y data: associations",
    "section": "",
    "text": "Using the mpg data, create a scatterplot of the highway fuel efficiency and city fuel efficiency.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmpg |&gt; \n  ggplot(aes(x = hwy, y = cty)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nNow add a dashed reference line showing equivalent values for the two axes and set the aspect ratio to 1.\n\n\nmpg |&gt; \n  ggplot(aes(x = hwy, y = cty)) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\")+\n  geom_point() +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\n\n\nLooks like there is a possibility of overplotting. Turn this into a bubble chart with dot size scaling to the number of data points for each dot and make the dot colors steelblue.\n\n\nmpg |&gt; \n  ggplot(aes(x = hwy, y = cty)) +\n  geom_count(color = \"steelblue\")\n\n\n\n\n\n\n\n\n\nAdd rugs to scatterplot #1 and change to minimal theme.\n\n\nmpg |&gt; \n  ggplot(aes(x = hwy, y = cty)) +\n  geom_point() +\n  geom_rug() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nFrom scatterplot #1, color the dots by class, move the legend to the top left corner of the plot, and add marginal density plots.\n\n\nlibrary(ggExtra)\nclass_plot &lt;- mpg |&gt; \n  ggplot(aes(x = hwy, y = cty, color = class)) +\n  geom_point() +\n  theme(legend.position = c(0.2, 0.7))\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\nggMarginal(class_plot, type = \"density\", groupFill = TRUE)\n\n\n\n\n\n\n\n\n\nCreate a data frame called mpg_num that only includes variables with numeric values using the where() function. Then remove the year column.\n\n\nmpg_num &lt;- mpg |&gt; \n  select(where(is.numeric)) |&gt; \n  select(!year)\n\n\nCreate correlation plots of the numeric variables in mpg_num in both base R and using {GGally}’s ggpairs() function.\n\n\npairs(mpg_num)\n\n\n\n\n\n\n\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nggpairs(mpg_num)\n\n\n\n\n\n\n\n\n\nCreate a correlation matrix of mpg_num with the cor() function. Then use ggcorrplot() from the {ggcorrplot} package to make a heatmap correlation plot with just the upper triangle of the matrix and using circles to represent correlation coefficient magnitude.\n\n\nlibrary(ggcorrplot)\nmpg_num |&gt; \n  cor() |&gt; \n  ggcorrplot(type = \"upper\", method = \"circle\")"
  },
  {
    "objectID": "code/34_timeseries_answers.html",
    "href": "code/34_timeseries_answers.html",
    "title": "Plotting x-y data: time series",
    "section": "",
    "text": "Using the mpg data, calculate the mean highway fuel efficiency for each number of cylinders and plot a line graph of fuel efficiency by cylinder number.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmpg |&gt; \n  group_by(cyl) |&gt; \n  summarise(mean_hwy = mean(hwy)) |&gt; \n  ggplot(aes(x = cyl, y = mean_hwy)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nRepeat the previous plot but also group by class and plot separately colored lines for different classes.\n\n\nmpg |&gt; \n  group_by(cyl, class) |&gt; \n  summarise(mean_hwy = mean(hwy)) |&gt; \n  ggplot(aes(x = cyl, y = mean_hwy, color = class)) +\n  geom_line()\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nCreate a new column called low_high that codes high fuel efficiency greater than or equal to 25 as 1 and less than 25 as 0. Plot low_high as a function of displacement with a bubble chart (no legend) and include a logistic regression curve and band.\n\n\nmpg |&gt; \n  mutate(low_high = ifelse(hwy &gt; 25, 1, 0)) |&gt; \n  ggplot(aes(x = displ, y = low_high)) +\n  geom_count(show.legend = FALSE) +\n  geom_smooth(method = \"glm\", formula = y ~ x, method.args = list(family = \"binomial\"))\n\n\n\n\n\n\n\n\n\nPlot highway fuel efficiency for each class as points first, then add jitter, finding an appropriate amount of jitter to add.\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_point()\n\n\n\n\n\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_jitter(width = 0.1, height = 2)\n\n\n\n\n\n\n\n\n\nRepeat plot #4 with a beeswarm plot.\n\n\nlibrary(ggbeeswarm)\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_beeswarm()"
  },
  {
    "objectID": "code/35_categories_answers.html",
    "href": "code/35_categories_answers.html",
    "title": "Plotting x-y data: categories",
    "section": "",
    "text": "Using the mpg data, create a data object called class_cyl that subsets only the compact and midsize class cars with 4 or 6 cylinders and makes cylinder number a factor. You should end up with 84 observations.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nclass_cyl &lt;- mpg |&gt; \n  filter(class %in% c(\"compact\", \"midsize\") &\n           cyl %in% c(4, 6)) |&gt; \n  mutate(cyl = as.factor(cyl))\n\n\nCreate an interaction plot from class_cyl with cylinder number on the x-axis, highway fuel efficiency on the y-axis, and separately colored lines for class. Spatially separate overlapping error bars.\n\n\nlibrary(tidyverse)\nclass_cyl |&gt; \n  ggplot(aes(x = cyl, y = hwy, color = class, group = class)) +\n  stat_summary(position = position_dodge(width = 0.1)) +\n  stat_summary(fun = mean, geom = \"line\", position = position_dodge(width = 0.1))\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n\nRepeat interaction plot #2, reversing the roles of class and cylinder number by making class the x-axis and cylinder number the lines. Do the two plots communicate information differently? Which do you prefer?\n\n\nmpg |&gt; \n  filter(class %in% c(\"compact\", \"midsize\") &\n           cyl %in% c(4, 6)) |&gt; \n  mutate(cyl = as.factor(cyl)) |&gt; \n  ggplot(aes(x = class, y = hwy, color = cyl, group = cyl)) +\n  stat_summary() +\n  stat_summary(fun = mean, geom = \"line\")\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n\nTake the class_cyl data and calculate the mean and standard error for each combination of class and cylinder number levels. Note that you can calculate standard error by dividing the standard deviation by the square root of the sample size. Next, create a column that subtracts SE from mean for the lower bound and add SE to mean for the upper bound. Assign these means, standard errors, and lower and upper bounds to mean_mpg (you should have 4 observations and 6 variables).\n\n\nmean_mpg &lt;- class_cyl |&gt; \n  group_by(cyl, class) |&gt; \n  summarise(mean_hwy = mean(hwy), se_hwy = sd(hwy) / sqrt(n())) |&gt; \n  mutate(lower = mean_hwy - se_hwy, upper = mean_hwy + se_hwy)\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n\nReplicate plot #3 using the mean_mpg data set by plotting the means and bounds as error bars and include a line connecting across class. Is it identical to plot #3?\n\n\nmean_mpg |&gt; \n  ggplot(aes(x = class, y = mean_hwy, color = cyl)) +\n  geom_pointrange(aes(ymin = lower, ymax = upper)) +\n  geom_line(aes(group = cyl))\n\n\n\n\n\n\n\n\n\nUsing class_cyl, calculate the mean highway fuel efficiency for each manufacturer and cylinder size. Plot a slopegraph of dashed lines for each manufacturer connecting the mean fuel efficiency for 4 and 6 cylinders. Overlay the mean and standard deviation across manufacturers for both levels of cylinder number.\n\n\nclass_cyl |&gt; \n  group_by(manufacturer, cyl) |&gt; \n  summarise(mean_hwy = mean(hwy)) |&gt; \n  ggplot(aes(x = cyl, y = mean_hwy)) +\n  geom_line(linetype = \"dashed\", aes(group = manufacturer)) +\n  stat_summary()\n\n`summarise()` has grouped output by 'manufacturer'. You can override using the\n`.groups` argument.\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n\nUsing mpg, create a raincloud plot that includes a half density plot and half dot plot of highway fuel efficiency for each class. Adjust the bin width and dot size to produce a reasonable distribution of dots. Color the lines and shaded areas differently for each class, but remove the legend. Reduce the opacity of the shaded areas.\n\n\nlibrary(gghalves)\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy, fill = class, color = class)) +\n  geom_half_violin(alpha = 0.5) +\n  geom_half_dotplot(binwidth = 0.5, dotsize = 0.5) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "code/36_axes_answers.html",
    "href": "code/36_axes_answers.html",
    "title": "Adjusting axes",
    "section": "",
    "text": "Using the mpg data, create boxplots of highway fuel efficiency as a function of class.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nZoom into the plot with y-axis limits of 15 and 40 without altering the data.\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot() +\n  coord_cartesian(ylim = c(15, 40))\n\n\n\n\n\n\n\n\n\nChange the y-axis limits to 15 and 40 but allow the statistical transformations to change the data.\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot() +\n  ylim(15, 40)\n\nWarning: Removed 10 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nReplot #1 but using a log10 scale.\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot() +\n  scale_y_log10()\n\n\n\n\n\n\n\n\n\nReplot #1 but with y-axis limits running from 0 to 50 and with labels in increments of 5 but no minor grid lines.\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0, 50), breaks = seq(0, 50, 5)) +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nReplot #1 but create separate panels based on year (as rows) and cylinders (as columns) and allowing the scales to vary across rows.\n\n\nmpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot() +\n  facet_grid(rows = vars(year), cols = vars(cyl), scale = \"free\")\n\n\n\n\n\n\n\n\n\nReplot #1 and assign it to hwy_plot and replot a similar version with city fuel efficiency named cty_plot. Then combine them into a compound plot labeled as subfigures A and B and save this figure on your computer as a PNG file.\n\n\nhwy_plot &lt;- mpg |&gt; \n  ggplot(aes(x = class, y = hwy)) +\n  geom_boxplot()\ncty_plot &lt;- mpg |&gt; \n  ggplot(aes(x = class, y = cty)) +\n  geom_boxplot()\nlibrary(patchwork)\nhwy_plot + cty_plot + plot_annotation(tag_levels = \"A\")\n\n\n\n\n\n\n\n# ggsave(\"fuel_efficiency_class.png\")"
  },
  {
    "objectID": "code/37_annotating_answers.html",
    "href": "code/37_annotating_answers.html",
    "title": "Annotating plots",
    "section": "",
    "text": "Using the mpg data, create a scatterplot of highway and city fuel efficiencies. Create a title, subtitle, caption, and axes labels.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmpg |&gt; \n  ggplot(aes(x = cty, y = hwy)) +\n  geom_point() +\n  labs(title = \"Fuel efficiency\", subtitle = \"Highway vs. city miles per gallon\", caption = \"Source: mpg data\", x = \"City miles per gallon\", y = \"Highway miles per gallon\")\n\n\n\n\n\n\n\n\n\nRepeat #1 adding a linear regression line. Use cor() to calculate the correlation coefficient for the correlation. Add it to the plot somewhere labeled and rounded to two decimals.\n\n\nmpg_corr &lt;- cor(mpg$hwy, mpg$cty)\nmpg |&gt; \n  ggplot(aes(x = cty, y = hwy)) +\n  geom_smooth(method = \"lm\") +\n  geom_point() +\n  labs(title = \"Fuel efficiency\", subtitle = \"Highway vs. city miles per gallon\", caption = \"Source: mpg data\", x = \"City miles per gallon\", y = \"Highway miles per gallon\") +\n  annotate(geom = \"text\", label = paste0(\"r = \", round(mpg_corr, 2)), x = 15, y = 40)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nRepeat #1. Find the manufacturer and model of the data point with the highest city fuel efficiency. Label this point by drawing a line from the point to the text label and include the manufacturer and model (broken across two lines).\n\n\nmpg |&gt; \n  ggplot(aes(x = cty, y = hwy)) +\n  geom_point() +\n  labs(title = \"Fuel efficiency\", subtitle = \"Highway vs. city miles per gallon\", caption = \"Source: mpg data\", x = \"City miles per gallon\", y = \"Highway miles per gallon\") +\n  annotate(geom = \"text\", label = \"Volkswagon\\nBeetle\", x = 33, y = 40) +\n  annotate(geom = \"segment\", x = 33, xend = 34.8, y = 41, yend = 43.5)\n\n\n\n\n\n\n\n\n\nRepeat #1 drawing grey horizontal and vertical lines at 20 mpg for both axes underneath the data points. Add a lightpink rectangle under the points filling the upper right quandrant (&gt;20 for both axes).\n\n\nmpg |&gt; \n  ggplot(aes(x = cty, y = hwy)) +\n  geom_hline(yintercept = 20, color = \"grey60\") +\n  geom_vline(xintercept = 20, color = \"grey60\") +\n  annotate(geom = \"rect\", xmin = 20, xmax = 50, ymin = 20, ymax = 50, fill = \"lightpink\", alpha = 0.25) +\n  geom_point() +\n  labs(title = \"Fuel efficiency\", subtitle = \"Highway vs. city miles per gallon\", caption = \"Source: mpg data\", x = \"City miles per gallon\", y = \"Highway miles per gallon\") +\n  coord_cartesian(xlim = c(9, 35), ylim = c(10, 45))\n\n\n\n\n\n\n\n\n\nCreate boxplots of fuel efficiency by class but order the class levels by mean highway fuel efficiency. At y = 10, add the sample size for each box (e.g., N=5, N=47, etc.).\n\n\nmpg |&gt; \n  ggplot(aes(x = fct_reorder(class, hwy), y = hwy)) +\n  geom_boxplot() +\n  geom_text(stat = \"count\", aes(label = paste0(\"N=\", after_stat(count))), y = 10) +\n  ylim(10, 44)"
  },
  {
    "objectID": "code/39_tables_answers.html",
    "href": "code/39_tables_answers.html",
    "title": "Tables",
    "section": "",
    "text": "Using the mpg data, create a data frame called my_mpg that capitalizes the manufacturer.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmy_mpg &lt;- mpg |&gt; \n  mutate(manufacturer = str_to_sentence(manufacturer))\n\n\nCalculate mean highway and city fuel efficiency for each manufacturer and return a table with the caption “Highway and city fuel efficiency” and column names “Manufacturer”, “Highway”, and “City”.\n\n\nlibrary(knitr)\nmy_mpg |&gt; \n  summarise(mean_hwy = mean(hwy), mean_cty = mean(cty), .by = c(manufacturer)) |&gt; \n  kable(digits = 1, \n        col.names = c(\"Manufacturer\", \"Highway\", \"City\"),\n        caption = \"Highway and city fuel efficiency\")\n\n\nHighway and city fuel efficiency\n\n\nManufacturer\nHighway\nCity\n\n\n\n\nAudi\n26.4\n17.6\n\n\nChevrolet\n21.9\n15.0\n\n\nDodge\n17.9\n13.1\n\n\nFord\n19.4\n14.0\n\n\nHonda\n32.6\n24.4\n\n\nHyundai\n26.9\n18.6\n\n\nJeep\n17.6\n13.5\n\n\nLand rover\n16.5\n11.5\n\n\nLincoln\n17.0\n11.3\n\n\nMercury\n18.0\n13.2\n\n\nNissan\n24.6\n18.1\n\n\nPontiac\n26.4\n17.0\n\n\nSubaru\n25.6\n19.3\n\n\nToyota\n24.9\n18.5\n\n\nVolkswagen\n29.2\n20.9\n\n\n\n\n\n\nRepeat the table from #2 but add a header that spans Highway and City that says “Fuel efficiency”. Reminder, you’ll need to load {kableExtra} to do this.\n\n\nlibrary(kableExtra)\nmy_mpg |&gt; \n  summarise(mean_hwy = mean(hwy), mean_cty = mean(cty), .by = c(manufacturer)) |&gt; \n  kable(digits = 1, \n        col.names = c(\"Manufacturer\", \"Highway\", \"City\"),\n        caption = \"Highway and city fuel efficiency\") |&gt; \n  add_header_above(c(\" \" = 1, \"Fuel efficiency\" = 2))\n\n\nHighway and city fuel efficiency\n\n\n\n\n\n\n\n\n\nFuel efficiency\n\n\n\nManufacturer\nHighway\nCity\n\n\n\n\nAudi\n26.4\n17.6\n\n\nChevrolet\n21.9\n15.0\n\n\nDodge\n17.9\n13.1\n\n\nFord\n19.4\n14.0\n\n\nHonda\n32.6\n24.4\n\n\nHyundai\n26.9\n18.6\n\n\nJeep\n17.6\n13.5\n\n\nLand rover\n16.5\n11.5\n\n\nLincoln\n17.0\n11.3\n\n\nMercury\n18.0\n13.2\n\n\nNissan\n24.6\n18.1\n\n\nPontiac\n26.4\n17.0\n\n\nSubaru\n25.6\n19.3\n\n\nToyota\n24.9\n18.5\n\n\nVolkswagen\n29.2\n20.9\n\n\n\n\n\n\n\n\nCalculate mean highway and city fuel efficiency for each manufacturer and year. Order the data frame by year, then remove the year column and add labels for each year that spans the rows for each year. Also, add a footnote that says “Source: mpg data set.”.\n\n\nmy_mpg |&gt; \n  summarise(mean_hwy = mean(hwy), mean_cty = mean(cty), .by = c(year, manufacturer)) |&gt; \n  arrange(year) |&gt; \n  select(-year) |&gt; \n  kable(digits = 1, \n        col.names = c(\"Manufacturer\", \"Highway\", \"City\"),\n        caption = \"Highway and city fuel efficiency\") |&gt; \n  pack_rows(\"1999\", 1, 15) |&gt; \n  pack_rows(\"2008\", 16, 30) |&gt; \n  footnote(general = \"Source: mpg data set.\")\n\n\nHighway and city fuel efficiency\n\n\nManufacturer\nHighway\nCity\n\n\n\n\n1999\n\n\nAudi\n26.1\n17.1\n\n\nChevrolet\n21.6\n15.1\n\n\nDodge\n18.4\n13.4\n\n\nFord\n18.6\n13.9\n\n\nHonda\n31.6\n24.8\n\n\nHyundai\n26.7\n18.3\n\n\nJeep\n18.5\n14.5\n\n\nLand rover\n15.0\n11.0\n\n\nLincoln\n16.5\n11.0\n\n\nMercury\n17.0\n13.5\n\n\nNissan\n23.5\n17.7\n\n\nPontiac\n26.3\n17.0\n\n\nSubaru\n25.5\n19.0\n\n\nToyota\n24.0\n18.1\n\n\nVolkswagen\n29.7\n21.2\n\n\n2008\n\n\nAudi\n26.8\n18.1\n\n\nChevrolet\n22.1\n14.9\n\n\nDodge\n17.6\n13.0\n\n\nFord\n20.5\n14.1\n\n\nHonda\n33.8\n24.0\n\n\nHyundai\n27.0\n18.9\n\n\nJeep\n17.3\n13.2\n\n\nLand rover\n18.0\n12.0\n\n\nLincoln\n18.0\n12.0\n\n\nMercury\n19.0\n13.0\n\n\nNissan\n25.6\n18.4\n\n\nPontiac\n26.5\n17.0\n\n\nSubaru\n25.6\n19.5\n\n\nToyota\n26.1\n19.1\n\n\nVolkswagen\n28.5\n20.5\n\n\n\nNote: \n\n\n\n\n Source: mpg data set.\n\n\n\n\n\n\n\n\n\n\n\nConduct a linear regression called my_model of the effects of displacement, cylinder, and year on highway fuel efficiency: lm(hwy ~ displ + cyl + year, my_mpg). Apply the summary() function to the model object, then return the coefficients table from the summary.\n\n\nmy_model &lt;- lm(hwy ~ displ + cyl + year, my_mpg)\nmy_model_summary &lt;- summary(my_model)$coefficients\nkable(my_model_summary)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n-259.1221270\n109.1594125\n-2.373795\n0.0184288\n\n\ndispl\n-2.0912178\n0.5146232\n-4.063590\n0.0000663\n\n\ncyl\n-1.3065333\n0.4111205\n-3.177982\n0.0016866\n\n\nyear\n0.1484984\n0.0545146\n2.724013\n0.0069446\n\n\n\n\n\n\nExtract the table after applying {papaja}’s apa_print() to my_model, then pass this to apa_table().\n\n\nlibrary(papaja)\napa_table(apa_print(my_model)$table)\n\n\n(#tab:unnamed-chunk-6)\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n-259.12\n[-474.20, -44.04]\n-2.37\n230\n.018\n\n\nDispl\n-2.09\n[-3.11, -1.08]\n-4.06\n230\n&lt; .001\n\n\nCyl\n-1.31\n[-2.12, -0.50]\n-3.18\n230\n.002\n\n\nYear\n0.15\n[0.04, 0.26]\n2.72\n230\n.007"
  },
  {
    "objectID": "code/codebook_mtcars.html",
    "href": "code/codebook_mtcars.html",
    "title": "Codebook for mtcars",
    "section": "",
    "text": "# &gt;\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#mpg",
    "href": "code/codebook_mtcars.html#mpg",
    "title": "Codebook for mtcars",
    "section": "mpg",
    "text": "mpg\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n25\n\n\nMedian\n19.2\n\n\n1st and 3rd quartiles\n15.43; 22.8\n\n\nMin. and max.\n10.4; 33.9\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#cyl",
    "href": "code/codebook_mtcars.html#cyl",
    "title": "Codebook for mtcars",
    "section": "cyl",
    "text": "cyl\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n3\n\n\nMedian\n6\n\n\n1st and 3rd quartiles\n4; 8\n\n\nMin. and max.\n4; 8\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#disp",
    "href": "code/codebook_mtcars.html#disp",
    "title": "Codebook for mtcars",
    "section": "disp",
    "text": "disp\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n27\n\n\nMedian\n196.3\n\n\n1st and 3rd quartiles\n120.83; 326\n\n\nMin. and max.\n71.1; 472\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#hp",
    "href": "code/codebook_mtcars.html#hp",
    "title": "Codebook for mtcars",
    "section": "hp",
    "text": "hp\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n22\n\n\nMedian\n123\n\n\n1st and 3rd quartiles\n96.5; 180\n\n\nMin. and max.\n52; 335\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#drat",
    "href": "code/codebook_mtcars.html#drat",
    "title": "Codebook for mtcars",
    "section": "drat",
    "text": "drat\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n22\n\n\nMedian\n3.7\n\n\n1st and 3rd quartiles\n3.08; 3.92\n\n\nMin. and max.\n2.76; 4.93\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#wt",
    "href": "code/codebook_mtcars.html#wt",
    "title": "Codebook for mtcars",
    "section": "wt",
    "text": "wt\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n29\n\n\nMedian\n3.33\n\n\n1st and 3rd quartiles\n2.58; 3.61\n\n\nMin. and max.\n1.51; 5.42\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#qsec",
    "href": "code/codebook_mtcars.html#qsec",
    "title": "Codebook for mtcars",
    "section": "qsec",
    "text": "qsec\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n30\n\n\nMedian\n17.71\n\n\n1st and 3rd quartiles\n16.89; 18.9\n\n\nMin. and max.\n14.5; 22.9\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#vs",
    "href": "code/codebook_mtcars.html#vs",
    "title": "Codebook for mtcars",
    "section": "vs",
    "text": "vs\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n2\n\n\nMedian\n0\n\n\n1st and 3rd quartiles\n0; 1\n\n\nMin. and max.\n0; 1\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#am",
    "href": "code/codebook_mtcars.html#am",
    "title": "Codebook for mtcars",
    "section": "am",
    "text": "am\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n2\n\n\nMedian\n0\n\n\n1st and 3rd quartiles\n0; 1\n\n\nMin. and max.\n0; 1\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#gear",
    "href": "code/codebook_mtcars.html#gear",
    "title": "Codebook for mtcars",
    "section": "gear",
    "text": "gear\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n3\n\n\nMedian\n4\n\n\n1st and 3rd quartiles\n3; 4\n\n\nMin. and max.\n3; 5\n\n\n\n\n# &gt;"
  },
  {
    "objectID": "code/codebook_mtcars.html#carb",
    "href": "code/codebook_mtcars.html#carb",
    "title": "Codebook for mtcars",
    "section": "carb",
    "text": "carb\n\n\n\n\n\n\n\nFeature\nResult\n\n\n\n\nVariable type\nnumeric\n\n\nNumber of missing obs.\n0 (0 %)\n\n\nNumber of unique values\n6\n\n\nMedian\n2\n\n\n1st and 3rd quartiles\n2; 4\n\n\nMin. and max.\n1; 8\n\n\n\n\n# &gt;\n\nReport generation information:\n\nCreated by: Jeffrey R. Stevens (username: jstevens).\nReport creation time: Sat Feb 04 2023 12:27:58\nReport was run from directory: /media/jstevens/data/jstevens/OneDrive/active_sync/projects/dpavir_2023/code\ndataReporter v1.0.2 [Pkg: 2021-11-11 from RSPM (R 4.2.0)]\nR version 4.2.2 Patched (2022-11-10 r83330).\nPlatform: x86_64-pc-linux-gnu (64-bit)(Ubuntu 22.04.1 LTS).\nFunction call: dataReporter::makeDataReport(data = mtcars, mode = c(\"summarize\",  \"visualize\", \"check\"), smartNum = FALSE, file = \"codebook_mtcars.Rmd\",      replace = TRUE, checks = list(character = \"showAllFactorLevels\",          factor = \"showAllFactorLevels\", labelled = \"showAllFactorLevels\",          haven_labelled = \"showAllFactorLevels\", numeric = NULL,          integer = NULL, logical = NULL, Date = NULL), listChecks = FALSE,      maxProbVals = Inf, codebook = TRUE, reportTitle = \"Codebook for mtcars\")"
  },
  {
    "objectID": "group_challenges.html",
    "href": "group_challenges.html",
    "title": "Group challenges",
    "section": "",
    "text": "Using the penguins data set from the {palmerpenguins} package, recreate this data frame.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\n\n`summarise()` has grouped output by 'species', 'island'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 4 × 4\n# Groups:   species, island [4]\n  species   island    female  male\n  &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie    Biscoe     3369. 4050 \n2 Adelie    Dream      3344. 4046.\n3 Adelie    Torgersen  3396. 4035.\n4 Chinstrap Dream      3527. 3939."
  },
  {
    "objectID": "group_challenges.html#group-data-wrangling-challenge",
    "href": "group_challenges.html#group-data-wrangling-challenge",
    "title": "Group challenges",
    "section": "",
    "text": "Using the penguins data set from the {palmerpenguins} package, recreate this data frame.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\n\n`summarise()` has grouped output by 'species', 'island'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 4 × 4\n# Groups:   species, island [4]\n  species   island    female  male\n  &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie    Biscoe     3369. 4050 \n2 Adelie    Dream      3344. 4046.\n3 Adelie    Torgersen  3396. 4035.\n4 Chinstrap Dream      3527. 3939."
  },
  {
    "objectID": "group_challenges.html#group-plotting-challenge",
    "href": "group_challenges.html#group-plotting-challenge",
    "title": "Group challenges",
    "section": "Group plotting challenge",
    "text": "Group plotting challenge\nplot1 &lt;- penguins |&gt; filter(species == “Adelie”) |&gt; drop_na(sex) |&gt; mutate(Sex = fct_recode(sex, “Female” = “female”, “Male” = “male”)) |&gt; ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = Sex)) + geom_point(size = 2.8, alpha = 0.55) + geom_smooth(method = “lm”, se = F, color = “gray50”) + scale_x_continuous(limits = c(31, 46), n.breaks = 15) + scale_y_continuous(limits = c(16, 21), n.breaks = 8, expand = c(0, 1.5)) + annotate(geom = “segment”, x = 33.5, xend = 34.35, y = 21.5, yend = 21.2, color = “black”) + annotate(geom = “text”, label = “Penguin 42”, x = 34, y = 21.8) + labs(y = “Bill depth (mm)”, x = “Bill length (mm)”, title = “Bill size by sex”) + theme_classic() + theme(legend.position = c(0.85, 0.2), legend.background = element_rect(fill = “transparent”, color = “transparent”))\nplot2 &lt;- penguins |&gt; filter(species == “Adelie”) |&gt; drop_na(sex, island) |&gt; mutate(Sex = fct_recode(sex, “Female” = “female”, “Male” = “male”), Island = island) |&gt; ggplot(aes(x = Sex, y = flipper_length_mm, group = Island, shape = Island, color = Island)) + stat_summary(position = position_dodge(width = 0.12)) + stat_summary(fun = mean, geom = “line”, position = position_dodge(width = 0.12)) + labs(y = “Flipper length (mm)”, title = “Mean and standard error of flipper length by sex and island”) + theme_classic() + theme(legend.position = c(0.85, 0.25))\nplot3 &lt;- penguins |&gt; filter(species == “Adelie”) |&gt; drop_na(sex, island, year) |&gt; mutate(Sex = fct_recode(sex, “Female” = “female”, “Male” = “male”), Year = as.factor(year)) |&gt; ggplot(aes(x = Year, y = flipper_length_mm, color = Year)) + geom_jitter(width = .2, alpha = 0.6) + stat_summary(fun.data = mean_cl_normal, color = “black”) + scale_y_continuous(limits = c(170, 210), n.breaks = 5) + geom_text(stat = “count”, aes(label = paste0(“N =”, after_stat(count))), y = 170, color = “black”) + facet_wrap(vars(island)) + labs(y = “Flipper length (mm)”, title = “Mean and 95% confidence interval of flipper length by island and year”) + scale_color_manual(values = c(“#0072B2”, “#009E73”, “#E69F00”)) + theme_classic() + theme(legend.position = “none”)\n(plot1 + plot2) / plot3 + plot_annotation(title = “Adelie penguin bill and flipper size”, caption = “Source {palmerpenguins} data set”, tag_levels = “A”)"
  }
]